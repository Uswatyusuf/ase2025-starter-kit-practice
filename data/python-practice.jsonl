{"id": "3c4689", "repo": "celery/kombu", "revision": "0d3b1e254f9178828f62b7b84f0307882e28e2a0", "path": "t/integration/test_redis.py", "modified": ["t/integration/common.py", "t/integration/test_redis.py"], "prefix": "from __future__ import absolute_import, unicode_literals\n\nimport os\n\nimport pytest\nimport kombu\n\nfrom .common import BasicFunctionality, BaseExchangeTypes\n\n\ndef get_connection(\n        hostname, port, vhost):\n    return kombu.Connection('redis://{}:{}'.format(hostname, port))\n\n\n@pytest.fixture()\ndef connection(request):\n    # this fixture yields plain connections to broker and TLS encrypted\n    return get_connection(\n        hostname=os.environ.get('REDIS_HOST', 'localhost'),\n        port=os.environ.get('REDIS_6379_TCP', '6379'),\n        vhost=getattr(\n            request.config, \"slaveinput\", {}\n        ).get(\"slaveid\", None),\n    )\n\n\n@pytest.mark.env('redis')\n@pytest.mark.flaky(reruns=5, reruns_delay=2)\nclass test_RedisBasicFunctionality(BasicFunctionality):\n    pass\n\n\n@pytest.mark.env('redis')\n@pytest.mark.flaky(reruns=5, reruns_delay=2)\nclass test_RedisBaseExchangeTypes(BaseExchangeTypes):\n    pass\n\n\n@pytest.mark.env('redis')\n@pytest.mark.flaky(reruns=5, reruns_delay=2)\nclass test_RedisPriority(BasePriority):\n\n    # Comparing to py-amqp transport has Redis transport several\n    # differences:\n    # 1. Order of priorities is reversed\n    # 2. drain_events() consumes only single value\n\n    # redis transport has lower numbers higher priority\n    PRIORITY_ORDER = 'desc'\n\n    def test_publish_consume(self, connection):\n        test_queue = kombu.Queue(\n            'priority_test', routing_key='priority_test', max_priority=10\n        )\n\n        received_messages = []\n\n        def callback(body, message):\n            received_messages.append(body)\n            message.ack()\n\n        with connection as conn:\n            with conn.channel() as channel:\n                producer = kombu.Producer(channel)\n                ", "suffix": "                ]:\n                    producer.publish(\n                        msg,\n                        retry=True,\n                        exchange=test_queue.exchange,\n                        routing_key=test_queue.routing_key,\n                        declare=[test_queue],\n                        serializer='pickle',\n                        priority=prio\n                    )\n                # Sleep to make sure that queue sorted based on priority\n                sleep(0.5)\n                consumer = kombu.Consumer(\n                    conn, [test_queue], accept=['pickle']\n                )\n                consumer.register_callback(callback)\n                with consumer:\n                    # drain_events() returns just on number in\n                    # Virtual transports\n                    conn.drain_events(timeout=1)\n                    conn.drain_events(timeout=1)\n                # Second message must be received first\n                assert received_messages[0] == {'msg': 'second'}\n                assert received_messages[1] == {'msg': 'first'}", "archive": "celery__kombu-0d3b1e254f9178828f62b7b84f0307882e28e2a0.zip"}
{"id": "eea7c5", "repo": "celery/kombu", "revision": "180aabec1ffc71fd802a28231931ba00bf295df5", "path": "kombu/tests/test_transport_amqplib.py", "modified": ["kombu/tests/test_transport_amqplib.py"], "prefix": "from __future__ import absolute_import\n\nfrom ..transport import amqplib\nfrom ..connection import BrokerConnection\n\nfrom .utils import unittest\n\n\nclass MockConnection(dict):\n\n    def __setattr__(self, key, value):\n        self[key] = value\n\n\nclass Channel(amqplib.Channel):\n    wait_returns =", "suffix": "\n    def _send_method(self, *args, **kwargs):\n        pass\n\n\nclass test_Channel(unittest.TestCase):\n\n    def setUp(self):\n        self.conn = Mock()\n        self.conn.channels = {}\n        self.channel = Channel(self.conn, 0)\n\n    def test_init(self):\n        self.assertFalse(self.channel.no_ack_consumers)\n\n    def test_prepare_message(self):\n        x = self.channel.prepare_message(\"foobar\", 10,\n                \"application/data\", \"utf-8\",\n                properties={})\n        self.assertTrue(x)\n\n    def test_message_to_python(self):\n        message = Mock()\n        message.headers = {}\n        message.properties = {}\n        self.assertTrue(self.channel.message_to_python(message))\n\n    def test_close_resolves_connection_cycle(self):\n        self.assertIsNotNone(self.channel.connection)\n        self.channel.close()\n        self.assertIsNone(self.channel.connection)\n\n    def test_basic_consume_registers_ack_status(self):\n        self.channel.wait_returns = \"my-consumer-tag\"\n        self.channel.basic_consume(\"foo\", no_ack=True)\n        self.assertIn(\"my-consumer-tag\", self.channel.no_ack_consumers)\n\n        self.channel.wait_returns = \"other-consumer-tag\"\n        self.channel.basic_consume(\"bar\", no_ack=False)\n        self.assertNotIn(\"other-consumer-tag\", self.channel.no_ack_consumers)\n\n        self.channel.basic_cancel(\"my-consumer-tag\")\n        self.assertNotIn(\"my-consumer-tag\", self.channel.no_ack_consumers)\n\n\nclass test_Transport(unittest.TestCase):\n\n    def setUp(self):\n        self.connection = BrokerConnection(\"amqplib://\")\n        self.transport = self.connection.transport\n\n    def test_create_channel(self):\n        connection = Mock()\n        self.transport.create_channel(connection)\n        connection.channel.assert_called_with()\n\n    def test_drain_events(self):\n        connection = Mock()\n        self.transport.drain_events(connection, timeout=10.0)\n        connection.drain_events.assert_called_with(timeout=10.0)\n\n    def test_dnspython_localhost_resolve_bug(self):\n\n        class Conn(object):\n\n            def __init__(self, **kwargs):\n                vars(self).update(kwargs)\n\n        self.transport.Connection = Conn\n        self.transport.client.hostname = \"localhost\"\n        conn1 = self.transport.establish_connection()\n        self.assertEqual(conn1.host, \"127.0.0.1:5672\")\n\n        self.transport.client.hostname = \"example.com\"\n        conn2 = self.transport.establish_connection()\n        self.assertEqual(conn2.host, \"example.com:5672\")\n\n    def test_close_connection(self):\n        connection = Mock()\n        connection.client = Mock()\n        self.transport.close_connection(connection)\n\n        self.assertIsNone(connection.client)\n        connection.close.assert_called_with()\n\n    def test_verify_connection(self):\n        connection = Mock()\n        connection.channels = None\n        self.assertFalse(self.transport.verify_connection(connection))\n\n        connection.channels = {1: 1, 2: 2}\n        self.assertTrue(self.transport.verify_connection(connection))\n\n    @mask_modules(\"ssl\")\n    def test_import_no_ssl(self):\n        pm = sys.modules.pop(\"kombu.transport.amqplib\")\n        try:\n            from kombu.transport.amqplib import SSLError\n            self.assertEqual(SSLError.__module__, \"kombu.transport.amqplib\")\n        finally:\n            if pm is not None:\n                sys.modules[\"kombu.transport.amqplib\"] = pm\n\n\nclass test_amqplib(unittest.TestCase):\n\n    def test_default_port(self):\n\n        class Transport(amqplib.Transport):\n            Connection = MockConnection\n\n        c = BrokerConnection(port=None, transport=Transport).connect()\n        self.assertEqual(c[\"host\"],\n                         \"127.0.0.1:%s\" % (Transport.default_port, ))\n\n    def test_custom_port(self):\n\n        class Transport(amqplib.Transport):\n            Connection = MockConnection\n\n        c = BrokerConnection(port=1337, transport=Transport).connect()\n        self.assertEqual(c[\"host\"], \"127.0.0.1:1337\")", "archive": "celery__kombu-180aabec1ffc71fd802a28231931ba00bf295df5.zip"}
{"id": "a40931", "repo": "celery/kombu", "revision": "31adb300dc794012c404bf73afaa7ecf66d3d07d", "path": "kombu/utils/compat.py", "modified": ["kombu/transport/__init__.py", "kombu/transport/mongodb.py", "kombu/utils/compat.py", "kombu/utils/eventio.py", "t/unit/utils/test_compat.py"], "prefix": "from __future__ import absolute_import, unicode_literals\n\nimport numbers\nimport sys\n\nfrom functools import wraps\n\nfrom contextlib import contextmanager\n\nfrom kombu.five import reraise\n\ntry:\n    from io import UnsupportedOperation\n    FILENO_ERRORS = (AttributeError, ValueError, UnsupportedOperation)\nexcept ImportError:  # pragma: no cover\n    # Py2\n    FILENO_ERRORS = (AttributeError, ValueError)  # noqa\n\ntry:\n    from billiard.util import register_after_fork\nexcept ImportError:  # pragma: no cover\n    try:\n        from multiprocessing.util import register_after_fork  # noqa\n    except ImportError:\n        register_after_fork = None  # noqa\n\n\ndef coro(gen):\n\n    @wraps(gen)\n    def wind_up(*args, **kwargs):\n        it = gen(*args, **kwargs)\n        next(it)\n        return it\n    return wind_up\n\n\ndef _detect_environment():\n    # ## -eventlet-\n    if 'eventlet' in sys.modules:\n        ", "suffix": "\n    # ## -gevent-\n    if 'gevent' in sys.modules:\n        try:\n            from gevent import socket as _gsocket\n            import socket\n\n            if socket.socket is _gsocket.socket:\n                return 'gevent'\n        except ImportError:\n            pass\n\n    return 'default'\n\n\ndef detect_environment():\n    global _environment\n    if _environment is None:\n        _environment = _detect_environment()\n    return _environment\n\ndef entrypoints(namespace):\n    try:\n        from pkg_resources import iter_entry_points\n    except ImportError:\n        return iter([])\n    return ((ep, ep.load()) for ep in iter_entry_points(namespace))\n\n\ndef fileno(f):\n    if isinstance(f, numbers.Integral):\n        return f\n    return f.fileno()\n\n\ndef maybe_fileno(f):\n    \"\"\"Get object fileno, or :const:`None` if not defined.\"\"\"\n    try:\n        return fileno(f)\n    except FILENO_ERRORS:\n        pass\n\n\n@contextmanager\ndef nested(*managers):  # pragma: no cover\n    # flake8: noqa\n    \"\"\"Combine multiple context managers into a single nested\n    context manager.\"\"\"\n    exits = []\n    vars = []\n    exc = (None, None, None)\n    try:\n        try:\n            for mgr in managers:\n                exit = mgr.__exit__\n                enter = mgr.__enter__\n                vars.append(enter())\n                exits.append(exit)\n            yield vars\n        except:\n            exc = sys.exc_info()\n        finally:\n            while exits:\n                exit = exits.pop()\n                try:\n                    if exit(*exc):\n                        exc = (None, None, None)\n                except:\n                    exc = sys.exc_info()\n            if exc != (None, None, None):\n                # Don't rely on sys.exc_info() still containing\n                # the right information.  Another exception may\n                # have been raised and caught by an exit method\n                reraise(exc[0], exc[1], exc[2])\n    finally:\n        del(exc)", "archive": "celery__kombu-31adb300dc794012c404bf73afaa7ecf66d3d07d.zip"}
{"id": "3d9507", "repo": "celery/kombu", "revision": "333dfa3cd010a164df89cf0685da1ea5ad657f0c", "path": "kombu/clocks.py", "modified": ["kombu/clocks.py"], "prefix": "\"\"\"\nkombu.clocks\n============\n\nLogical Clocks and Synchronization.\n\n:copyright: (c) 2009 - 2012 by Ask Solem.\n:license: BSD, see LICENSE for more details.\n\n\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import with_statement\n\nimport threading\n\n__all__ = ['LamportClock']\n\n\nclass LamportClock(object):\n    \"\"\"Lamport's logical clock.\n\n    From Wikipedia:\n\n    A Lamport logical clock is a monotonically incrementing software counter\n    maintained in each process.  It follows some simple rules:\n\n        * A process increments its counter before each event in that process;\n        * When a process sends a message, it includes its counter value with\n          the message;\n        * On receiving a message, the receiver process sets its counter to be\n          greater than the maximum of its own value and the received value\n          before it considers the message received.\n\n    Conceptually, this logical clock can be thought of as a clock that only\n    has meaning in relation to messages moving between processes.  When a\n    process receives a message, it resynchronizes its logical clock with\n    the sender.\n\n    .. seealso::\n\n        * `Lamport timestamps`_\n\n        * `Lamports distributed mutex`_\n\n    .. _`Lamport Timestamps`: http://en.wikipedia.org/wiki/Lamport_timestamps\n    .. _`Lamports distributed mutex`: http://bit.ly/p99ybE\n\n    *Usage*\n\n    When sending a message use :meth:`forward` to increment the clock,\n    when receiving a message use :meth:`adjust` to sync with\n    the time stamp of the incoming message.\n\n    \"\"\"\n    #: The clocks current value.\n    value = 0\n\n    def __init__(self, initial_value=0):\n        self.value = initial_value\n        self.mutex = threading.Lock()\n\n    def adjust(self, other):\n        with self.mutex:\n            self.value = max(self.value, other) + 1\n\n    def forward(self):\n        with self.mutex:\n            self.value += 1\n            return self.value\n\n    def sort(self, d):\n        return d[sorted(d)[0]]\n\n    def sort_heap(self, h):\n        \"\"\"List of tuples containing at least two elements, representing\n        an event, where the first element is the event's scalar clock value,\n        and the second element is the id of the process (usually\n        ``\"hostname:pid\"``): ``sh([(clock, processid, ...?), (...)])``\n\n        The list must already be sorted, which is why we refer to it as a\n        heap.\n\n        The tuple will not be unpacked, so more than two elements can be\n        present.  Returns the latest event.\n\n        \"\"\"\n        if h[0][0] == h[1][0]:\n            same = []\n            for i, PN in izip(h, islice(h, 1, None)):\n                if PN[0][0] != pn[1][0]:\n                    break  # Prev and Next's clocks differ\n                same.append(pn[0])\n            # return first item sorted by process id\n            return sorted(same, key=lambda event: event[1])[0]\n        # all clock values unique, return first item\n        return h[0]\n\n    def _sort_same_heap(sel", "suffix": "\n    def __str__(self):\n        return str(self.value)\n\n    def __repr__(self):\n        return '<LamportClock: %r>' % (self.value, )", "archive": "celery__kombu-333dfa3cd010a164df89cf0685da1ea5ad657f0c.zip"}
{"id": "ea43df", "repo": "celery/kombu", "revision": "75d781ef6164f620f4d87c01ab7b6a79c16b6cc7", "path": "kombu/transport/mongodb.py", "modified": ["kombu/transport/mongodb.py"], "prefix": "\"\"\"\nkombu.transport.mongodb\n=======================\n\nMongoDB transport.\n\n:copyright: (c) 2010 - 2012 by Flavio Percoco Premoli.\n:license: BSD, see LICENSE for more details.\n\n\"\"\"\nfrom __future__ import absolute_import\n\nfrom Queue import Empty\n\nimport pymongo\nfrom pymongo import errors\nfrom anyjson import loads, dumps\nfrom pymongo.connection import Connection\n\nfrom . import virtual\n\nDEFAULT_HOST = \"127.0.0.1\"\nDEFAULT_PORT = 27017\n\n__author__ = \"Flavio [FlaPer87] Percoco Premoli <flaper87@flaper87.org>\"\n\n\nclass Channel(virtual.Channel):\n    _client = None\n\n    def _new_queue(self, queue, **kwargs):\n        pass\n\n    def _get(self, queue):\n        try:\n            msg = self.client.database.command(\"findandmodify\", \"messages\",\n                    query={\"queue\": queue},\n                    sort={\"_id\": pymongo.ASCENDING}, remove=True)\n        except errors.OperationFailure, exc:\n            if \"No matching object found\" in exc.args[0]:\n                raise Empty()\n            raise\n        # as of mongo 2.0 empty results won't raise an error\n        if msg['value'] is None:\n            raise Empty()\n        return loads(msg[\"value\"][\"payload\"])\n\n    def _size(self, queue):\n        return self.client.find({\"queue\": queue}).count()\n\n    def _put(self, queue, message, **kwargs):\n        self.client.insert({\"payload\": dumps(message), \"queue\": queue})\n\n    def _purge(self, queue):\n        size = self._size(queue)\n        self.client.remove({\"queue\": queue})\n        return size\n\n    def close(self):\n        super(Channel, self).close()\n        if self._client:\n            self._client.database.connection.end_request()\n\n    def _open(self):\n        conninfo = self.connection.client\n        mongoconn = Connection(host=conninfo.hostname, port=conninfo.port)\n        dbname = conninfo.virtual_host\n        version = mongoconn.server_info()[\"version\"]\n        if tuple(map(int, version.split(\".\")[:2])) < (1, 3):\n            raise NotImplementedError(\n                \"Kombu requires MongoDB version 1.3+, but connected to %s\" % (\n                    version, ))\n        if not dbname or dbname == \"/\":\n            dbname = \"kombu_default\"\n        database = getattr(mongoconn, dbname)\n        if conninfo.userid:\n            database.authenticate(conninfo.userid, conninfo.password)\n        col = database.messages\n        col.ensure_index([(\"queue\", 1)])\n        return col\n        \n    def get_table(self, exchange):\n        \"\"\"Get table of bindings for `exchange`.\"\"\"\n        brokerRoutes = self.routing.find({\"exchange\":exchange})\n\n        localRoutes = self.state.exchanges[exchange][\"table\"]\n        for route in brokerRoutes:\n            localRoutes.append((route[\"routing_key\"], route[\"pattern\"], route[\"queue\"]))\n        return set(localRoutes)\n    \n    def ", "suffix": "        \n    def _queue_bind(self, exchange, routing_key, pattern, queue):\n        if self.typeof(exchange).type == \"fanout\":\n            cursor = self.bcast.find(query={\"queue\":exchange}, sort=[(\"$natural\", 1)], tailable=True)\n            # Fast forward the cursor past old events\n            self._queue_cursors[queue] = cursor.skip(cursor.count())\n            self._fanout_queues[queue] = exchange\n            \n        meta = dict(exchange=exchange, queue=queue, routing_key=routing_key, pattern=pattern)\n        self.routing.update(meta, meta, upsert=True)\n        \n        \n    def queue_delete(self, queue, if_unusued=False, if_empty=False, **kwargs):\n        self.routing.remove({\"queue\":queue})\n        super(Channel, self).queue_delete(queue, if_unusued, if_empty, **kwargs)\n        if queue in self._fanout_queues:\n            self._queue_cursors[queue].close()\n            del self._queue_cursors[queue]\n            del self._fanout_queues[queue]\n        \n\n    @property\n    def client(self):\n        if self._client is None:\n            self._client = self._open()\n        return self._client\n\n\nclass Transport(virtual.Transport):\n    Channel = Channel\n\n    polling_interval = 1\n    default_port = DEFAULT_PORT\n    connection_errors = (errors.ConnectionFailure, )\n    channel_errors = (errors.ConnectionFailure,\n                      errors.OperationFailure, )", "archive": "celery__kombu-75d781ef6164f620f4d87c01ab7b6a79c16b6cc7.zip"}
{"id": "6d6e17", "repo": "celery/kombu", "revision": "7ccec0b5369f94c51bdf487ac274a68c4b9bdfb9", "path": "kombu/tests/utils/test_json.py", "modified": ["kombu/tests/utils/test_json.py", "kombu/utils/json.py"], "prefix": "from __future__ import absolute_import, unicode_literals\n\nfrom kombu.utils.encoding import str_to_bytes\nfrom kombu.utils.json import _DecodeError, dumps, loads\n\nfrom kombu.tests.case import Case, MagicMock, Mock, skip\n\n\nclass Custom(object):\n\n    def __init__(self, data):\n        self.data = data\n\n    def __json__(self):\n        return self.data\n\n\nclass test_JSONEncoder(Case):\n\n    def test_datetime(self):\n        now = datetime.utcnow()\n        ", "suffix": "        ))\n        self.assertDictEqual(serialized, {\n            'datetime': now.isoformat(),\n            'tz': '{0}Z'.format(now_utc.isoformat().split('+', 1)[0]),\n            'time': now.time().isoformat(),\n            'date': stripped.isoformat(),\n        })\n\n    def test_Decimal(self):\n        d = Decimal('3314132.13363235235324234123213213214134')\n        self.assertDictEqual(loads(dumps({'d': d})), {\n            'd': text_t(d),\n        })\n\n    def test_UUID(self):\n        id = uuid4()\n        self.assertDictEqual(loads(dumps({'u': id})), {\n            'u': text_t(id),\n        })\n\n    def test_default(self):\n        with self.assertRaises(TypeError):\n            dumps({'o': object()})\n\n\nclass test_dumps_loads(Case):\n\n    def test_dumps_custom_object(self):\n        x = {'foo': Custom({'a': 'b'})}\n        self.assertEqual(loads(dumps(x)), {'foo': x['foo'].__json__()})\n\n    def test_dumps_custom_object_no_json(self):\n        x = {'foo': object()}\n        with self.assertRaises(TypeError):\n            dumps(x)\n\n    def test_loads_memoryview(self):\n        self.assertEqual(\n            loads(memoryview(bytearray(dumps({'x': 'z'}), encoding='utf-8'))),\n            {'x': 'z'},\n        )\n\n    def test_loads_bytearray(self):\n        self.assertEqual(\n            loads(bytearray(dumps({'x': 'z'}), encoding='utf-8')),\n            {'x': 'z'})\n\n    def test_loads_bytes(self):\n        self.assertEqual(\n            loads(str_to_bytes(dumps({'x': 'z'})), decode_bytes=True),\n            {'x': 'z'},\n        )\n\n    @skip.if_python3()\n    def test_loads_buffer(self):\n        self.assertEqual(loads(buffer(dumps({'x': 'z'}))), {'x': 'z'})\n\n    def test_loads_DecodeError(self):\n        _loads = Mock(name='_loads')\n        _loads.side_effect = _DecodeError(\n            MagicMock(), MagicMock(), MagicMock())\n        self.assertEqual(loads(dumps({'x': 'z'}), _loads=_loads), {'x': 'z'})", "archive": "celery__kombu-7ccec0b5369f94c51bdf487ac274a68c4b9bdfb9.zip"}
{"id": "7ac514", "repo": "celery/kombu", "revision": "7f9674419b585921b1da4ecbd5f3dc203891955e", "path": "kombu/tests/transport/test_sqlalchemy.py", "modified": ["kombu/tests/transport/test_sqlalchemy.py", "kombu/transport/sqlalchemy/__init__.py", "kombu/transport/sqlalchemy/models.py"], "prefix": "from __future__ import absolute_import\nfrom __future__ import with_statement\n\nfrom mock import patch\nfrom nose import SkipTest\n\nfrom kombu import Connection\nfrom kombu.tests.utils import TestCase\n\n\nclass test_sqlalchemy(TestCase):\n\n    def setUp(self):\n        try:\n            import sqlalchemy  # noqa\n        except ImportError:\n            raise SkipTest('sqlalchemy not installed')\n\n    def test_url_parser(self):\n        with patch('kombu.transport.sqlalchemy.Channel._open'):\n            url = 'sqlalchemy+sqlite:///celerydb.sqlite'\n            Connection(url).connect()\n\n            url = 'sqla+sqlite:///celerydb.sqlite'\n            Connection(url).connect()\n\n            # Should prevent regression fixed by f187ccd\n            url = 'sqlb+sqlite:///celerydb.sqlite'\n            with self.assertRaises(KeyError):\n                Connection(url).connect()\n\n    def test_simple_queueing(self):\n        conn = Connection('sqlalchemy+sqlite:///:memory:')\n        conn.connect()\n        channel = conn.channel()\n        self.assertEqual(\n            channel.queue_cls.__table__.name,\n            'kombu_queue'\n        ", "suffix": "\n    def test_custom_table_names(self):\n        conn = Connection('sqlalchemy+sqlite:///:memory:', transport_options={\n            'queue_tablename': 'my_custom_queue',\n            'message_tablename': 'my_custom_message'\n        })\n        conn.connect()\n        channel = conn.channel()\n        self.assertEqual(\n            channel.queue_cls.__table__.name,\n            'my_custom_queue'\n        )\n        self.assertEqual(\n            channel.message_cls.__table__.name,\n            'my_custom_message'\n        )\n        channel._put('celery', 'DATA')\n        assert channel._get('celery') == 'DATA'\n\n    def test_clone(self):\n        hostname = 'sqlite:///celerydb.sqlite'\n        x = Connection('+'.join(['sqla', hostname]))\n        self.assertEqual(x.uri_prefix, 'sqla')\n        self.assertEqual(x.hostname, hostname)\n        clone = x.clone()\n        self.assertEqual(clone.hostname, hostname)\n        self.assertEqual(clone.uri_prefix, 'sqla')", "archive": "celery__kombu-7f9674419b585921b1da4ecbd5f3dc203891955e.zip"}
{"id": "605359", "repo": "celery/kombu", "revision": "844d8d0673b8fa91303ee3b1700f93422afbc6ba", "path": "kombu/utils/url.py", "modified": ["kombu/utils/url.py", "t/unit/utils/test_url.py"], "prefix": "\"\"\"URL Utilities.\"\"\"\n# flake8: noqa\n\nfrom __future__ import absolute_import, unicode_literals\n\ntry:\n    from collections.abc import Mapping\nexcept ImportError:\n    from collections import Mapping\n\nfrom functools import partial\n\ntry:\n    from urllib.parse import parse_qsl, quote, unquote, urlparse\nexcept ImportError:\n    from urllib import quote, unquote                  # noqa\n    from urlparse import urlparse, parse_qsl    # noqa\n\nfrom kombu.five import bytes_if_py2, string_t\n\nfrom .compat import NamedTuple\n\nsafequote = partial(quote, safe=bytes_if_py2(''))\n\n\nurlparts = NamedTuple('urlparts', [\n    ('scheme', str),\n    ('hostname', str),\n    ('port', int),\n    ('username', str),\n    ('password', str),\n    ('path', str),\n    ('query', Mapping),\n])\n\n\ndef parse_url(url):\n    # type: (str) -> Dict\n    \"\"\"Parse URL into mapping of components.\"\"\"\n    scheme, host, port, user, password, path, query = _parse_url(url)\n    if query:\n        keys = [key for key in query.keys() if key.startswith('ssl_')]\n        for key in keys:\n            if key == 'ssl_cert_reqs':\n                if ssl_available:\n                    query[key] = getattr(ssl, query[key])\n                else:\n                    ", "suffix": "\n            if 'ssl' not in query:\n                query['ssl'] = {}\n\n            query['ssl'][key] = query[key]\n            del query[key]\n\n    return dict(transport=scheme, hostname=host,\n                port=port, userid=user,\n                password=password, virtual_host=path, **query)\n\n\ndef url_to_parts(url):\n    # type: (str) -> urlparts\n    \"\"\"Parse URL into :class:`urlparts` tuple of components.\"\"\"\n    scheme = urlparse(url).scheme\n    schemeless = url[len(scheme) + 3:]\n    # parse with HTTP URL semantics\n    parts = urlparse('http://' + schemeless)\n    path = parts.path or ''\n    path = path[1:] if path and path[0] == '/' else path\n    return urlparts(\n        scheme,\n        unquote(parts.hostname or '') or None,\n        parts.port,\n        unquote(parts.username or '') or None,\n        unquote(parts.password or '') or None,\n        unquote(path or '') or None,\n        dict(parse_qsl(parts.query)),\n    )\n_parse_url = url_to_parts  # noqa\n\n\ndef as_url(scheme, host=None, port=None, user=None, password=None,\n           path=None, query=None, sanitize=False, mask='**'):\n    # type: (str, str, int, str, str, str, str, bool, str) -> str\n    \"\"\"Generate URL from component parts.\"\"\"\n    parts = ['{0}://'.format(scheme)]\n    if user or password:\n        if user:\n            parts.append(safequote(user))\n        if password:\n            if sanitize:\n                parts.extend([':', mask] if mask else [':'])\n            else:\n                parts.extend([':', safequote(password)])\n        parts.append('@')\n    parts.append(safequote(host) if host else '')\n    if port:\n        parts.extend([':', port])\n    parts.extend(['/', path])\n    return ''.join(str(part) for part in parts if part)\n\n\ndef sanitize_url(url, mask='**'):\n    # type: (str, str) -> str\n    \"\"\"Return copy of URL with password removed.\"\"\"\n    return as_url(*_parse_url(url), sanitize=True, mask=mask)\n\n\ndef maybe_sanitize_url(url, mask='**'):\n    # type: (Any, str) -> Any\n    \"\"\"Sanitize url, or do nothing if url undefined.\"\"\"\n    if isinstance(url, string_t) and '://' in url:\n        return sanitize_url(url, mask)\n    return url", "archive": "celery__kombu-844d8d0673b8fa91303ee3b1700f93422afbc6ba.zip"}
{"id": "f061ee", "repo": "celery/kombu", "revision": "8ddfb92557b00e4be2ef913ff47ce9ebc0837878", "path": "kombu/tests/test_pidbox.py", "modified": ["kombu/common.py", "kombu/entity.py", "kombu/mixins.py", "kombu/pidbox.py", "kombu/serialization.py", "kombu/tests/test_compat.py", "kombu/tests/test_connection.py", "kombu/tests/test_pidbox.py", "kombu/tests/test_pools.py", "kombu/tests/test_serialization.py", "kombu/tests/transport/test_base.py", "kombu/tests/transport/test_redis.py", "kombu/tests/transport/test_transport.py", "kombu/transport/__init__.py", "kombu/transport/redis.py"], "prefix": "from __future__ import absolute_import\n\nimport socket\n\nfrom kombu import Connection\nfrom kombu import pidbox\nfrom kombu.utils import uuid\n\nfrom .case import Case, Mock\n\n\nclass test_Mailbox(Case):\n\n    def _handler(self, state):\n        return self.stats['var']\n\n    def setUp(self):\n\n        class Mailbox(pidbox.Mailbox):\n\n            def _collect(self, *args, **kwargs):\n                return 'COLLECTED'\n\n        self.mailbox = Mailbox('test_pidbox')\n        self.connection = Connection(transport='memory')\n        self.state = {'var': 1}\n        self.handlers = {'mymethod': self._handler}\n        self.bound = self.mailbox(self.connection)\n        self.default_chan = self.connection.channel()\n        self.node = self.bound.Node(\n            'test_pidbox',\n            state=self.state, handlers=self.handlers,\n            channel=self.default_chan,\n        )\n\n    def ", "suffix": "\n    def test_reply__collect(self):\n        mailbox = pidbox.Mailbox('test_reply__collect')(self.connection)\n        exchange = mailbox.reply_exchange.name\n        channel = self.connection.channel()\n        mailbox.reply_queue(channel).declare()\n\n        ticket = uuid()\n        mailbox._publish_reply({'foo': 'bar'}, exchange, mailbox.oid, ticket)\n        _callback_called = [False]\n\n        def callback(body):\n            _callback_called[0] = True\n\n        reply = mailbox._collect(ticket, limit=1,\n                                 callback=callback, channel=channel)\n        self.assertEqual(reply, [{'foo': 'bar'}])\n        self.assertTrue(_callback_called[0])\n\n        ticket = uuid()\n        mailbox._publish_reply({'biz': 'boz'}, exchange, mailbox.oid, ticket)\n        reply = mailbox._collect(ticket, limit=1, channel=channel)\n        self.assertEqual(reply, [{'biz': 'boz'}])\n\n        de = mailbox.connection.drain_events = Mock()\n        de.side_effect = socket.timeout\n        mailbox._collect(ticket, limit=1, channel=channel)\n\n    def test_constructor(self):\n        self.assertIsNone(self.mailbox.connection)\n        self.assertTrue(self.mailbox.exchange.name)\n        self.assertTrue(self.mailbox.reply_exchange.name)\n\n    def test_bound(self):\n        bound = self.mailbox(self.connection)\n        self.assertIs(bound.connection, self.connection)\n\n    def test_Node(self):\n        self.assertTrue(self.node.hostname)\n        self.assertTrue(self.node.state)\n        self.assertIs(self.node.mailbox, self.bound)\n        self.assertTrue(self.handlers)\n\n        # No initial handlers\n        node2 = self.bound.Node('test_pidbox2', state=self.state)\n        self.assertDictEqual(node2.handlers, {})\n\n    def test_Node_consumer(self):\n        consumer1 = self.node.Consumer()\n        self.assertIs(consumer1.channel, self.default_chan)\n        self.assertTrue(consumer1.no_ack)\n\n        chan2 = self.connection.channel()\n        consumer2 = self.node.Consumer(channel=chan2, no_ack=False)\n        self.assertIs(consumer2.channel, chan2)\n        self.assertFalse(consumer2.no_ack)\n\n    def test_handler(self):\n        node = self.bound.Node('test_handler', state=self.state)\n\n        @node.handler\n        def my_handler_name(state):\n            return 42\n\n        self.assertIn('my_handler_name', node.handlers)\n\n    def test_dispatch(self):\n        node = self.bound.Node('test_dispatch', state=self.state)\n\n        @node.handler\n        def my_handler_name(state, x=None, y=None):\n            return x + y\n\n        self.assertEqual(node.dispatch('my_handler_name',\n                                       arguments={'x': 10, 'y': 10}), 20)\n\n    def test_dispatch_raising_SystemExit(self):\n        node = self.bound.Node('test_dispatch_raising_SystemExit',\n                               state=self.state)\n\n        @node.handler\n        def my_handler_name(state):\n            raise SystemExit\n\n        with self.assertRaises(SystemExit):\n            node.dispatch('my_handler_name')\n\n    def test_dispatch_raising(self):\n        node = self.bound.Node('test_dispatch_raising', state=self.state)\n\n        @node.handler\n        def my_handler_name(state):\n            raise KeyError('foo')\n\n        res = node.dispatch('my_handler_name')\n        self.assertIn('error', res)\n        self.assertIn('KeyError', res['error'])\n\n    def test_dispatch_replies(self):\n        _replied = [False]\n\n        def reply(data, **options):\n            _replied[0] = True\n\n        node = self.bound.Node('test_dispatch', state=self.state)\n        node.reply = reply\n\n        @node.handler\n        def my_handler_name(state, x=None, y=None):\n            return x + y\n\n        node.dispatch('my_handler_name',\n                      arguments={'x': 10, 'y': 10},\n                      reply_to={'exchange': 'foo', 'routing_key': 'bar'})\n        self.assertTrue(_replied[0])\n\n    def test_reply(self):\n        _replied = [(None, None, None)]\n\n        def publish_reply(data, exchange, routing_key, ticket, **kwargs):\n            _replied[0] = (data, exchange, routing_key, ticket)\n\n        mailbox = self.mailbox(self.connection)\n        mailbox._publish_reply = publish_reply\n        node = mailbox.Node('test_reply')\n\n        @node.handler\n        def my_handler_name(state):\n            return 42\n\n        node.dispatch('my_handler_name',\n                      reply_to={'exchange': 'exchange',\n                                'routing_key': 'rkey'},\n                      ticket='TICKET')\n        data, exchange, routing_key, ticket = _replied[0]\n        self.assertEqual(data, {'test_reply': 42})\n        self.assertEqual(exchange, 'exchange')\n        self.assertEqual(routing_key, 'rkey')\n        self.assertEqual(ticket, 'TICKET')\n\n    def test_handle_message(self):\n        node = self.bound.Node('test_dispatch_from_message')\n\n        @node.handler\n        def my_handler_name(state, x=None, y=None):\n            return x * y\n\n        body = {'method': 'my_handler_name',\n                'arguments': {'x': 64, 'y': 64}}\n\n        self.assertEqual(node.handle_message(body, None), 64 * 64)\n\n        # message not for me should not be processed.\n        body['destination'] = ['some_other_node']\n        self.assertIsNone(node.handle_message(body, None))\n\n    def test_listen(self):\n        consumer = self.node.listen()\n        self.assertEqual(consumer.callbacks[0],\n                         self.node.handle_message)\n        self.assertEqual(consumer.channel, self.default_chan)\n\n    def test_cast(self):\n        self.bound.cast(['somenode'], 'mymethod')\n        consumer = self.node.Consumer()\n        self.assertIsCast(self.get_next(consumer))\n\n    def test_abcast(self):\n        self.bound.abcast('mymethod')\n        consumer = self.node.Consumer()\n        self.assertIsCast(self.get_next(consumer))\n\n    def test_call_destination_must_be_sequence(self):\n        with self.assertRaises(ValueError):\n            self.bound.call('some_node', 'mymethod')\n\n    def test_call(self):\n        self.assertEqual(\n            self.bound.call(['some_node'], 'mymethod'),\n            'COLLECTED',\n        )\n        consumer = self.node.Consumer()\n        self.assertIsCall(self.get_next(consumer))\n\n    def test_multi_call(self):\n        self.assertEqual(self.bound.multi_call('mymethod'), 'COLLECTED')\n        consumer = self.node.Consumer()\n        self.assertIsCall(self.get_next(consumer))\n\n    def get_next(self, consumer):\n        m = consumer.queues[0].get()\n        if m:\n            return m.payload\n\n    def assertIsCast(self, message):\n        self.assertTrue(message['method'])\n\n    def assertIsCall(self, message):\n        self.assertTrue(message['method'])\n        self.assertTrue(message['reply_to'])", "archive": "celery__kombu-8ddfb92557b00e4be2ef913ff47ce9ebc0837878.zip"}
{"id": "46eec8", "repo": "celery/kombu", "revision": "b304f93ccbea54ea2e9c8c4dccfe3bf8b9256b88", "path": "kombu/tests/test_serialization.py", "modified": ["kombu/messaging.py", "kombu/serialization.py", "kombu/tests/test_compression.py", "kombu/tests/test_entities.py", "kombu/tests/test_messaging.py", "kombu/tests/test_pidbox.py", "kombu/tests/test_serialization.py", "kombu/tests/test_simple.py", "kombu/tests/test_transport_redis.py", "kombu/tests/test_utils.py", "kombu/utils/__init__.py"], "prefix": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import with_statement\n\nimport sys\n\nfrom ..serialization import (registry, register, SerializerNotInstalled,\n                             raw_encode, register_yaml, register_msgpack,\n                             decode, bytes_type, pickle,\n                             unregister, register_pickle)\n\nfrom .utils import unittest\nfrom .utils import mask_modules, skip_if_not_module\n\n# For content_encoding tests\nunicode_string = u'abcd\u00e9\\u8463'\nunicode_string_as_utf8 = unicode_string.encode('utf-8')\nlatin_string = u'abcd\u00e9'\nlatin_string_as_latin1 = latin_string.encode('latin-1')\nlatin_string_as_utf8 = latin_string.encode('utf-8')\n\n\n# For serialization tests\npy_data = {\"string\": \"The quick brown fox jumps over the lazy dog\",\n        \"int\": 10,\n        \"float\": 3.14159265,\n        \"unicode\": u\"Th\u00e9 quick brown fox jumps over th\u00e9 lazy dog\",\n        \"list\": [\"george\", \"jerry\", \"elaine\", \"cosmo\"],\n}\n\n# JSON serialization tests\njson_data = ('{\"int\": 10, \"float\": 3.1415926500000002, '\n             '\"list\": [\"george\", \"jerry\", \"elaine\", \"cosmo\"], '\n             '\"string\": \"The quick brown fox jumps over the lazy '\n             'dog\", \"unicode\": \"Th\\\\u00e9 quick brown fox jumps over '\n             'th\\\\u00e9 lazy dog\"}')\n\n# Pickle serialization tests\npickle_data = pickle.dumps(py_data)\n\n# YAML serialization tests\nyaml_data = ('float: 3.1415926500000002\\nint: 10\\n'\n             'list: [george, jerry, elaine, cosmo]\\n'\n             'string: The quick brown fox jumps over the lazy dog\\n'\n             'unicode: \"Th\\\\xE9 quick brown fox '\n             'jumps over th\\\\xE9 lazy dog\"\\n')\n\n\nmsgpack_py_data = dict(py_data)\n# msgpack only supports tuples\nmsgpack_py_data[\"list\"] = tuple(msgpack_py_data[\"list\"])\n# Unicode chars are lost in transmit :(\nmsgpack_py_data[\"unicode\"] = 'Th quick brown fox jumps over th lazy dog'\nmsgpack_data = ('\\x85\\xa3int\\n\\xa5float\\xcb@\\t!\\xfbS\\xc8\\xd4\\xf1\\xa4list'\n                '\\x94\\xa6george\\xa5jerry\\xa6elaine\\xa5cosmo\\xa6string\\xda'\n                '\\x00+The quick brown fox jumps over the lazy dog\\xa7unicode'\n                '\\xda\\x00)Th quick brown fox jumps over th lazy dog')\n\n\ndef say(m):\n    sys.stderr.write(\"%s\\n\" % (m, ))\n\n\nclass test_Serialization(unittest.TestCase):\n\n    def test_disable(self):\n        disabled = registry._disabled_content_types\n        try:\n            ", "suffix": "\n    def test_decode_when_disabled(self):\n        disabled = registry._disabled_content_types\n        try:\n            registry.disable(\"testS\")\n\n            with self.assertRaises(SerializerNotInstalled):\n                registry.decode(\"xxd\", \"application/testS\", \"utf-8\",\n                                force=False)\n\n            ret = registry.decode(\"xxd\", \"application/testS\", \"utf-8\",\n                            force=True)\n            self.assertEqual(ret, \"decoded\")\n        finally:\n            disabled.clear()\n\n    def test_decode_when_data_is_None(self):\n        registry.decode(None, \"application/testS\", \"utf-8\")\n\n    def test_content_type_decoding(self):\n        self.assertEqual(unicode_string,\n                          registry.decode(\n                              unicode_string_as_utf8,\n                              content_type='plain/text',\n                              content_encoding='utf-8'))\n        self.assertEqual(latin_string,\n                          registry.decode(\n                              latin_string_as_latin1,\n                              content_type='application/data',\n                              content_encoding='latin-1'))\n\n    def test_content_type_binary(self):\n        self.assertIsInstance(registry.decode(unicode_string_as_utf8,\n                                              content_type='application/data',\n                                              content_encoding='binary'),\n                              bytes_type)\n\n        self.assertEqual(unicode_string_as_utf8,\n                          registry.decode(\n                              unicode_string_as_utf8,\n                              content_type='application/data',\n                              content_encoding='binary'))\n\n    def test_content_type_encoding(self):\n        # Using the \"raw\" serializer\n        self.assertEqual(unicode_string_as_utf8,\n                          registry.encode(\n                              unicode_string, serializer=\"raw\")[-1])\n        self.assertEqual(latin_string_as_utf8,\n                          registry.encode(\n                              latin_string, serializer=\"raw\")[-1])\n        # And again w/o a specific serializer to check the\n        # code where we force unicode objects into a string.\n        self.assertEqual(unicode_string_as_utf8,\n                            registry.encode(unicode_string)[-1])\n        self.assertEqual(latin_string_as_utf8,\n                            registry.encode(latin_string)[-1])\n\n    def test_json_decode(self):\n        self.assertEqual(py_data,\n                          registry.decode(\n                              json_data,\n                              content_type='application/json',\n                              content_encoding='utf-8'))\n\n    def test_json_encode(self):\n        self.assertEqual(registry.decode(\n                              registry.encode(py_data, serializer=\"json\")[-1],\n                              content_type='application/json',\n                              content_encoding='utf-8'),\n                          registry.decode(\n                              json_data,\n                              content_type='application/json',\n                              content_encoding='utf-8'))\n\n    @skip_if_not_module('msgpack')\n    def test_msgpack_decode(self):\n        register_msgpack()\n        self.assertEqual(msgpack_py_data,\n                          registry.decode(\n                              msgpack_data,\n                              content_type='application/x-msgpack',\n                              content_encoding='binary'))\n\n    @skip_if_not_module('msgpack')\n    def test_msgpack_encode(self):\n        register_msgpack()\n        self.assertEqual(registry.decode(\n                registry.encode(msgpack_py_data, serializer=\"msgpack\")[-1],\n                content_type='application/x-msgpack',\n                content_encoding='binary'),\n                registry.decode(\n                    msgpack_data,\n                    content_type='application/x-msgpack',\n                    content_encoding='binary'))\n\n    @skip_if_not_module('yaml')\n    def test_yaml_decode(self):\n        register_yaml()\n        self.assertEqual(py_data,\n                          registry.decode(\n                              yaml_data,\n                              content_type='application/x-yaml',\n                              content_encoding='utf-8'))\n\n    @skip_if_not_module('yaml')\n    def test_yaml_encode(self):\n        register_yaml()\n        self.assertEqual(registry.decode(\n                              registry.encode(py_data, serializer=\"yaml\")[-1],\n                              content_type='application/x-yaml',\n                              content_encoding='utf-8'),\n                          registry.decode(\n                              yaml_data,\n                              content_type='application/x-yaml',\n                              content_encoding='utf-8'))\n\n    def test_pickle_decode(self):\n        self.assertEqual(py_data,\n                          registry.decode(\n                              pickle_data,\n                              content_type='application/x-python-serialize',\n                              content_encoding='binary'))\n\n    def test_pickle_encode(self):\n        self.assertEqual(pickle_data,\n                          registry.encode(py_data,\n                              serializer=\"pickle\")[-1])\n\n    def test_register(self):\n        register(None, None, None, None)\n\n    def test_unregister(self):\n        with self.assertRaises(SerializerNotInstalled):\n            unregister(\"nonexisting\")\n        registry.encode(\"foo\", serializer=\"pickle\")\n        unregister(\"pickle\")\n        with self.assertRaises(SerializerNotInstalled):\n            registry.encode(\"foo\", serializer=\"pickle\")\n        register_pickle()\n\n    def test_set_default_serializer_missing(self):\n        with self.assertRaises(SerializerNotInstalled):\n            registry._set_default_serializer(\"nonexisting\")\n\n    def test_encode_missing(self):\n        with self.assertRaises(SerializerNotInstalled):\n            registry.encode(\"foo\", serializer=\"nonexisting\")\n\n    def test_raw_encode(self):\n        self.assertTupleEqual(raw_encode(\"foo\".encode(\"utf-8\")),\n                              (\"application/data\", \"binary\",\n                                  \"foo\".encode(\"utf-8\")))\n\n    @mask_modules(\"yaml\")\n    def test_register_yaml__no_yaml(self):\n        register_yaml()\n        with self.assertRaises(SerializerNotInstalled):\n            decode(\"foo\", \"application/x-yaml\", \"utf-8\")\n\n    @mask_modules(\"msgpack\")\n    def test_register_msgpack__no_msgpack(self):\n        register_msgpack()\n        with self.assertRaises(SerializerNotInstalled):\n            decode(\"foo\", \"application/x-msgpack\", \"utf-8\")", "archive": "celery__kombu-b304f93ccbea54ea2e9c8c4dccfe3bf8b9256b88.zip"}
{"id": "62346c", "repo": "celery/kombu", "revision": "d570d6a5e213323f940be0e754dfb254a6190c8a", "path": "kombu/pools.py", "modified": ["kombu/__init__.py", "kombu/pools.py"], "prefix": "from kombu.connection import Resource\nfrom kombu.messaging import Producer\n\n\nclass ProducerPool(Resource):\n    Producer = Producer\n\n    def __init__(self, connections, *args, **kwargs):\n        self.connections = connections\n        super(ProducerPool, self).__init__(*args, **kwargs)\n\n    def create_producer(self):\n        conn = self.connections.acquire(block=True)\n        channel = conn.channel()\n        producer = self.Producer(channel)\n        producer.connection = conn\n        conn._producer_chan = channel\n        return producer\n\n    def new(self):\n        return lambda: self.create_producer()\n\n    def setup(self):\n        if self.limit:\n            for _ in xrange(self.limit):\n                self._resource.put_nowait(self.new())\n\n    def prepare(self, p):\n        if callable(p):\n            p = p()\n        if not p.connection:\n            p.connection = self.connections.acquire(block=True)\n            if not getattr(p.connection, \"_producer_chan\", None):\n                p.connection._producer_chan = p.connection.channel()\n            p.revive(p.connection._producer_chan)\n        return p\n\n    def release(self, resource):\n        resource.connection.release()\n        resource.connection = None\n        super(ProducerPool, self).release(resource)\n\n\nclass HashingDict(dict):\n\n    def __getitem__(self, key):\n        h = hash(key)\n        if h not in self:\n            return self.__missing__(key)\n        return dict.__getitem__(self, h)\n\n    d", "suffix": "\n\nclass _Connections(HashingDict):\n\n    def __missing__(self, connection):\n        k = self[connection] = connection.Pool(limit=_limit[0])\n        return k\nconnections = _Connections()\n\n\nclass _Producers(HashingDict):\n\n    def __missing__(self, conn):\n        k = self[conn] = ProducerPool(connections[conn], limit=_limit[0])\n        return k\nproducers = _Producers()\n\n\ndef _all_pools():\n    return chain(connections.itervalues() if connections else iter([]),\n                 producers.itervalues() if producers else iter([]))\n\n\ndef set_limit(limit):\n    _limit[0] = limit\n    for pool in _all_pools():\n        pool.limit = limit\n    return limit\n\n\ndef reset():\n    global connections\n    global producers\n    for pool in _all_pools():\n        try:\n            pool.force_close_all()\n        except Exception:\n            pass\n    connections = _Connections()\n    producers._Producers()\n\n\ntry:\n    from multiprocessing.util import register_after_fork\n    register_after_fork(connections, reset)\nexcept ImportError:\n    pass", "archive": "celery__kombu-d570d6a5e213323f940be0e754dfb254a6190c8a.zip"}
{"id": "027b5d", "repo": "celery/kombu", "revision": "d57dde5631c5c7dd73300a79613975531112aae6", "path": "t/unit/transport/test_filesystem.py", "modified": ["kombu/transport/filesystem.py", "t/unit/transport/test_filesystem.py"], "prefix": "import tempfile\n\nimport pytest\n\nimport t.skip\nfrom kombu import Connection, Consumer, Exchange, Producer, Queue\n\n\n@t.skip.if_win32\nclass test_FilesystemTransport:\n\n    def setup(self):\n        self.channels = set()\n        try:\n            data_folder_in = tempfile.mkdtemp()\n            data_folder_out = tempfile.mkdtemp()\n        except Exception:\n            pytest.skip('filesystem transport: cannot create tempfiles')\n        self.c = Connection(transport='filesystem',\n                            transport_options={\n                                'data_folder_in': data_folder_in,\n                                'data_folder_out': data_folder_out,\n                            })\n        self.channels.add(self.c.default_channel)\n        self.p = Connection(transport='filesystem',\n                            transport_options={\n                                'data_folder_in': data_folder_out,\n                                'data_folder_out': data_folder_in,\n                            })\n        self.channels.add(self.p.default_channel)\n        self.e = Exchange('test_transport_filesystem')\n        self.q = Queue('test_transport_filesystem',\n                       exchange=self.e,\n                       routing_key='test_transport_filesystem')\n        self.q2 = Queue('test_transport_filesystem2',\n                        exchange=self.e,\n                        routing_key='test_transport_filesystem2')\n\n    def teardown(self):\n        # make sure we don't attempt to restore messages at shutdown.\n        for channel in self.channels:\n            try:\n                channel._qos._dirty.clear()\n            except AttributeError:\n                pass\n            try:\n                channel._qos._delivered.clear()\n            except AttributeError:\n                pass\n\n    def _add_channel(self, channel):\n        self.channels.add(channel)\n        return channel\n\n    def test_produce_consume_noack(self):\n        producer = Producer(self._add_channel(self.p.channel()), self.e)\n        consumer = Consumer(self._add_channel(self.c.channel()), self.q,\n                            no_ack=True)\n\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem')\n\n        _received = []\n\n        def callback(message_data, message):\n            _received.append(message)\n\n        consumer.register_callback(callback)\n        consumer.consume()\n\n        while 1:\n            if len(_received) == 10:\n                break\n            self.c.drain_events()\n\n        assert len(_received) == 10\n\n    def test_produce_consume(self):\n        producer_channel = self._add_channel(self.p.channel())\n        consumer_channel = self._add_channel(self.c.channel())\n        producer = Producer(producer_channel, self.e)\n        consumer1 = Consumer(consumer_channel, self.q)\n        consumer2 = Consumer(consumer_channel, self.q2)\n        self.q2(consumer_channel).declare()\n\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem')\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem2')\n\n        _received1 = []\n        _received2 = []\n\n        def callback1(message_data, message):\n            _received1.append(message)\n            message.ack()\n\n        def callback2(message_data, message):\n            _received2.append(message)\n            message.ack()\n\n        consumer1.register_callback(callback1)\n        consumer2.register_callback(callback2)\n\n        consumer1.consume()\n        consumer2.consume()\n\n        while 1:\n            if len(_received1) + len(_received2) == 20:\n                break\n            self.c.drain_events()\n\n        assert len(_received1) + len(_received2) == 20\n\n        # compression\n        producer.publish({'compressed': True},\n                         routing_key='test_transport_filesystem',\n                         compression='zlib')\n        m = self.q(consumer_channel).get()\n        assert m.payload == {'compressed': True}\n\n        # queue.delete\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem')\n        assert self.q(consumer_channel).get()\n        self.q(consumer_channel).delete()\n        self.q(consumer_channel).declare()\n        assert self.q(consumer_channel).get() is None\n\n        # queue.purge\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem2')\n        assert self.q2(consumer_channel).get()\n        self.q2(consumer_channel).purge()\n        assert self.q2(consumer_channel).get() is None\n\n\n@t.skip.if_win32\nclass test_FilesystemFanout:\n    def setup(self):\n        try:\n            ", "suffix": "\n        self.consumer_connection = Connection(\n            transport=\"filesystem\",\n            transport_options={\n                \"data_folder_in\": data_folder_in,\n                \"data_folder_out\": data_folder_out,\n                \"control_folder\": control_folder,\n            },\n        )\n        self.consume_channel = self.consumer_connection.channel()\n        self.produce_connection = Connection(\n            transport=\"filesystem\",\n            transport_options={\n                \"data_folder_in\": data_folder_out,\n                \"data_folder_out\": data_folder_in,\n                \"control_folder\": control_folder,\n            },\n        )\n        self.producer_channel = self.produce_connection.channel()\n        self.exchange = Exchange(\"filesystem_exchange_fanout\", type=\"fanout\")\n        self.q1 = Queue(\"queue1\", exchange=self.exchange)\n        self.q2 = Queue(\"queue2\", exchange=self.exchange)\n\n    def teardown(self):\n        # make sure we don't attempt to restore messages at shutdown.\n        for channel in [self.producer_channel, self.consumer_connection]:\n            try:\n                channel._qos._dirty.clear()\n            except AttributeError:\n                pass\n            try:\n                channel._qos._delivered.clear()\n            except AttributeError:\n                pass\n\n    def test_produce_consume(self):\n\n        producer = Producer(self.producer_channel, self.exchange)\n        consumer1 = Consumer(self.consume_channel, self.q1)\n        consumer2 = Consumer(self.consume_channel, self.q2)\n        self.q2(self.consume_channel).declare()\n\n        for i in range(10):\n            producer.publish({\"foo\": i})\n\n        _received1 = []\n        _received2 = []\n\n        def callback1(message_data, message):\n            _received1.append(message)\n            message.ack()\n\n        def callback2(message_data, message):\n            _received2.append(message)\n            message.ack()\n\n        consumer1.register_callback(callback1)\n        consumer2.register_callback(callback2)\n\n        consumer1.consume()\n        consumer2.consume()\n\n        while 1:\n            try:\n                self.consume_channel.drain_events()\n            except Empty:\n                break\n\n        assert len(_received1) + len(_received2) == 20\n\n        # queue.delete\n        for i in range(10):\n            producer.publish({\"foo\": i})\n        assert self.q1(self.consume_channel).get()\n        self.q1(self.consume_channel).delete()\n        self.q1(self.consume_channel).declare()\n        assert self.q1(self.consume_channel).get() is None\n\n        # queue.purge\n        assert self.q2(self.consume_channel).get()\n        self.q2(self.consume_channel).purge()\n        assert self.q2(self.consume_channel).get() is None", "archive": "celery__kombu-d57dde5631c5c7dd73300a79613975531112aae6.zip"}
{"id": "5acca7", "repo": "celery/kombu", "revision": "da0972ec2003a5c9d59f39216ce4445a66a9708d", "path": "kombu/transport/pyredis.py", "modified": ["kombu/transport/pyredis.py", "kombu/utils/__init__.py"], "prefix": "from Queue import Empty\n\nfrom anyjson import serialize, deserialize\nfrom redis import Redis\nfrom redis import exceptions\n\nfrom kombu.transport import virtual\n\nDEFAULT_PORT = 6379\nDEFAULT_DB = 0\n\n\nclass Channel(virtual.Channel):\n    _client = None\n    supports_fanout = True\n    keyprefix_fanout = \"_kombu.fanout.%s\"\n    keyprefix_queue = \"_kombu.binding.%s\"\n    sep = '\\x06\\x16'\n\n    def _queue_bind(self, exchange, routing_key, pattern, queue):\n        self.client.sadd(self.keyprefix_queue % (exchange, ),\n                         self.sep.join([routing_key or \"\",\n                                        pattern or \"\",\n                                        queue or \"\"]))\n\n    def ", "suffix": "\n    def _new_queue(self, queue, **kwargs):\n        pass\n\n    def _get(self, queue):\n        item = self.client.rpop(queue)\n        if item:\n            return deserialize(item)\n        raise Empty()\n\n    def _size(self, queue):\n        return self.client.llen(queue)\n\n    def _get_many(self, queues, timeout=None):\n        dest__item = self.client.brpop(queues, timeout=timeout)\n        if dest__item:\n            dest, item = dest__item\n            return deserialize(item), dest\n        raise Empty()\n\n    def _put(self, queue, message, **kwargs):\n        self.client.lpush(queue, serialize(message))\n\n    def _purge(self, queue):\n        size = self.client.llen(queue)\n        self.client.delete(queue)\n        return size\n\n    def close(self):\n        super(Channel, self).close()\n        try:\n            self.client.bgsave()\n        except exceptions.ResponseError:\n            pass\n\n    def _open(self):\n        conninfo = self.connection.connection\n        database = conninfo.virtual_host\n        if not isinstance(database, int):\n            if not database or database == \"/\":\n                database = DEFAULT_DB\n            elif database.startswith(\"/\"):\n                database = database[1:]\n            try:\n                database = int(database)\n            except ValueError:\n                raise ValueError(\n                    \"Database name must be int between 0 and limit - 1\")\n\n        return Redis(host=conninfo.hostname,\n                     port=conninfo.port or DEFAULT_PORT,\n                     db=database,\n                     password=conninfo.password)\n\n    @property\n    def client(self):\n        if self._client is None:\n            self._client = self._open()\n        return self._client\n\n\nclass Transport(virtual.Transport):\n    Channel = Channel\n\n    default_port = DEFAULT_PORT\n    connection_errors = (exceptions.ConnectionError,\n                         exceptions.AuthenticationError)\n    channel_errors = (exceptions.ConnectionError,\n                      exceptions.InvalidData,\n                      exceptions.InvalidResponse,\n                      exceptions.ResponseError)", "archive": "celery__kombu-da0972ec2003a5c9d59f39216ce4445a66a9708d.zip"}
{"id": "f36f23", "repo": "celery/kombu", "revision": "ecf1457f138a94ae2fcc9fd769593c0a5581671b", "path": "kombu/transport/base.py", "modified": ["kombu/async/hub.py", "kombu/tests/async/test_hub.py", "kombu/tests/transport/test_librabbitmq.py", "kombu/tests/transport/test_pyamqp.py", "kombu/tests/transport/test_redis.py", "kombu/transport/amqplib.py", "kombu/transport/base.py", "kombu/transport/librabbitmq.py", "kombu/transport/pyamqp.py", "kombu/transport/redis.py"], "prefix": "\"\"\"\nkombu.transport.base\n====================\n\nBase transport interface.\n\n\"\"\"\nfrom __future__ import absolute_import\n\nfrom kombu.exceptions import ChannelError, ConnectionError\nfrom kombu.message import Message\nfrom kombu.utils import cached_property\n\n__all__ = ['Message', 'StdChannel', 'Management', 'Transport']\n\n\ndef _LeftBlank(obj, method):\n    return NotImplementedError(\n        'Transport {0.__module__}.{0.__name__} does not implement {1}'.format(\n            obj.__class__, method))\n\n\nclass StdChannel(object):\n    no_ack_consumers = None\n\n    def Consumer(self, *args, **kwargs):\n        from kombu.messaging import Consumer\n        return Consumer(self, *args, **kwargs)\n\n    def Producer(self, *args, **kwargs):\n        from kombu.messaging import Producer\n        return Producer(self, *args, **kwargs)\n\n    def get_bindings(self):\n        raise _LeftBlank(self, 'get_bindings')\n\n    def after_reply_message_received(self, queue):\n        \"\"\"reply queue semantics: can be used to delete the queue\n           after transient reply message received.\"\"\"\n        pass\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc_info):\n        self.close()\n\n\nclass Management(object):\n\n    def __init__(self, transport):\n        self.transport = transport\n\n    def get_bindings(self):\n        raise _LeftBlank(self, 'get_bindings')\n\n\nclass Transport(object):\n    \"\"\"Base class for transports.\"\"\"\n    Management = Management\n\n    #: The :class:`~kombu.Connection` owning this instance.\n    client = None\n\n    #: Default port used when no port has been specified.\n    default_port = None\n\n    #: Tuple of errors that can happen due to connection failure.\n    connection_errors = (ConnectionError, )\n\n    #: Tuple of errors that can happen due to channel/method failure.\n    channel_errors = (ChannelError, )\n\n    #: For non-blocking use, an eventloop should keep\n    #: draining events as long as ``connection.more_to_read`` is True.\n    nb_keep_draining = False\n\n    #: Type of driver, can be used to separate transports\n    #: using the AMQP protocol (driver_type: 'amqp'),\n    #: Redis (driver_type: 'redis'), etc...\n    driver_type = 'N/A'\n\n    #: Name of driver library (e.g. 'py-amqp', 'redis', 'beanstalkc').\n    driver_name = 'N/A'\n\n    #: Whether this transports support heartbeats,\n    #: and that the :meth:`heartbeat_check` method has any effect.\n    supports_heartbeats = False\n\n    #: Set to true if the transport supports the AIO interface.\n    supports_ev = False\n\n    def __init__(self, client, **kwargs):\n        self.client = client\n\n    def establish_connection(self):\n        raise _LeftBlank(self, 'establish_connection')\n\n    def close_connection(self, connection):\n        raise _LeftBlank(self, 'close_connection')\n\n    def create_channel(self, connection):\n        raise _LeftBlank(self, 'create_channel')\n\n    def close_channel(self, connection):\n        raise _LeftBlank(self, 'close_channel')\n\n    def drain_events(self, connection, **kwargs):\n        raise _LeftBlank(self, 'drain_events')\n\n    def heartbeat_check(self, connection, rate=2):\n        pass\n\n    def driver_version(self):\n        return 'N/A'\n\n    def register_with_event_loop(self, loop):\n        pass\n\n    def verify_connection(self, connection):\n        return True\n\n    def _reader(self, connection, timeout=socket.timeout, error=socket.error,\n                get_errno=get_errno, _unavail=(errno.EAGAIN, errno.EINTR)):\n        drain_events = connection.drain_events\n        while 1:\n            ", "suffix": "\n    def on_readable(self, connection, loop):\n        reader = self.__reader\n        if reader is None:\n            reader = self.__reader = self._reader(connection)\n        try:\n            next(reader)\n        except StopIteration:\n            reader = self.__reader = self._reader(connection)\n            next(reader, None)\n        loop.on_tick.add(reader)\n\n    @property\n    def default_connection_params(self):\n        return {}\n\n    def get_manager(self, *args, **kwargs):\n        return self.Management(self)\n\n    @cached_property\n    def manager(self):\n        return self.get_manager()", "archive": "celery__kombu-ecf1457f138a94ae2fcc9fd769593c0a5581671b.zip"}
{"id": "81fc3b", "repo": "celery/kombu", "revision": "ff64066d4e25d6e8c1e89d145392c129b67823a2", "path": "kombu/__init__.py", "modified": ["kombu/__init__.py"], "prefix": "\"\"\"Messaging Framework for Python\"\"\"\nfrom __future__ import absolute_import\n\nVERSION = (2, 4, 7)\n__version__ = '.'.join(map(str, VERSION[0:3])) + ''.join(VERSION[3:])\n__author__ = 'Ask Solem'\n__contact__ = 'ask@celeryproject.org'\n__homepage__ = 'http://kombu.readthedocs.org'\n__docformat__ = 'restructuredtext en'\n\n# -eof meta-\n\nimport os\nimport sys\n\nif sys.version_info < (2, 5):  # pragma: no cover\n    if sys.version_info >= (2, 4):\n        raise Exception(\n                'Python 2.4 is not supported by this version. '\n                'Please use Kombu versions 1.x.')\n    else:\n        raise Exception('Kombu requires Python versions 2.5 or later.')\n\nSTATICA_HACK = True\nglobals()['kcah_acitats'[::-1].upper()] = False\nif STATICA_HACK:\n    # This is never executed, but tricks static analyzers (PyDev, PyCharm,\n    # pylint, etc.) into knowing the types of these symbols, and what\n    # they contain.\n    ", "suffix": "\n# Lazy loading.\n# - See werkzeug/__init__.py for the rationale behind this.\nfrom types import ModuleType\n\nall_by_module = {\n    'kombu.connection': ['Connection', 'BrokerConnection'],\n    'kombu.entity':     ['Exchange', 'Queue'],\n    'kombu.messaging':  ['Consumer', 'Producer'],\n    'kombu.pools':      ['connections', 'producers'],\n    'kombu.utils.url':  ['parse_url'],\n    'kombu.common':     ['eventloop', 'uuid']\n}\n\nobject_origins = {}\nfor module, items in all_by_module.iteritems():\n    for item in items:\n        object_origins[item] = module\n\n\nclass module(ModuleType):\n\n    def __getattr__(self, name):\n        if name in object_origins:\n            module = __import__(object_origins[name], None, None, [name])\n            for extra_name in all_by_module[module.__name__]:\n                setattr(self, extra_name, getattr(module, extra_name))\n            return getattr(module, name)\n        return ModuleType.__getattribute__(self, name)\n\n    def __dir__(self):\n        result = list(new_module.__all__)\n        result.extend(('__file__', '__path__', '__doc__', '__all__',\n                       '__docformat__', '__name__', '__path__', 'VERSION',\n                       '__package__', '__version__', '__author__',\n                       '__contact__', '__homepage__', '__docformat__'))\n        return result\n\n# 2.5 does not define __package__\ntry:\n    package = __package__\nexcept NameError:\n    package = 'kombu'\n\n# keep a reference to this module so that it's not garbage collected\nold_module = sys.modules[__name__]\n\nnew_module = sys.modules[__name__] = module(__name__)\nnew_module.__dict__.update({\n    '__file__': __file__,\n    '__path__': __path__,\n    '__doc__': __doc__,\n    '__all__': tuple(object_origins),\n    '__version__': __version__,\n    '__author__': __author__,\n    '__contact__': __contact__,\n    '__homepage__': __homepage__,\n    '__docformat__': __docformat__,\n    '__package__': package,\n    'VERSION': VERSION})\n\nif os.environ.get('KOMBU_LOG_DEBUG'):\n    os.environ.update(KOMBU_LOG_CHANNEL='1', KOMBU_LOG_CONNECTION='1')\n    from .utils import debug\n    debug.setup_logging()", "archive": "celery__kombu-ff64066d4e25d6e8c1e89d145392c129b67823a2.zip"}
{"id": "4410b0", "repo": "cool-RR/GarlicSim", "revision": "2526e0259f1ceb855553c6551c7071922019d041", "path": "garlicsim/garlicsim/asynchronous_crunching/crunchers/process_cruncher/__init__.py", "modified": ["garlicsim/garlicsim/asynchronous_crunching/crunchers/__init__.py", "garlicsim/garlicsim/asynchronous_crunching/crunchers/process_cruncher/__init__.py", "garlicsim/garlicsim/asynchronous_crunching/crunchers/process_cruncher/process_cruncher.py"], "prefix": "# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\nThis package defines the `ProcessCruncher` class.\n\nSee its documentation for more information.\n\nThis package requires the `multiprocessing` package to be installed. It is part of\nthe standard library for Python 2.6 and above, but not for earlier versions. A\nbackport of it for Python 2.5 is available at\nhttp://pypi.python.org/pypi/multiprocessing.\n'''\n\nfrom .process_cruncher import ProcessCruncher\n\n\n### Warning if `multiprocessing` isn't installed: #############################\n#                                                                             #\n\nfrom garlicsim.general_misc import import_tools\n\nif not import_tools.", "suffix": "    \ndel import_tools\n\n#                                                                             #\n### Finished warning about `multiprocessing`. #################################", "archive": "cool-RR__GarlicSim-2526e0259f1ceb855553c6551c7071922019d041.zip"}
{"id": "e3e7c9", "repo": "cool-RR/GarlicSim", "revision": "31a3f8f7971d0eec9c5402117415a7f913158a90", "path": "garlicsim/garlicsim/general_misc/sys_tools.py", "modified": ["garlicsim/garlicsim/general_misc/import_tools.py", "garlicsim/garlicsim/general_misc/sys_tools.py", "garlicsim/test_garlicsim/test_doc/test_tutorial_2/test.py"], "prefix": "import os\nimport sys\nimport cStringIO\nimport subprocess\n\nfrom garlicsim.general_misc.temp_value_setters import TempValueSetter\n\n\nclass OutputCapturer(object):\n    '''\n\n    \n    with OutputCapturer as output_capturer:\n        do_stuff()\n    output_capturer.output # <-- String containing all output\n    '''\n    def __init__(self):\n        self.string_io = cStringIO.StringIO()\n        self._temp_stdout_setter = \\\n            TempValueSetter((sys, 'stdout'), self.string_io)\n        self.output = None\n    \n    def __enter__(self):\n        self._temp_stdout_setter.__enter__()\n        return self\n    \n    def __exit__(self, *args, **kwargs):\n        self._temp_stdout_setter.__exit__(*args, **kwargs)\n        self.output = self.string_io.getvalue()\n\nclass TempSysPathAdder(object):\n\n    def __init__(self, addition):\n        if isinstance(addition, basestring):\n            addition = [addition]\n        for entry in addition:\n            assert isinstance(entry, basestring)\n        self.addition = addition\n        \n        #self.string_io = cStringIO.StringIO()\n        #self._temp_stdout_setter = \\\n            #TempValueSetter((sys, 'stdout'), self.string_io)\n        #self.output = None\n\n        \n    ", "suffix": "    \n\n    def __exit__(self, *args, **kwargs):\n        \n        for entry in self.entries_not_in_sys_path:\n            \n            # We don't allow anyone to remove it except for us:\n            assert entry in sys.path \n            \n            sys.path.remove(entry)\n        \n\ndef execute(command):\n    with OutputCapturer() as output_capturer:\n        subprocess.Popen('command', shell=True)\n    return output_capturer.output\n    ", "archive": "cool-RR__GarlicSim-31a3f8f7971d0eec9c5402117415a7f913158a90.zip"}
{"id": "e4ae32", "repo": "cool-RR/GarlicSim", "revision": "687062c31e86b124df7d51754aa0abf6178219de", "path": "garlicsim/garlicsim/general_misc/weak_key_default_dict.py", "modified": ["garlicsim/garlicsim/general_misc/weak_key_default_dict.py", "garlicsim_wx/garlicsim_wx/general_misc/emitting_ordered_set.py", "garlicsim_wx/garlicsim_wx/general_misc/misc_tools.py"], "prefix": "\nfrom weakref import WeakKeyDictionary\n\nclass WeakKeyDefaultDict(WeakKeyDictionary):\n    \n    def __init__(self, *args, **kwargs):\n        self.default_factory = None\n        if 'default_factory' in kwargs:\n            self.default_factory = kwargs.pop('default_factory')\n        elif len(args) > 0 and callable(args[0]):\n            self.default_factory = args[0]\n            args = args[1:]\n        super(WeakKeyDefaultDict, self).__init__(*args, **kwargs)\n \n    def __missing__(self, key):\n        if self.default_factory is not None:\n            self[key] = value = self.default_factory()\n            return value\n        else: # self.default_factory is None\n            raise KeyError(key)\n\n    def __repr__(self, recurse=set()):\n        if id(self) in recurse:\n            return \"WeakKeyDefaultDict(...)\"\n        try:\n            recurse.add(id(self))\n            return \"WeakKeyDefaultDict(%s, %s)\" % (\n                repr(self.default_factory),\n                super(WeakKeyDefaultDict, self).__repr__()\n            )\n        finally:\n            recurse.remove(id(self))\n\n    def copy(self):\n        return type(self)(self, default_factory=self.default_factory)\n    \n    def __copy__(self):\n        return self.copy()\n\n    def __reduce__(self):\n        \"\"\"\n        __reduce__ must return a 5-tuple as follows:\n\n           - factory function\n           - tuple of args for the factory function\n           - additional state (here None)\n           - sequence iterator (here None)\n           - dictionary iterator (yielding successive (key, value) pairs\n\n           This API is used by pickle.py and copy.py.\n        \"\"\"\n        return (type(self), (self.default_factory,), None, None, self.iteritems())\n\n    \n    def __delitem__(self, key):\n        del self.data[ref(key)]\n\n    def __getitem__(self, key):\n        try:\n            return self.data[ref(key)]\n        except KeyError:\n            return self.__missing__(key)\n\n    def __setitem__(self, key, value):\n        self.data[ref(key, self._remove)] = value\n\n    def ", "suffix": "\n    def has_key(self, key):\n        try:\n            wr = ref(key)\n        except TypeError:\n            return 0\n        return wr in self.data\n\n    def __contains__(self, key):\n        try:\n            wr = ref(key)\n        except TypeError:\n            return 0\n        return wr in self.data\n\n    def items(self):\n        L = []\n        for key, value in self.data.items():\n            o = key()\n            if o is not None:\n                L.append((o, value))\n        return L\n\n    def iteritems(self):\n        for wr, value in self.data.iteritems():\n            key = wr()\n            if key is not None:\n                yield key, value\n\n    def iterkeyrefs(self):\n        \"\"\"Return an iterator that yields the weak references to the keys.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the keys around longer than needed.\n\n        \"\"\"\n        return self.data.iterkeys()\n\n    def iterkeys(self):\n        for wr in self.data.iterkeys():\n            obj = wr()\n            if obj is not None:\n                yield obj\n\n    def __iter__(self):\n        return self.iterkeys()\n\n    def itervalues(self):\n        return self.data.itervalues()\n\n    def keyrefs(self):\n        \"\"\"Return a list of weak references to the keys.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the keys around longer than needed.\n\n        \"\"\"\n        return self.data.keys()\n\n    def keys(self):\n        L = []\n        for wr in self.data.keys():\n            o = wr()\n            if o is not None:\n                L.append(o)\n        return L\n\n    def popitem(self):\n        while 1:\n            key, value = self.data.popitem()\n            o = key()\n            if o is not None:\n                return o, value\n\n    def pop(self, key, *args):\n        return self.data.pop(ref(key), *args)\n\n    def setdefault(self, key, default=None):\n        return self.data.setdefault(ref(key, self._remove),default)\n\n    def update(self, dict=None, **kwargs):\n        d = self.data\n        if dict is not None:\n            if not hasattr(dict, \"items\"):\n                dict = type({})(dict)\n            for key, value in dict.items():\n                d[ref(key, self._remove)] = value\n        if len(kwargs):\n            self.update(kwargs)", "archive": "cool-RR__GarlicSim-687062c31e86b124df7d51754aa0abf6178219de.zip"}
{"id": "2de689", "repo": "cool-RR/GarlicSim", "revision": "6ec509ab4bbcd6c7da21607af1dbeff844ec54a3", "path": "garlicsim/garlicsim/data_structures/node_selection.py", "modified": ["garlicsim/garlicsim/data_structures/__init__.py", "garlicsim/garlicsim/data_structures/node_selection.py", "garlicsim/garlicsim/data_structures/path.py", "garlicsim/garlicsim/data_structures/tree.py", "garlicsim/garlicsim/general_misc/cute_iter_tools.py", "garlicsim/garlicsim/general_misc/logic_tools.py"], "prefix": "'''tododoc'''\n\nfrom node import Node\n\nclass NodeRange(object):\n    def __init__(self, first_node, last_node=None):\n        path = last_node.make_containing_path()\n        self.__node_list = list\n        \n    def compact(self):\n        for range in self.ranges:\n            assert range.is_valid()\n        \n        try:\n            ", "suffix": "            \n    def __partially_compact(self):\n        first, second = None, None\n        for (r1, r2) in cute_iter_tools.orderless_combinations(self.ranges, 2):\n            if r1.start in r2:\n                second, first = r1, r2\n                break\n            elif r2.start in r1:\n                first, second = r1, r2\n                break\n            else:\n                pass\n        if first is not None and second is not None:\n            if second.end in first:\n                pass\n            else: # second.end not in first\n                for current in second:\n                    if current not in first:\n                        break\n                if current.parent is first.end:\n                    self.ranges.remove(first)\n                    new_range = NodeRange(start=first.start, end=second.end)\n                else:\n                    new_range = NodeRange(start=current, end=second.end)\n                self.ranges.append(new_range)\n              \n            self.ranges.remove(second)\n            return\n        else:\n            raise CompletelyCanonic\n        \n    def __add__(self, other):\n        assert isinstance(other, NodeSelection)\n        return NodeSelection(self.ranges + other.ranges)\n    \n    def __radd__(self, other):\n        return self.__add__(other)\n\n    def copy(self):\n        return NodeSelection(self.ranges)\n    \n    __copy__ = copy\n    \n    \n    \n    \n    \n    \n    ", "archive": "cool-RR__GarlicSim-6ec509ab4bbcd6c7da21607af1dbeff844ec54a3.zip"}
{"id": "95d05c", "repo": "cool-RR/GarlicSim", "revision": "771e329ebe6b99174bce8491aefcc563ffe1b794", "path": "garlicsim/tests/general_misc/cute_profile/cute_profile.py", "modified": ["garlicsim/garlicsim/general_misc/cute_profile/cute_profile.py", "garlicsim/tests/general_misc/cute_profile/cute_profile.py", "garlicsim/tests/general_misc/cute_profile/shared.py"], "prefix": "\nfrom garlicsim.general_misc import cute_profile\n\nfrom .shared import call_and_check_if_profiled\n\n\ndef func(x, y, z=3):\n    sum([1, 2, 3])\n    set([1, 2]) | set([2, 3])\n    return x, y, z\n\n\n\ndef test_profile_ready():\n    \n    f = cute_profile.profile_ready(start_on=True, off_after=False)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    \n    f = cute_profile.profile_ready(off_after=True)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    \n    \ndef test_method():\n    \n    class A(object):\n        def __init__(self):\n            self.x = 0\n                \n        ", "suffix": "            \n    a = A()\n    assert a.x == 0\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 1\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 2\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 3\n\n    a.increment.im_func.profiling_on = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 4\n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 5\n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 6\n    \n    a.increment.im_func.off_after = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 7\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 8\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 9\n    \n    a.increment.im_func.profiling_on = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 10\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 11\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 12\n    \n    \n    ", "archive": "cool-RR__GarlicSim-771e329ebe6b99174bce8491aefcc563ffe1b794.zip"}
{"id": "cf483f", "repo": "cool-RR/GarlicSim", "revision": "77c9d277bb603cfcfdd81ae74f6e3b4574106657", "path": "garlicsim/garlicsim/asynchronous_crunching/crunchers/pi_cloud_cruncher/pi_cloud_cruncher.py", "modified": ["garlicsim/garlicsim/asynchronous_crunching/crunchers/__init__.py", "garlicsim/garlicsim/asynchronous_crunching/crunchers/pi_cloud_cruncher/pi_cloud_cruncher.py", "garlicsim/garlicsim/bootstrap/bootstrap.py", "garlicsim/garlicsim/data_structures/block.py", "garlicsim_lib/garlicsim_lib/__init__.py", "garlicsim_wx/garlicsim_wx/bootstrap/bootstrap.py"], "prefix": "# Copyright 2009-2010 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n\n\nimport cloud\nimport copy\nimport Queue\nimport sys\nimport os\n\nimport garlicsim\nfrom garlicsim.asynchronous_crunching import \\\n     BaseCruncher, CrunchingProfile, ObsoleteCruncherError\n\n\n__all__ = ['PiCloudCruncher']    \n\n        \nclass PiCloudCruncher(BaseCruncher):\n    \n    def __init__(self, crunching_manager, initial_state, crunching_profile):\n        \n        BaseCruncher.__init__(self, crunching_manager,\n                              initial_state, crunching_profile)\n        \n        \n        self.work_queue = self.process.work_queue\n        '''\n        Queue for putting completed work to be picked up by the main thread.\n        \n        In this queue the cruncher will put the states that it produces, in\n        chronological order. If the cruncher is being given a new crunching\n        profile which has a new and different step profile, the cruncher\n        will put the new step profile in this queue in order to signal that\n        from that point on, all states were crunched with that step profile.\n        '''\n        \n        self.order_queue = self.process.order_queue\n        '''Queue for receiving instructions from the main thread.'''\n        \n        \n    def start(self):\n        self.process.start()\n\n            \n            self.iterator = self.step_iterator_getter(thing, self.step_profile)\n            \n            order = None\n            \n            try:\n                for state in self.iterator:\n                    self.work_queue.put(state)\n                    self.check_crunching_profile(state)\n                    order = self.get_order()\n                    if order:\n                        self.process_order(order)\n\t    except garlicsim.misc.WorldEnd:\n\t\tself.work_queue.put(garlicsim.asynchronous_crunching.misc.EndMarker())\n                        \n\t\t\n    def check_crunching_profile(self, state):\n\t'''\n\tCheck if the cruncher crunched enough states. If so retire.\n\t\n\tThe crunching manager specifies how much the cruncher should crunch.\n\tWe consult with it to check if the cruncher has finished, and if it did\n\twe retire the cruncher.\n\t'''\n\t", "suffix": "\t\n        \n    def get_order(self):\n        '''\n        Attempt to read an order from the order_queue, if one has been sent.\n        \n        Returns the order.\n        '''\n        try:\n            return self.order_queue.get(block=False)\n        except Queue.Empty:\n            return None\n\n        \n    def process_order(self, order):\n        '''Process an order receieved from order_queue.'''\n        if order == 'retire':\n            raise ObsoleteCruncherError(\"Cruncher received a 'retire' order; \"\n                                        \"Shutting down.\")\n        \n        elif isinstance(order, CrunchingProfile):\n            self.process_crunching_profile_order(order)\n            \n            \n    def process_crunching_profile_order(self, order):\n        '''Process an order to update the crunching profile.'''\n        if self.crunching_profile.step_profile != order.step_profile:\n            raise ObsoleteCruncherError('Step profile changed; Shutting down. '\n                                        'Crunching manager should create a '\n                                        'new cruncher.')\n        self.crunching_profile = order\n\n        \n    def retire(self):\n        '''\n        Retire the cruncher. Process-safe.\n        \n        Causes it to shut down as soon as it receives the order.\n        '''\n        self.order_queue.put(\"retire\")\n        \n        \n    def update_crunching_profile(self, profile):\n        '''Update the cruncher's crunching profile. Process-safe.'''\n        self.order_queue.put(profile)\n        \n        \n    def is_alive(self):\n        return self.process.is_alive()\n        \n        \n    ", "archive": "cool-RR__GarlicSim-77c9d277bb603cfcfdd81ae74f6e3b4574106657.zip"}
{"id": "ffcbe1", "repo": "cool-RR/GarlicSim", "revision": "79f823b8574b1866094361c153ece4722b8ec231", "path": "garlicsim/garlicsim/misc/simpack_grokker/base_step_type.py", "modified": ["garlicsim/garlicsim/misc/simpack_grokker/base_step_type.py", "garlicsim/garlicsim/misc/simpack_grokker/step_types.py"], "prefix": "# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\nDefines the `BaseStepType` class.\n\nSee its dcoumentation for more details.\n'''\n# todo: can do __instancehook__ shit later\n# todo: inherit from uninstanciable.\n# todo: should this be a metaclass?\n# todo: this abc doesn't enforce anything since we don't instantiate.\n# todo: cool idea: allow using this class as a decorator to step functions\n\nfrom garlicsim.general_misc.third_party import abc\n\n\nclass BaseStepType(object):\n    '''\n    A type of step function.\n    \n    There are several different types of step functions with different\n    advantages and disadvantages. See the\n    `garlicsim.misc.simpack_grokker.step_types` package for a collection of\n    various step types.\n    '''\n    __metaclass__ = abc.ABCMeta\n    \n    verbose_name = abc.abstractproperty()\n    '''The verbose name of the step type.'''\n    \n    step_iterator_class = abc.abstractproperty()\n    '''The step iterator class used for steps of this step type.'''\n\n\n    @classmethod\n    def __call__(cls, step_function):\n        step_function._BaseStepType__step_type = cls\n        return step_function\n    \n    \n    @classmethod\n    def __instancecheck__(cls, thing):\n        if hasattr(thing, '_BaseStepType__step_type'):\n            return thing._BaseStepType__step_type\n        else:\n            ", "suffix": "        return step_type\n        \n        \n    @classmethod\n    def __raw_instance_check(cls, thing):\n        #tododoc: justify lines\n        if not callable(thing):\n            return False\n        \n        match = cls.name_identifier in thing.__name__\n        \n        if match is False:\n            return False\n        \n        all_name_identifiers = \\\n            [cls_.name_identifier for cls_ in BaseStepType.__subclasses__]\n             \n        if any((cls.name_identifier in name_identifier_) for \n               name_identifier_ in all_name_identifiers):\n            return False\n        \n        return True\n        \n    \n    @staticmethod\n    def get_step_type(thing):\n        step_types = BaseStepType.__subclasses__()\n        matches = dict((step_type, step_type.__instancecheck__(thing)) for \n                       step_type in step_types)\n        matching_step_types = [step_type for (step_type, match) in matches\n                               if match is True]\n        \n        assert 0 <= len(matching_step_types) <= 1\n        \n        \n    \n        \n        \n        #if 'step' not in name:\n            #raise GarlicSimException(\n                #\"%s is not a step function-- It doesn't have the word 'step' in \"\n                #\"it. If you want GarlicSim to use it as a step function, give it \"\n                #\"a `.step_type` attribute pointing to a step type. (Like \"\n                #\"`garlicsim.misc.simpack_grokker.step_types.SimpleStep`.)\" \\\n                #% thing)\n        \n        #if 'inplace_step_generator' in name:\n            #raise NotImplementedError('`inplace_step_generator` not yet '\n                                      #'supported. It will probably become '\n                                      #'available in GarlicSim 0.7 in mid-2011.')\n            #return InplaceStepGenerator\n        \n        #elif 'inplace_step' in name:\n            #raise NotImplementedError('`inplace_step` not yet '\n                                      #'supported. It will probably become '\n                                      #'available in GarlicSim 0.7 in mid-2011.')\n            #return InplaceStep\n        \n        #elif 'history_step_generator' in name:\n            #raise NotImplementedError('`history_step_generator` not yet. '\n                                      #'supported. It will probably become '\n                                      #'available in GarlicSim 0.7 in mid-2011.')\n            #return HistoryStepGenerator\n        \n        #elif 'step_generator' in name:\n            #return StepGenerator\n        \n        #elif 'history_step' in name:\n            #return HistoryStep\n        \n        #else:\n            #assert 'step' in name\n            #return SimpleStep\n        \n    ", "archive": "cool-RR__GarlicSim-79f823b8574b1866094361c153ece4722b8ec231.zip"}
{"id": "9c8081", "repo": "cool-RR/GarlicSim", "revision": "8e56defbbccb90684de3d7bd57984409ec5fd3c3", "path": "garlicsim/test_garlicsim/test_general_misc/test_sys_tools/test_output_capturer.py", "modified": ["garlicsim/garlicsim/general_misc/context_manager.py", "garlicsim/garlicsim/general_misc/sys_tools.py", "garlicsim/test_garlicsim/test_general_misc/test_sys_tools/test_output_capturer.py"], "prefix": "# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''Testing module for `garlicsim.general_misc.sys_tools.OutputCapturer`.'''\n\nfrom __future__ import with_statement\n\nfrom garlicsim.general_misc.sys_tools import OutputCapturer\n\n\ndef test():\n    '''Test the basic workings of `OutputCapturer`.'''\n    with OutputCapturer() as output_capturer:\n        print('meow')\n    assert output_capturer.output == 'meow\\n'\n    \n    \ndef test_nested():\n    '''Test an `OutputCapturer` inside an `OutputCapturer`.'''\n    with OutputCapturer() as output_capturer_1:\n        print('123')\n        with OutputCapturer() as output_capturer_2:\n            print('456')\n        assert output_capturer_2.output == '456\\n'\n    assert output_capturer_1.output == '123\\n'\n    \n\ndef test_streams():\n    '''Test capturing different streams with `OutputCapturer`.'''\n    with OutputCapturer() as catch_all_output_capturer:\n        with OutputCapturer(True, False) as stdout_output_capturer:\n            print('Woo!')\n            sys.stdout.write('frrr.')\n            ", "suffix": "        assert catch_all_output_capturer.value == 'qwerty'\n        \n        with OutputCapturer(False, False) as blank_output_capturer:\n            print('zort')\n            sys.stdout.write('zort')\n            sys.stderr.write('zort')\n        assert blank_output_capturer.value == ''\n        assert catch_all_output_capturer.value.endswith('zort\\nzortzort')\n        \n        with OutputCapturer(stdout=False) as stderr_output_capturer:\n            print('one')\n            sys.stdout.write('two')\n            sys.stderr.write('three')\n            \n            with OutputCapturer():\n                print('spam')\n                sys.stdout.write('spam')\n                sys.stderr.write('spam')\n                \n        assert stderr_output_capturer.value == 'three'\n        assert catch_all_output_capturer.value.endswith('one\\ntwo')\n        assert 'spam' not in stderr_output_capturer.value\n        assert 'spam' not in catch_all_output_capturer.value\n        \n            \n        ", "archive": "cool-RR__GarlicSim-8e56defbbccb90684de3d7bd57984409ec5fd3c3.zip"}
{"id": "63a4aa", "repo": "cool-RR/GarlicSim", "revision": "94576016f90008812e8675ea0c23c19f459dbcf4", "path": "garlicsim/test_garlicsim/test_general_misc/test_cute_profile/test_cute_profile.py", "modified": ["garlicsim/garlicsim/general_misc/decorator_tools.py", "garlicsim/test_garlicsim/test_general_misc/test_caching/test_cache.py", "garlicsim/test_garlicsim/test_general_misc/test_cute_profile/test_cute_profile.py"], "prefix": "# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\nTesting module for `garlicsim.general_misc.cute_profile`.\n'''\n\nfrom garlicsim.general_misc import cute_profile\nfrom garlicsim.general_misc import cute_testing\n\nfrom .shared import call_and_check_if_profiled\n\n\ndef func(x, y, z=3):\n    '''Function that does some meaningless number-juggling.'''\n    sum([1, 2, 3])\n    set([1, 2]) | set([2, 3])\n    return x, y, z\n\n\n\ndef test_simple():\n    '''Test the basic workings of `profile_ready`.'''\n    f = cute_profile.profile_ready()(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    \n    f = cute_profile.profile_ready(condition=True)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    \n    f = cute_profile.profile_ready(condition=True, off_after=False)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    \n    \n    f = cute_profile.profile_ready(off_after=True)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.condition = lambda f, *args, **kwargs: True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    \n    \ndef test_method():\n    '''Test that `profile_ready` works as a method decorator.'''\n    \n    class A(object):\n        def __init__(self):\n            self.x = 0\n                \n        @cute_profile.profile_ready(off_after=False)\n        def increment(self):\n            sum([1, 2, 3])\n            self.x += 1\n            \n    a = A()\n    assert a.x == 0\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 1\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 2\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 3\n\n    a.increment.im_func.profiling_on = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 4\n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 5\n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 6\n    \n    a.increment.im_func.off_after = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 7\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 8\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 9\n    \n    a.increment.im_func.profiling_on = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 10\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 11\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 12\n    \n    \n\ndef test_condition():\n    '''Test the `condition` argument of `profile_ready`.'''\n\n    x = 7\n    \n    @cute_profile.profile_ready(condition=lambda function, y: x == y,\n                                off_after=False)\n    def f(y):\n        pass\n    \n    # Condition is `False`:\n    assert call_and_check_if_profiled(lambda: f(5)) is False\n    assert call_and_check_if_profiled(lambda: f(6)) is False\n    \n    # Condition is `True`:\n    assert call_and_check_if_profiled(lambda: f(7)) is True\n    \n    # So now profiling is on regardless of condition:\n    assert call_and_check_if_profiled(lambda: f(8)) is True\n    assert call_and_check_if_profiled(lambda: f(9)) is True\n    assert call_and_check_if_profiled(lambda: f(4)) is True\n    assert call_and_check_if_profiled(lambda: f('frr')) is True\n    \n    # Setting profiling off:\n    f.profiling_on = False\n        \n    # So no profiling now:\n    assert call_and_check_if_profiled(lambda: f(4)) is False\n    assert call_and_check_if_profiled(lambda: f('frr')) is False\n    \n    # Until the condition becomes `True` again: (And this time, for fun, with a\n    # different `x`:)\n    x = 9\n    assert call_and_check_if_profiled(lambda: f(9)) is True\n    \n    # So now, again, profiling is on regardless of condition:\n    assert call_and_check_if_profiled(lambda: f(4)) is True\n    assert call_and_check_if_profiled(lambda: f('frr')) is True\n    \n    # Let's give it a try with `.off_after = True`:\n    f.off_after = True\n    \n    # Setting profiling off again:\n    f.profiling_on = False\n    \n    # And for fun set a different `x`:\n    x = 'wow'\n    \n    # Now profiling is on only when the condition is fulfilled, and doesn't\n    # stay on after:\n    assert call_and_check_if_profiled(lambda: f('ooga')) is False\n    assert call_and_check_if_profiled(lambda: f('booga')) is False\n    assert call_and_check_if_profiled(lambda: f('wow')) is True\n    assert call_and_check_if_profiled(lambda: f('meow')) is False\n    assert call_and_check_if_profiled(lambda: f('kabloom')) is False\n    \n    # In fact, after successful profiling the condition gets reset to `None`:\n    assert f.condition is None\n    \n    # So now if we'll call the function again, even if the (former) condition\n    # is `True`, there will be no profiling:\n    assert call_and_check_if_profiled(lambda: f(9)) is False\n    \n    # So if we want to use a condition again, we have to set it ourselves:\n    f.condition = lambda f, y: isinstance(y, float)\n    \n    # And again (since `.off_after == True`) profiling will turn on for just\n    # one time when the condition evaluates to `True` :\n    assert call_and_check_if_profiled(lambda: f('kabloom')) is False\n    assert call_and_check_if_profiled(lambda: f(3)) is False\n    assert call_and_check_if_profiled(lambda: f(3.1)) is True\n    assert call_and_check_if_profiled(lambda: f(3.1)) is False\n    assert call_and_check_if_profiled(lambda: f(-4.9)) is False\n    \n    \ndef test_perfects():\n    \n    def get_divisors(x):\n        return [i for i in xrange(1, x) if (x % i == 0)]\n    \n    def is_perfect(x):\n        return sum(get_divisors(x)) == x\n    \n    @cute_profile.profile_ready()\n    def get_perfects(top):\n        return [i for i in xrange(1, top) if is_perfect(i)]\n    \n    result = get_perfects(30)\n    get_perfects.profiling_on = True\n    def f():\n        assert get_perfects(30) == result\n    assert call_and_check_if_profiled(f) is True\n    \n    \ndef test_polite_wrapper():\n    '''tododocTest that the `profile_ready` decorator preserves function signature.'''\n    cute_testing.assert_polite_wrapper(\n        cute_profile.profile_ready()(func),\n        func\n    )\n\n    \ndef ", "suffix": "\n    #def confusedly_put_function_as_max_size():\n        #@cache\n        #def f(): pass\n        \n    #with cute_testing.RaiseAssertor(\n        #TypeError,\n        #re.compile(\n            #'You entered the callable `.*?` where you should have '\n            #'entered the `max_size` for the cache. You probably '\n            #'used `@cache`, while you should have used `@cache\\(\\)`'\n        #)\n    #):\n        \n        #confusedly_put_function_as_max_size()", "archive": "cool-RR__GarlicSim-94576016f90008812e8675ea0c23c19f459dbcf4.zip"}
{"id": "df9fe2", "repo": "cool-RR/GarlicSim", "revision": "9e408d47050b9158d1dbb03d4426463b73befa31", "path": "misc/testing/zip/make_zip.py", "modified": ["misc/testing/zip/make_zip.py"], "prefix": "#!/usr/bin/env python\n# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\n'''\n\nimport os.path\nimport zipfile\n\ndef zipdir(basedir, archivename, ignored_extenstions=[]):\n    # blocktodo: make pretty\n    assert os.path.isdir(basedir)\n    \n    ### Ensuring ignored extensions start with '.': ###########################\n    #                                                                         #\n    for ignored_extenstion in ignored_extenstions:\n        ", "suffix": "    #                                                                         #\n    ### Finished ensuring ignored extensions start with '.'. ##################\n            \n    with contextlib.closing(\n        zipfile.ZipFile(archivename, 'w', zipfile.ZIP_DEFLATED)\n        ) as z:\n        for root, dirs, files in os.walk(basedir):\n            #NOTE: ignore empty directories\n            for fn in files:\n                extension = os.path.splitext(fn)[1]\n                if extension in ignored_extenstions:\n                    continue\n                absfn = os.path.join(root, fn)\n                zfn = absfn[len(basedir)+len(os.sep):] #XXX: relative path\n                z.write(absfn, zfn)\n\n                \n# todo: define function for zipping a folder, then use it to make garlicsim,\n# garlicsim_lib and garlicsim_wx in build folder\n\n###############################################################################\n#                                                                             #\n# tododoc: helpful error messages:\nassert __name__ == '__main__'\nassert os.path.realpath('.') == \\\n       os.path.realpath(os.path.join(os.getcwd(), 'misc', 'testing', 'zip'))\n\n# todo: define function for zipping a folder, then use it to make garlicsim,\n# garlicsim_lib and garlicsim_wx in build folder", "archive": "cool-RR__GarlicSim-9e408d47050b9158d1dbb03d4426463b73befa31.zip"}
{"id": "c018b6", "repo": "cool-RR/GarlicSim", "revision": "a60743289f5bc10325dd38ccdb5fe10549305e92", "path": "garlicsim/garlicsim/general_misc/context_manager.py", "modified": ["garlicsim/garlicsim/general_misc/context_manager.py", "garlicsim/garlicsim/general_misc/misc_tools.py"], "prefix": "# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\nThis module defines the `ContextManager` class.\n\nSee its documentation for more information.\n'''\n\nfrom garlicsim.general_misc.third_party import decorator as decorator_module\n\n\nclass ContextManagerType(type):\n    def __new__(mcls, *args, **kwargs):\n        type_ = super(ContextManagerType, mcls).__new__(mcls, *args, **kwargs)\n        mro\n        return result\n\n    \n    def _use_generator_for_context_management(cls):\n        \n        @monkeypatching_tools.monkeypatch_method(type_)\n        def __enter__(self):\n            assert self._generator is None\n            self._generator = self.run()\n            assert isinstance(self._generator, types.GeneratorType)\n            \n            try:\n                return self._generator.next()\n            except StopIteration:\n                raise RuntimeError(\"generator didn't yield\")\n        \n        @monkeypatching_tools.monkeypatch_method(type_)\n        def __exit__(self, type_, value, traceback):\n            \n            assert isinstance(self._generator, types.GeneratorType)\n            \n            if type_ is None:\n                try:\n                    self._generator.next()\n                except StopIteration:\n                    return\n                else:\n                    raise RuntimeError(\"generator didn't stop\")\n            else:\n                if value is None:\n                    # Need to force instantiation so we can reliably\n                    # tell if we get the same exception back\n                    value = type_()\n                try:\n                    self._generator.throw(type_, value, traceback)\n                    raise RuntimeError(\"generator didn't stop after throw()\")\n                except StopIteration as exc:\n                    # Suppress the exception *unless* it's the same exception that\n                    # was passed to ", "suffix": "                except:\n                    # only re-raise if it's *not* the exception that was\n                    # passed to throw(), because __exit__() must not raise\n                    # an exception unless __exit__() itself failed.  But throw()\n                    # has to raise the exception to signal propagation, so this\n                    # fixes the impedance mismatch between the throw() protocol\n                    # and the __exit__() protocol.\n                    #\n                    if sys.exc_info()[1] is not value:\n                        raise\n\n\nclass ContextManager(object):\n    \n    def __call__(self, function):\n        def inner(*args, **kwargs):\n            with self:\n                return function(*args, **kwargs)\n        return decorator_module.decorator(inner, function)\n    \n    def __enter__(self):\n        pass\n    \n    def __exit__(self, *args, **kwargs):\n        pass", "archive": "cool-RR__GarlicSim-a60743289f5bc10325dd38ccdb5fe10549305e92.zip"}
{"id": "8cd862", "repo": "cool-RR/GarlicSim", "revision": "b592fa125872d8af81d6bcb5366ef0c758ae932a", "path": "garlicsim_wx/test_garlicsim_wx/__init__.py", "modified": ["garlicsim/test_garlicsim/__init__.py", "garlicsim_lib/test_garlicsim_lib/__init__.py", "garlicsim_wx/test_garlicsim_wx/__init__.py"], "prefix": "# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''Testing package for `garlicsim_wx`.'''\n\n\ndef __bootstrap():\n    '''\n    Add needed packages in repo to path if we can't find them.\n    \n    This adds `garlicsim`'s, `garlicsim_lib`'s and `garlicsim_wx`'s root\n    folders to `sys.path` if they can't currently be imported.\n    '''\n    import os\n    import sys\n    from garlicsim.general_misc import import_tools    \n    if not import_tools.exists('garlicsim'):\n        garlicsim_candidate_path = os.path.realpath(\n            os.path.join(\n                os.path.split(__file__)[0],\n                '..',\n                '..',\n                'garlicsim'\n            )\n        )\n        sys.path.append(garlicsim_candidate_path)\n    if not import_tools.exists('garlicsim_lib'):\n        ", "suffix": "    if not import_tools.exists('garlicsim_wx'):\n        garlicsim_wx_candidate_path = os.path.realpath(\n            os.path.join(\n                os.path.split(__file__)[0],\n                '..',\n                '..',\n                'garlicsim_wx'\n            )\n        )\n        sys.path.append(garlicsim_wx_candidate_path)\n        \n        \n__bootstrap()", "archive": "cool-RR__GarlicSim-b592fa125872d8af81d6bcb5366ef0c758ae932a.zip"}
{"id": "ab3342", "repo": "cool-RR/GarlicSim", "revision": "b92ea385d8b4b38465d0f2c830410b0cb6b53c30", "path": "garlicsim_wx/garlicsim_wx/general_misc/junk/aui.py", "modified": ["garlicsim_wx/garlicsim_wx/general_misc/junk/aui.py"], "prefix": "import wx\nimport wx.lib.agw.aui as aui\nfrom wx.lib.agw.aui import *\n\nclass MyFrame(wx.Frame):\n\n    def __init__(self, parent, id=-1, title=\"AUI Test\", pos=wx.DefaultPosition,\n                 size=(800, 600), style=wx.DEFAULT_FRAME_STYLE):\n\n        wx.Frame.__init__(self, parent, id, title, pos, size, style)\n\n        self._mgr = aui.AuiManager()\n        \n        # notify AUI which frame to use\n        self._mgr.SetManagedWindow(self)\n\n        # create several text controls\n        text1 = wx.TextCtrl(self, -1, \"Pane 1 - sample text\",\n                            wx.DefaultPosition, wx.Size(200,150),\n                            wx.NO_BORDER | wx.TE_MULTILINE)\n                                           \n        text2 = wx.TextCtrl(self, -1, \"Pane 2 - sample text\",\n                            wx.DefaultPosition, wx.Size(200,150),\n                            wx.NO_BORDER | wx.TE_MULTILINE)\n                                           \n        text3 = wx.TextCtrl(self, -1, \"Main content window\",\n                            wx.DefaultPosition, wx.Size(200,150),\n                            wx.NO_BORDER | wx.TE_MULTILINE)\n        \n        # add the panes to the manager\n        self._mgr.AddPane(text1, AuiPaneInfo().Left().Caption(\"Pane Number One\"))\n        self._mgr.AddPane(text2, AuiPaneInfo().Bottom().Caption(\"Pane Number Two\"))\n        self._mgr.AddPane(text3, AuiPaneInfo().CenterPane())\n                              \n        # tell the manager to \"commit\" all the changes just made\n        self._mgr.Update()\n\n        sel", "suffix": "\n\n# our normal wxApp-derived class, as usual\n\napp = wx.PySimpleApp()\n\nframe = MyFrame(None)\napp.SetTopWindow(frame)\nframe.Show()\n\napp.MainLoop()", "archive": "cool-RR__GarlicSim-b92ea385d8b4b38465d0f2c830410b0cb6b53c30.zip"}
{"id": "00fefa", "repo": "cool-RR/GarlicSim", "revision": "cfd291f6c682302a75633c9e825281b5e5d2bcad", "path": "garlicsim/garlicsim/general_misc/misc_tools.py", "modified": ["garlicsim/garlicsim/general_misc/import_tools.py", "garlicsim/garlicsim/general_misc/misc_tools.py", "garlicsim/garlicsim/misc/simpack_grokker/simpack_grokker.py", "garlicsim_wx/garlicsim_wx/misc/simpack_wx_grokker/simpack_wx_grokker.py"], "prefix": "# Copyright 2009-2010 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''This module defines miscellaneous tools.'''\n\nimport math\n\n\ndef frange(start, finish=None, step=1.):\n    '''\n    Make a list containing an arithmetic progression of numbers.\n\n    This is an extension of the builtin `range`; It allows using floating point\n    numbers.\n    '''\n    if finish is None:\n        finish, start = start, 0.\n    else:\n        start = float(start)\n\n    count = int(math.ceil(finish - start)/step)\n    return (start + n*step for n in range(count))\n\n\ndef shorten_class_address(module_name, class_name):\n    '''\n    Shorten the address of a class.\n    \n    This is mostly used in `__repr__` methods of various classes to shorten the\n    text and make the final output more conscise. For example, if you have a\n    class `garlicsim.asynchronous_crunching.project.Project`, but which is also\n    available as `garlicsim.Project`, this function will return\n    'garlicsim.Project'.    \n    '''\n    get_module = lambda module_name: __import__(module_name, fromlist=[''])\n    original_module = get_module(module_name)\n    original_class = getattr(original_module, class_name)\n    \n    current_module_name = module_name\n    \n    last_successful_module_name = current_module_name\n    \n    while True:\n        # Removing the last submodule from the module name:\n        current_module_name = '.'.join(current_module_name.split('.')[:-1]) \n        \n        if not current_module_name:\n            # We've reached the top module and it's successful, can break now.\n            break\n        \n        current_module = get_module(current_module_name)\n        \n        candidate_class = getattr(current_module, class_name, None)\n        \n        if candidate_class is original_class:\n            last_successful_module_name = current_module_name\n        else:\n            break\n        \n    return '.'.join((last_successful_module_name, class_name))\n\n\ndef get_object_from_address(address, parent_object=None):\n    if not parent_object:\n        if '.' not in address:\n            try:\n                ", "suffix": "        else: # '.' in address\n            first_object_address, second_object_address = \\\n                address.rsplit('.', 1)\n            first_object = get_object_from_address(first_object_address)\n            second_object = get_object_from_address(second_object_address,\n                                                    parent_object=first_object)\n            return second_object\n    \n    else: # parent_object is not none\n        if '.' not in address:\n            if isinstance(parent_object, types.ModuleType):\n                import_tools.import_if_exists(\n                    '.'.join(parent_object.__name__, address)\n                )\n                # Not keeping reference, just importing so we could get later\n            return getattr(parent_object, address)\n        else: # '.' in address\n            first_object_address, second_object_address = \\\n                address.rsplit('.', 1)\n            first_object = get_object_from_address(first_object_address, parent_object)\n            second_object = get_object_from_address(second_object_address,\n                                                    parent_object=first_object)\n            return second_object\n    \n\n\nclass LazilyEvaluatedConstantProperty(object):\n    '''\n    A property that is calculated (a) lazily and (b) only once for an object.\n    \n    Usage:\n    \n        class MyObject(object):\n        \n            # ... Regular definitions here\n        \n            def _get_personality(self):\n                print('Calculating personality...')\n                time.sleep(5) # Time consuming process that creates personality\n                return 'Nice person'\n        \n            personality = LazilyEvaluatedConstantProperty(_get_personality)\n    \n    '''\n    def __init__(self, getter, name=None):\n        '''\n        Construct the LEC-property.\n        \n        You may optionally pass in the name the this property has in the class;\n        This will save a bit of processing later.\n        '''\n        self.getter = getter\n        self.our_name = name\n        \n        \n    def __get__(self, obj, our_type=None):\n\n        value = self.getter(obj)\n        \n        if not self.our_name:\n            if not our_type:\n                our_type = type(obj)\n            (self.our_name,) = (key for (key, value) in \n                                vars(our_type).iteritems()\n                                if value is self)\n        \n        setattr(obj, self.our_name, value)\n        \n        return value\n\ndef getted_vars(thing):\n    # todo: can make \"fallback\" option, to use value from original `vars` if get\n    # is unsuccessful.\n    my_vars = vars(thing)\n    return dict((name, getattr(thing, name)) for name in my_vars.iterkeys())\n    \n\n        \nif __name__ == '__main__': # todo: move to test suite\n    import random\n    class A(object):\n        def _get_personality(self):\n            print(\n                \"Calculating personality for %s. (Should happen only once.)\" % self\n            )\n            return random.choice(['Angry', 'Happy', 'Sad', 'Excited'])\n        personality = LazilyEvaluatedConstantProperty(_get_personality)\n    a = A()\n    print(a.personality)\n    print(a.personality)\n    print(a.personality)\n    \n    a2 = A()\n    print(a2.personality)\n    print(a2.personality)\n    print(a2.personality)\n    ", "archive": "cool-RR__GarlicSim-cfd291f6c682302a75633c9e825281b5e5d2bcad.zip"}
{"id": "4ed4a0", "repo": "cool-RR/GarlicSim", "revision": "d7a73874f2701e3c6e81500b851c7ee2552c09f7", "path": "src/garlicsim/asynchronous_crunching/project/project.py", "modified": ["src/garlicsim/__init__.py", "src/garlicsim/asynchronous_crunching/project/__init__.py", "src/garlicsim/asynchronous_crunching/project/project.py", "src/garlicsim/synchronous_crunching/__init__.py"], "prefix": "# Copyright 2009 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n\"\"\"\nThis module defines the Project class. See its documentation for more\ninformation.\n\"\"\"\n\nimport garlicsim.data_structures\nimport garlicsim.simpack_grokker\nimport crunching_manager\n\nimport garlicsim.misc.read_write_lock as read_write_lock\nfrom garlicsim.misc.infinity import Infinity\nimport garlicsim.misc.module_wrapper\nimport garlicsim.misc.cool_dict\n\n__all__ = [\"Project\"]\n\nclass Project(object):\n    \"\"\"\n    You create a project when you want to do a simulation which will crunch\n    in the background with worker threads or worker processes.\n\n    A project contains within it a tree.\n        \n    The crunching is taken care of by the CrunchingManager which is a part of\n    every project. The CrunchingManager employs CruncherThreads and/or\n    CruncherProcesses to get the work done. To make the CrunchingManager take\n    work from the crunchers and coordinate them, call the sync_crunchers method\n    of the project.\n    \n    What the crunching manager's sync_crunchers method will do is check the\n    attribute .nodes_to_crunch of the project. This attribute is a dict-like\n    object which maps nodes that should be crunched to a number specifying how\n    many states should be crunched from this node. The crunching manager will\n    then coordinate the crunchers in order to do this work. It will update the\n    .nodes_to_crunch attribute when the crunchers have completed some of the\n    work.\n    \"\"\"\n\n    def __init__(self, simpack):\n        \n        wrapped_simpack = \\\n            garlicsim.misc.module_wrapper.module_wrapper_factory(simpack)\n        \n        self.simpack_grokker = \\\n            garlicsim.simpack_grokker.SimpackGrokker(wrapped_simpack)\n        \n        self.simpack = wrapped_simpack\n\n        self.tree = garlicsim.data_structures.Tree()\n        \n        self.crunching_manager = crunching_manager.CrunchingManager(self)\n        \n        self.tree_lock = read_write_lock.ReadWriteLock()\n        \"\"\"\n        The tree_lock is a read-write lock that guards access to the tree.\n        We need such a thing because some simulations are history-dependent\n        and require reading from the tree in the same time that sync_crunchers\n        could potentially be writing to it.\n        \"\"\"\n\n        self.nodes_to_crunch = garlicsim.misc.cool_dict.CoolDict()\n        \"\"\"\n        A dict that maps leaves that should be worked on to a number specifying\n        how many nodes should be created after them.\n        \"\"\"\n\n    def make_plain_root(self, *args, **kwargs):\n        \"\"\"\n        Creates a parentless node, whose state is a simple plain state.\n        The simulation package should define the function `make_plain_state`\n        for this to work.\n        Returns the node.\n        \"\"\"\n        state = self.simpack.make_plain_state(*args, **kwargs)\n        return self.root_this_state(state)\n\n    def make_random_root(self, *args, **kwargs):\n        \"\"\"\n        Creates a parentless node, whose state is a random and messy state.\n        The simulation package should define the function `make_random_state`\n        for this to work.\n        Returns the node.\n        \"\"\"\n        state = self.simpack.make_random_state(*args, **kwargs)\n        return self.root_this_state(state)\n\n    def root_this_state(self, state):\n        \"\"\"\n        Takes a state, wraps it in a node and adds to the tree without a\n        parent.\n        Returns the node.\n        \"\"\"\n        return self.tree.add_state(state)\n\n    def crunch_all_leaves(self, node, wanted_distance):\n        \"\"\"\n        Orders to start crunching from all the leaves of `node`, so that there\n        will be a buffer whose length is at least `wanted_distance`.\n        \"\"\"\n        leaves = node.get_all_leaves(wanted_distance)\n        for (leaf, distance) in leaves.items():\n            new_distance = wanted_distance - distance\n            self.nodes_to_crunch.raise_to(leaf, new_distance)\n\n    def sync_crunchers(self, temp_infinity_node=None):\n        \"\"\"\n        Talks with all the crunchers, takes work from them for\n        implementing into the tree, terminates crunchers or creates\n        new crunchers if necessary.\n        You can pass a node as `temp_infinity_node`. That will cause this\n        function to temporarily treat this node as if it should be crunched\n        indefinitely.\n\n        Returns the total amount of nodes that were added to the tree.\n        \"\"\"\n        \n        return self.crunching_manager.sync_crunchers \\\n               (temp_infinity_node=temp_infinity_node)\n    \n    @with_tree_lock\n    def simulate(self, node, iterations=1, *args, **kwargs):\n        \"\"\"\n        Simulates from the given node for the given number of iterations,\n        implementing the results into the tree. Note this is done\n        synchronously, i.e. in the currrent thread.\n        \n        Any extraneous parameters will be passed to the step function.\n        \n        Returns the final node.                \n        \"\"\"\n        \n        if self.simpack_grokker.history_dependent:\n            return self.__history_dependent_simulate(node, iterations,\n                                                     *args, **kwargs)\n        else:\n            return self.__non_history_dependent_simulate(node, iterations,\n                                                         *args, **kwargs)\n        \n    def __history_dependent_simulate(self, node, iterations=1,\n                                     *args, **kwargs):\n        \"\"\"\n        For history-dependent simulations only:\n        \n        Simulates from the given node for the given number of iterations,\n        implementing the results into the tree. Note this is done\n        synchronously, i.e. in the currrent thread.\n        \n        Any extraneous parameters will be passed to the step function.\n        \n        Returns the final node.                \n        \"\"\"\n        \n        path = node.make_containing_path()\n        history_browser = garlicsim.synchronous_crunching.\\\n                        history_browser.HistoryBrowser(path)\n        current_node = node\n        state = node.state\n        for i in range(iterations):\n            ", "suffix": "            \n        return current_node\n    \n    def __non_history_dependent_simulate(self, node, iterations=1,\n                                         *args, **kwargs):\n        \"\"\"\n        For non-history-dependent simulations only:\n        \n        Simulates from the given node for the given number of iterations,\n        implementing the results into the tree. Note this is done\n        synchronously, i.e. in the currrent thread.\n        \n        Any extraneous parameters will be passed to the step function.\n        \n        Returns the final node.                \n        \"\"\"\n        \n        current_node = node\n        state = node.state\n        for i in range(iterations):\n            state = self.simpack_grokker.step(state, *args, **kwargs)\n            current_node = self.tree.add_state(state, parent=current_node)\n            \n        return current_node\n    \n    def __getstate__(self):\n        my_dict = dict(self.__dict__)\n        \n        del my_dict[\"tree_lock\"]\n        del my_dict[\"crunching_manager\"]\n        \n        return my_dict\n    \n    def __setstate__(self, pickled_project):\n        self.__init__(pickled_project[\"simpack\"])\n        self.__dict__.update(pickled_project)", "archive": "cool-RR__GarlicSim-d7a73874f2701e3c6e81500b851c7ee2552c09f7.zip"}
{"id": "5a74f4", "repo": "cool-RR/GarlicSim", "revision": "e03a7f97381fd5083365eb6cbf5500767f8c2191", "path": "src/garlicsim/misc/infinity.py", "modified": ["src/garlicsim/asynchronous_crunching/project/crunching_manager.py", "src/garlicsim/asynchronous_crunching/project/project.py", "src/garlicsim/crunching_profile.py", "src/garlicsim/misc/infinity.py", "src/garlicsim_wx/gui_project.py"], "prefix": "# Copyright 2009 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n\"\"\"\nThis module defines a variable Infinity which simply stands for float(\"inf\").\nThe only reason for this alias is to make code more readable.\n\"\"\"\nInfinity = float(\"inf\")\n\nclass FunnyInfinityClass(object):\n    def __init__(self):\n        self.added = 0\n        self.sign = 1\n    def __add__(self, other):\n        if is_a_number(other):\n            result = cop", "suffix": "            raise NotImplementedError\n    def __cmp__(self, other):\n        if is_a_number(other):\n            return 1\n        elif isinstance(other, FunnyInfinityClass):\n            sign_comparison = cmp(self.sign, other.sign)\n            if sign_comparison != 0:\n                return sign_comparison\n            else:\n                return cmp(self.added, other.added)\n        else:\n            raise NotImplementedError\n    def __neg__(self):\n        result = copy.deepcopy(self)\n        result.sign *= -1\n    def __repr__(self):\n        if self.added == 0:            \n            return \"FunnyInfinity\" \n        else:\n            return \"(FunnyInfinity + %s)\" % self.added\n    \n        \nFunnyInfinity = FunnyInfinityClass()\n        \n        ", "archive": "cool-RR__GarlicSim-e03a7f97381fd5083365eb6cbf5500767f8c2191.zip"}
{"id": "54fead", "repo": "pallets/werkzeug", "revision": "0a0c47d61b2df7885182cbf5f0882a076f98fe3c", "path": "tests/contrib/test_securecookie.py", "modified": ["tests/contrib/test_securecookie.py", "werkzeug/contrib/securecookie.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    tests.securecookie\n    ~~~~~~~~~~~~~~~~~~\n\n    Tests the secure cookie.\n\n    :copyright: (c) 2014 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\n\nfrom werkzeug.utils import parse_cookie\nfrom werkzeug.wrappers import Request, Response\nfrom werkzeug.contrib.securecookie import SecureCookie\n\n\ndef test_basic_support():\n    c = SecureCookie(secret_key=b'foo')\n    assert c.new\n    assert not c.modified\n    assert not c.should_save\n    c['x'] = 42\n    assert c.modified\n    assert c.should_save\n    s = c.serialize()\n\n    c2 = SecureCookie.unserialize(s, b'foo')\n    assert c is not c2\n    assert not c2.new\n    assert not c2.modified\n    assert not c2.should_save\n    assert c2 == c\n\n    c3 = SecureCookie.unserialize(s, b'wrong foo')\n    assert not c3.modified\n    assert not c3.new\n    assert c3 == {}\n\n    c4 = SecureCookie({'x': 42}, 'foo')\n    c4_serialized = c4.serialize()\n    assert SecureCookie.unserialize(c4_serialized, 'foo') == c4\n\n\ndef test_wrapper_support():\n    req = Request.from_values()\n    resp = Response()\n    c = SecureCookie.load_cookie(req, secret_key=b'foo')\n    assert c.new\n    c['foo'] = 42\n    assert c.secret_key == b'foo'\n    c.save_cookie(resp)\n\n    req = Request.from_values(headers={\n        'Cookie':  'session=\"%s\"' % parse_cookie(resp.headers['set-cookie'])['session']\n    })\n    c2 = SecureCookie.load_cookie(req, secret_key=b'foo')\n    assert not c2.new\n    assert c2 == c\n\n\ndef test_pickle_deprecated():\n    with pytest.warns(UserWarning):\n        SecureCookie({\"foo\": \"bar\"}, \"secret\").serialize()\n\n\ndef test_json():\n    class JSONCompat(object):\n        dumps = staticmethod(json.dumps)\n\n        ", "suffix": "\n    class JSONSecureCookie(SecureCookie):\n        serialization_method = JSONCompat\n\n    secure = JSONSecureCookie({\"foo\": \"bar\"}, \"secret\").serialize()\n    data = JSONSecureCookie.unserialize(secure, \"secret\")\n    assert data == {\"foo\": \"bar\"}", "archive": "pallets__werkzeug-0a0c47d61b2df7885182cbf5f0882a076f98fe3c.zip"}
{"id": "0f6793", "repo": "pallets/werkzeug", "revision": "0ea28bbc6f5f05eefb0e648b52e6400be4b11e43", "path": "tests/test_parsing.py", "modified": ["tests/test_parsing.py", "werkzeug/http.py", "werkzeug/utils.py", "werkzeug/wrappers.py"], "prefix": "# -*- coding: utf-8 -*-\nfrom os.path import join, dirname, abspath\nfrom werkzeug import Client, Request, Response\n\n\n@Request.application\ndef form_data_consumer(request):\n    result_object = request.args['object']\n    if result_object == 'text':\n        return Response(repr(request.form['text']))\n    f = request.files[result_object]\n    return Response('\\n'.join((\n        repr(f.filename),\n        repr(f.name),\n        repr(f.content_type),\n        f.stream.read()\n    )))\n\n\ndef get_contents(filename):\n    f = file(filename, 'rb')\n    try:\n        return f.read()\n    finally:\n        f.close()\n\n\ndef test_multipart():\n    \"\"\"Tests multipart parsing against data collected from webbrowsers\"\"\"\n    resources = join(dirname(__file__), 'multipart')\n    client = Client(form_data_consumer, Response)\n\n    repository = [\n        ('firefox3-2png1txt', '---------------------------186454651713519341951581030105', [\n            (u'anchor.png', 'file1', 'image/png', 'file1.png'),\n            (u'application_edit.png', 'file2', 'image/png', 'file2.png')\n        ], u'example text'),\n        ('firefox3-2pnglongtext', '---------------------------14904044739787191031754711748', [\n            (u'accept.png', 'file1', 'image/png', 'file1.png'),\n            (u'add.png', 'file2', 'image/png', 'file2.png')\n        ], u'--long text\\r\\n--with boundary\\r\\n--lookalikes--'),\n        ('opera8-2png1txt', '----------zEO9jQKmLc2Cq88c23Dx19', [\n            (u'arrow_branch.png', 'file1', 'image/png', 'file1.png'),\n            (u'award_star_bronze_1.png', 'file2', 'image/png', 'file2.png')\n        ], u'blafasel \u00f6\u00e4\u00fc'),\n        ('webkit3-2png1txt', '----WebKitFormBoundaryjdSFhcARk8fyGNy6', [\n            (u'gtk-apply.png', 'file1', 'image/png', 'file1.png'),\n            (u'gtk-no.png', 'file2', 'image/png', 'file2.png')\n        ], u'this is another text with \u00fcml\u00e4\u00fcts'),\n        ('ie6-2png1txt', '---------------------------7d91b03a20128', [\n            (u'file1.png', 'file1', 'image/x-png', 'file1.png'),\n            (u'file2.png', 'file2', 'image/x-png', 'file2.png')\n        ], u'ie6 sucks :-/')\n    ]\n\n    for name, boundary, files, text in repository:\n        folder = join(resources, name)\n        data = get_contents(join(folder, 'request.txt'))\n        for filename, field, content_type, fsname in files:\n            response = client.post('/?object=' + field, data=data, content_type=\n                                   'multipart/form-data; boundary=\"%s\"' % boundary,\n                                   content_length=len(data))\n            lines = response.data.split('\\n', 3)\n            assert lines[0] == repr(filename)\n            assert lines[1] == repr(field)\n            assert lines[2] == repr(content_type)\n            assert lines[3] == get_contents(join(folder, fsname))\n        response = client.post('/?object=text', data=data, content_type=\n                               'multipart/form-data; boundary=\"%s\"' % boundary,\n                               content_length=len(data))\n        assert response.data == repr(text)\n\n\ndef test_limiting():\n    \"\"\"Test the limiting features.\"\"\"\n    data = 'foo=Hello+World&bar=baz'\n    req = Request.from_values(input_stream=StringIO(data),\n                              content_length=len(data),\n                              content_type='application/x-www-form-urlencoded',\n                              method='POST')\n    req.max_content_length = 4\n\n    req = Request.from_values(input_stream=StringIO(data),\n                              content_length=len(data),\n                              content_type='application/x-www-form-urlencoded',\n                              method='POST')\n    req.max_content_length = 400\n    assert req.form['foo'] == 'Hello World'\n\n    req = Request.from_values(input_stream=StringIO(data),\n                              content_length=len(data),\n                              content_type='application/x-www-form-urlencoded',\n                              method='POST')\n    req.max_form_memory_size = 7\n    assert_raises(RequestEntityTooLarge, lambda: req.form['foo'])\n\n    req = Request.from_values(input_stream=StringIO(data),\n                              content_length=len(data),\n                              content_type='application/x-www-form-urlencoded',\n                              method='POST')\n    req.max_form_memory_size = 400\n    assert req.form['foo'] == 'Hello World'\n\n    data = ('--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\n'\n            'Hello World\\r\\n'\n            '--foo\\r\\nContent-Disposition: form-field; name=bar\\r\\n\\r\\n'\n            'bar=baz\\r\\n--foo--')\n    req = Request.from_values(input_stream=StringIO(data),\n                              content_length=len(data),\n                              content_type='multipart/form-data; boundary=foo',\n                              method='POST')\n    req.max_content_length = 4\n    assert_raises(RequestEntityTooLarge, lambda: req.form['foo'])\n\n    req = Request.from_values(input_stream=StringIO(data),\n                              content_length=len(data),\n                              content_type='multipart/form-data; boundary=foo',\n                              method='POST')\n    req.max_content_length = 400\n    assert req.form['foo'] == 'Hello World'\n\n    req = Request.from_values(input_stream=StringIO(data),\n                              content_length=len(data),\n                              content_type='multipart/form-data; boundary=foo',\n                              method='POST')\n    req.max_form_memory_size = 7\n    assert_raises(RequestEntityTooLarge, lambda: req.form['foo'])\n\n    req = Request.from_values(input_stream=StringIO(data),\n                              content_length=len(data),\n                              ", "suffix": "    req.max_form_memory_size = 400\n    assert req.form['foo'] == 'Hello World'", "archive": "pallets__werkzeug-0ea28bbc6f5f05eefb0e648b52e6400be4b11e43.zip"}
{"id": "43f03c", "repo": "pallets/werkzeug", "revision": "17beb0a425765c32f8cd58078ba2eff7fb4b30cd", "path": "werkzeug/debug/util.py", "modified": ["werkzeug/debug/util.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.debug.util\n    ~~~~~~~~~~~~~~~~~~~\n\n    Debugging utilities.\n\n    :copyright: 2007 by Georg Brandl, Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport os\nimport sys\nimport inspect\nimport threading\nfrom random import random\nfrom cStringIO import StringIO\n\nfrom werkzeug.debug.highlighter import PythonParser\n\n\ndef get_current_thread():\n    return threading.currentThread()\n\n\nclass Namespace(object):\n    def __init__(self, **kwds):\n        self.__dict__.update(kwds)\n\n\nclass ThreadedStream(object):\n    _orig = None\n\n    def __init__(self):\n        self._buffer = {}\n\n    def install(cls, environ):\n        if cls._orig or not environ['wsgi.multithread']:\n            return\n        cls._orig = sys.stdout\n        sys.stdout = cls()\n    install = classmethod(install)\n\n    def can_interact(cls):\n        return not cls._orig is None\n    can_interact = classmethod(can_interact)\n\n    def push(self):\n        tid = get_current_thread()\n        self._buffer[tid] = StringIO()\n\n    def release(self):\n        tid = get_current_thread()\n        if tid in self._buffer:\n            result = self._buffer[tid].getvalue()\n            del self._buffer[tid]\n        else:\n            result = ''\n        return result\n\n    def write(self, d):\n        tid = get_current_thread()\n        if tid in self._buffer:\n            self._buffer[tid].write(d)\n        else:\n            self._orig.write(d)\n\n\ndef get_uid():\n    \"\"\"\n    Return a random unique ID.\n    \"\"\"\n    return str(random()).encode('base64')[3:11]\n\n\nclass PythonParser(object):\n    \"\"\"\n    Simple python sourcecode highlighter.\n\n    Usage::\n\n        p = PythonParser(source)\n        p.parse()\n        for line in p.get_html_output():\n            print line\n    \"\"\"\n\n    _KEYWORD = token.NT_OFFSET + 1\n    _TEXT    = token.NT_OFFSET + 2\n    _classes = {\n        token.NUMBER:       'num',\n        token.OP:           'op',\n        token.STRING:       'str',\n        tokenize.COMMENT:   'cmt',\n        token.NAME:         'id',\n        token.ERRORTOKEN:   'error',\n        _KEYWORD:           'kw',\n        _TEXT:              'txt',\n    }\n\n    def __init__(self, raw):\n        self.raw = raw.expandtabs(8)\n        if isinstance(self.raw, unicode):\n            self.raw = self.raw.encode('utf-8', 'ignore')\n        self.out = StringIO()\n\n    def parse(self):\n        self.lines = [0, 0]\n        pos = 0\n        while 1:\n            ", "suffix": "        self.lines.append(len(self.raw))\n\n        self.pos = 0\n        text = StringIO(self.raw)\n        try:\n            tokenize.tokenize(text.readline, self)\n        except tokenize.TokenError:\n            pass\n\n    def get_html_output(self):\n        \"\"\" Return line generator. \"\"\"\n        def html_splitlines(lines):\n            # this cool function was taken from trac.\n            # http://projects.edgewall.com/trac/\n            open_tag_re = re.compile(r'<(\\w+)(\\s.*)?[^/]?>')\n            close_tag_re = re.compile(r'</(\\w+)>')\n            open_tags = []\n            for line in lines:\n                for tag in open_tags:\n                    line = tag.group(0) + line\n                open_tags = []\n                for tag in open_tag_re.finditer(line):\n                    open_tags.append(tag)\n                open_tags.reverse()\n                for ctag in close_tag_re.finditer(line):\n                    for otag in open_tags:\n                        if otag.group(1) == ctag.group(1):\n                            open_tags.remove(otag)\n                            break\n                for tag in open_tags:\n                    line += '</%s>' % tag.group(1)\n                yield line\n\n        return list(html_splitlines(self.out.getvalue().splitlines()))\n\n    def __call__(self, toktype, toktext, (srow,scol), (erow,ecol), line):\n        oldpos = self.pos\n        newpos = self.lines[srow] + scol\n        self.pos = newpos + len(toktext)\n\n        if toktype in [token.NEWLINE, tokenize.NL]:\n            self.out.write('\\n')\n            return\n\n        if newpos > oldpos:\n            self.out.write(self.raw[oldpos:newpos])\n\n        if toktype in [token.INDENT, token.DEDENT]:\n            self.pos = newpos\n            return\n\n        if token.LPAR <= toktype and toktype <= token.OP:\n            toktype = token.OP\n        elif toktype == token.NAME and keyword.iskeyword(toktext):\n            toktype = self._KEYWORD\n        clsname = self._classes.get(toktype, 'txt')\n\n        self.out.write('<span class=\"code-item p-%s\">' % clsname)\n        self.out.write(escape(toktext))\n        self.out.write('</span>')\n\n\ndef get_frame_info(tb, context_lines=7):\n    \"\"\"\n    Return a dict of information about a given traceback.\n    \"\"\"\n    # line numbers / function / variables\n    lineno = tb.tb_lineno\n    function = tb.tb_frame.f_code.co_name\n    variables = tb.tb_frame.f_locals\n\n    # get filename\n    fn = tb.tb_frame.f_globals.get('__file__')\n    if not fn:\n        fn = os.path.realpath(inspect.getsourcefile(tb) or\n                              inspect.getfile(tb))\n    if fn[-4:] in ('.pyc', '.pyo'):\n        fn = fn[:-1]\n\n    # module name\n    modname = tb.tb_frame.f_globals.get('__name__')\n\n    # get loader\n    loader = tb.tb_frame.f_globals.get('__loader__')\n\n    # sourcecode\n    try:\n        if not loader is None:\n            source = loader.get_source(modname)\n        else:\n            source = file(fn).read()\n    except:\n        source = ''\n        pre_context, post_context = [], []\n        context_line, context_lineno = None, None\n    else:\n        parser = PythonParser(source)\n        parser.parse()\n        parsed_source = parser.get_html_output()\n        lbound = max(0, lineno - context_lines - 1)\n        ubound = lineno + context_lines\n        try:\n            context_line = parsed_source[lineno - 1]\n            pre_context = parsed_source[lbound:lineno - 1]\n            post_context = parsed_source[lineno:ubound]\n        except IndexError, e:\n            context_line = None\n            pre_context = post_context = [], []\n        context_lineno = lbound\n\n    return {\n        'tb':               tb,\n        'filename':         isinstance(fn, unicode) and fn.encode('utf-8') or fn,\n        'loader':           loader,\n        'function':         function,\n        'lineno':           lineno,\n        'vars':             variables,\n        'pre_context':      pre_context,\n        'context_line':     context_line,\n        'post_context':     post_context,\n        'context_lineno':   context_lineno,\n        'source':           source\n    }", "archive": "pallets__werkzeug-17beb0a425765c32f8cd58078ba2eff7fb4b30cd.zip"}
{"id": "6b36f8", "repo": "pallets/werkzeug", "revision": "37b3fcc4aa517901b115001170267253bbbdfdc4", "path": "werkzeug/contrib/fixers.py", "modified": ["werkzeug/contrib/fixers.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.contrib.fixers\n    ~~~~~~~~~~~~~~~~~~~~~~~\n\n    .. versionadded:: 0.5\n\n    This module includes various helpers that fix bugs in web servers.  They may\n    be necessary for some versions of a buggy web server but not others.  We try\n    to stay updated with the status of the bugs as good as possible but you have\n    to make sure whether they fix the problem you encounter.\n\n    If you notice bugs in webservers not fixed in this module consider\n    contributing a patch.\n\n    :copyright: Copyright 2009 by the Werkzeug Team, see AUTHORS for more details.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nfrom urllib import unquote\n\n\nclass LighttpdCGIRootFix(object):\n    \"\"\"Wrap the application in this middleware if you are using lighttpd\n    with FastCGI or CGI and the application is mounted on the URL root.\n    \"\"\"\n\n    def __init__(self, app):\n        self.app = app\n\n    def __call__(self, environ, start_response):\n        environ['PATH_INFO'] = environ.get('SCRIPT_NAME', '') + \\\n                               environ.get('PATH_INFO', '')\n        environ['SCRIPT_NAME'] = ''\n        return self.app(environ, start_response)\n\n\nclass PathInfoFromRequestUriFix(object):\n    \"\"\"On windows environment variables are limited to the system charset\n    which makes it impossible to store the `PATH_INFO` variable in the\n    environment without loss of information on some systems.\n\n    This is for example a problem for CGI scripts on a Windows Apache.\n\n    This fixer works by recreating the `PATH_INFO` from `REQUEST_URI`,\n    `REQUEST_URL`, or `UNENCODED_URL` (whatever is available).  Thus the\n    fix can only be applied if the webserver supports either of these\n    variables.\n    \"\"\"\n\n    def __init__(self, app):\n        self.app = app\n\n    def __call__(self, environ, start_response):\n        for key in 'REQUEST_URL', 'REQUEST_URI', 'UNENCODED_URL':\n            if key not in environ:\n                continue\n            request_uri = unquote(environ[key])\n            script_name = unquote(environ.get('SCRIPT_NAME', ''))\n            if request_uri.startswith(script_name):\n                environ['PATH_INFO'] = request_uri[len(script_name):] \\\n                    .split('?', 1)[0]\n                break\n        return self.app(environ, start_response)\n\n\nclass ProxyFix(object):\n    \"\"\"This middleware can be applied to add HTTP proxy support to an\n    application that was not designed with HTTP proxies in mind.  It\n    sets `REMOTE_ADDR`, `HTTP_HOST` from `X-Forwarded` headers.\n\n    Werkzeug wrappers have builtin support for this by setting the\n    :attr:`~werkzeug.BaseRequest.is_behind_proxy` attribute to `True`.\n\n    Do not use this middleware in non-proxy setups for security reasons.\n\n    The original values of `REMOTE_ADDR` and `HTTP_HOST` are stored in\n    the WSGI environment as `werkzeug.proxy_fix.orig_remote_addr` and\n    `werkzeug.proxy_fix.orig_http_host`.\n    \"\"\"\n\n    def __init__(self, app):\n        self.app = app\n\n    def __call__(self, environ, start_response):\n        getter = environ.get\n        forwarded_for = getter('HTTP_X_FORWARDED_FOR', '').split(',')\n        forwarded_host = getter('HTTP_X_FORWARDED_HOST', '')\n        environ.update({\n            'werkzeug.proxy_fix.orig_remote_addr':  getter('REMOTE_ADDR'),\n            'werkzeug.proxy_fix.orig_http_host':    getter('HTTP_HOST')\n        })\n        if forwarded_for:\n            environ['REMOTE_ADDR'] = forwarded_for[0].strip()\n        if forwarded_host:\n            environ['HTTP_HOST'] = forwarded_host\n        return self.app(environ, start_response)\n\n\nclass HeaderRewriterFix(object):\n    \"\"\"This middleware can remove response headers and add others.  This\n    is for example useful to remove the `Date` header from responses if you\n    are using a server that adds that header, no matter if it's present or\n    not or to add `X-Powered-By` headers::\n\n        app = HeaderRewriterFix(app, remove_headers=['Date'],\n                                add_headers=[('X-Powered-By', 'WSGI')])\n\n    :param app: the WSGI application\n    :param remove_headers: a sequence of header keys that should be\n                           removed.\n    :param add_headers: a sequence of ``(key, value)`` tuples that should\n                        be added.\n    \"\"\"\n\n    def __init__(self, app, remove_headers=None, add_headers=None):\n        self.app = app\n        self.remove_headers = set(x.lower() for x in (remove_headers or ()))\n        self.add_headers = list(add_headers or ())\n\n    def __call__(self, environ, start_response):\n        def ", "suffix": "        return self.app(environ, rewriting_start_response)", "archive": "pallets__werkzeug-37b3fcc4aa517901b115001170267253bbbdfdc4.zip"}
{"id": "5a196f", "repo": "pallets/werkzeug", "revision": "5d6ae8b227eb6793b6b35001aa52f76394420076", "path": "werkzeug/debug/__init__.py", "modified": ["werkzeug/debug/__init__.py", "werkzeug/routing.py", "werkzeug/utils.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.debug\n    ~~~~~~~~~~~~~~\n\n    WSGI application traceback debugger.\n\n    :copyright: 2007 by Georg Brandl.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport sys\nimport inspect\nimport traceback\nimport code\n\nfrom werkzeug.debug.render import debug_page, load_resource\nfrom werkzeug.debug.util import ThreadedStream, Namespace, get_uid, \\\n     get_frame_info\nfrom werkzeug.utils import url_decode\n\n\nclass DebuggedApplication(object):\n    \"\"\"\n    Enables debugging support for a given application::\n\n        from werkzeug.debug import DebuggedApplication\n        from myapp import app\n        app = DebuggedApplication(app, evalex=True)\n\n    The `evalex` keyword argument allows evaluating expressions in a\n    traceback's frame context.\n\n    THIS IS A GAPING SECURITY HOLE IF PUBLICLY ACCESSIBLE!\n    \"\"\"\n\n    def __init__(self, application, evalex=False):\n        self.evalex = bool(evalex)\n        self.application = application\n        self.tracebacks = {}\n\n    def __call__(self, environ, start_response):\n        # exec code in open tracebacks or provide shared data\n        if environ.get('PATH_INFO', '').strip('/').endswith('__traceback__'):\n            parameters = url_decode(environ.get('QUERY_STRING', ''))\n            # shared data\n            if 'resource' in parameters and 'mimetype' in parameters:\n                data = load_resource(parameters['resource'])\n                start_response('200 OK', [\n                    ('Content-Type', str(parameters['mimetype'])),\n                    ('Content-Length', str(len(data)))\n                ])\n                yield data\n                return\n            # pastebin\n            elif parameters.get('pastetb'):\n                from xmlrpclib import ServerProxy\n                try:\n                    ", "suffix": "                data = environ['wsgi.input'].read(length)\n                s = ServerProxy('http://paste.pocoo.org/xmlrpc/')\n                paste_id = s.pastes.newPaste('pytb', data)\n                start_response('200 OK', [('Content-Type', 'text/plain')])\n                yield '{\"paste_id\": %d, \"url\": \"%s\"}' % (\n                    paste_id,\n                    'http://paste.pocoo.org/show/%d' % paste_id\n                )\n                return\n            # execute commands in an existing debug context\n            elif self.evalex:\n                try:\n                    tb = self.tracebacks[parameters['tb']]\n                    frame = parameters['frame']\n                    context = tb[frame]\n                    code = parameters['code']\n                except (IndexError, KeyError):\n                    pass\n                else:\n                    result = context.exec_expr(code)\n                    start_response('200 OK', [('Content-Type', 'text/plain')])\n                    yield result\n                    return\n\n        # wrap the application and catch errors.\n        appiter = None\n        try:\n            appiter = self.application(environ, start_response)\n            for line in appiter:\n                yield line\n        except:\n            ThreadedStream.install(environ)\n            exc_info = sys.exc_info()\n            try:\n                headers = [('Content-Type', 'text/html; charset=utf-8')]\n                start_response('500 INTERNAL SERVER ERROR', headers)\n            except:\n                pass\n            debug_context = self.create_debug_context(environ, exc_info)\n            yield debug_page(debug_context).encode('utf-8')\n\n        if hasattr(appiter, 'close'):\n            appiter.close()\n\n    def create_debug_context(self, environ, exc_info):\n        exception_type, exception_value, tb = exc_info\n        # skip first internal frame\n        if not tb.tb_next is None:\n            tb = tb.tb_next\n        plaintb = ''.join(traceback.format_exception(exception_type,\n                                                     exception_value, tb))\n        environ['wsgi.errors'].write(plaintb)\n\n        # load frames\n        frames = []\n        frame_map = {}\n        tb_uid = None\n        if ThreadedStream.can_interact():\n            tb_uid = get_uid()\n            frame_map = self.tracebacks[tb_uid] = {}\n\n        # walk through frames and collect information\n        while tb is not None:\n            if not tb.tb_frame.f_locals.get('__traceback_hide__', False):\n                if tb_uid:\n                    frame_uid = get_uid()\n                    frame_map[frame_uid] = InteractiveDebugger(tb.tb_frame)\n                else:\n                    frame_uid = None\n                frame = get_frame_info(tb)\n                frame['frame_uid'] = frame_uid\n                frames.append(frame)\n            tb = tb.tb_next\n\n        # guard for string exceptions\n        if isinstance(exception_type, str):\n            extypestr = 'string exception'\n            exception_value = exception_type\n        elif exception_type.__module__ == 'exceptions':\n            extypestr = exception_type.__name__\n        else:\n            extypestr = '%s.%s' % (\n                exception_type.__module__,\n                exception_type.__name__\n            )\n\n        # support for the werkzeug request object or fall back to\n        # WSGI environment\n        request = environ.get('werkzeug.request')\n        if request is not None:\n            req_vars = []\n            for varname in dir(request):\n                if varname[0] == '_':\n                    continue\n                value = getattr(request, varname)\n                if hasattr(value, 'im_func'):\n                    continue\n                req_vars.append((varname, value))\n        else:\n            req_vars = [('WSGI Environ', environ)]\n\n        return Namespace(\n            evalex =          self.evalex,\n            exception_type =  extypestr,\n            exception_value = str(exception_value),\n            frames =          frames,\n            last_frame =      frames[-1],\n            plaintb =         plaintb,\n            tb_uid =          tb_uid,\n            frame_map =       frame_map,\n            req_vars =        req_vars,\n        )\n\n\nclass InteractiveDebugger(code.InteractiveInterpreter):\n    \"\"\"\n    Subclass of the python interactive interpreter that\n    automatically captures stdout and buffers older input.\n    \"\"\"\n\n    def __init__(self, frame):\n        self.globals = frame.f_globals\n        code.InteractiveInterpreter.__init__(self, frame.f_locals)\n        self.prompt = '>>> '\n        self.buffer = []\n\n    def runsource(self, source):\n        prompt = self.prompt\n        sys.stdout.push()\n        try:\n            source_to_eval = ''.join(self.buffer + [source])\n            if code.InteractiveInterpreter.runsource(self,\n               source_to_eval, '<debugger>', 'single'):\n                self.prompt = '... '\n                self.buffer.append(source)\n            else:\n                self.prompt = '>>> '\n                del self.buffer[:]\n        finally:\n            return prompt + source + sys.stdout.release()\n\n    def runcode(self, code):\n        try:\n            exec code in self.globals, self.locals\n        except:\n            self.showtraceback()\n\n    def write(self, data):\n        sys.stdout.write(data)\n\n    def exec_expr(self, code):\n        rv = self.runsource(code)\n        if isinstance(rv, unicode):\n            return rv.encode('utf-8')\n        return rv", "archive": "pallets__werkzeug-5d6ae8b227eb6793b6b35001aa52f76394420076.zip"}
{"id": "b4f778", "repo": "pallets/werkzeug", "revision": "7fd02ca598a29681f1c0b27377b9751f9c8f8ce0", "path": "tests/contrib/test_cache.py", "modified": ["tests/contrib/test_cache.py", "werkzeug/contrib/cache.py"], "prefix": "import os, tempfile, shutil\n\nfrom werkzeug.contrib.cache import SimpleCache, FileSystemCache\n\n\ndef test_simplecache_get_dict():\n    \"\"\"SimpleCache.get_dict bug\"\"\"\n    cache = SimpleCache()\n    cache.set('a', 'a')\n    cache.set('b', 'b')\n    d = cache.get_dict('a', 'b')\n    assert 'a' in d\n    assert 'a' == d['a']\n    assert 'b' in d\n    assert 'b' == d['b']\n\n\ndef test_filesystemcache_set_get():\n    \"\"\"\n    test if FileSystemCache.set/get works\n    \"\"\"\n    tmp_dir = tempfile.mkdtemp()\n    try:\n        cache = FileSystemCache(cache_dir=tmp_dir)\n        for i in range(3):\n            cache.set(str(i), i * i)\n        for i in range(3):\n            result = cache.get(str(i))\n            assert result == i * i\n    finally:\n        shutil.rmtree(tmp_dir)\n\n\ndef test_filesystemcache_prune():\n    \"\"\"\n    test if FileSystemCache._prune works and keeps the cache entry count\n    below the given threshold.\n    \"\"\"\n    THRESHOLD = 13\n    tmp_dir = tempfile.mkdtemp()\n    cache = FileSystemCache(cache_dir=tmp_dir, threshold=THRESHOLD)\n    for i in range(2 * THRESHOLD):\n        cache.set(str(i), i)\n    cache_files = os.listdir(tmp_dir)\n    shutil.rmtree(tmp_dir)\n    assert len(cache_files) <= THRESHOLD\n\n\ndef test_filesystemcache_clear():\n    \"\"\"\n    test if FileSystemCache.clear works\n    \"\"\"\n    tmp_dir = tempfile.mkdtemp()\n    cache = FileSystemCache(cache_dir=tmp_dir)\n    cache.set('foo', 'bar')\n    cache_files = os.listdir(tmp_dir)\n    assert len(cache_files) == 1\n    cache.clear()\n    cache_files = os.listdir(tmp_dir)\n    assert len(cache_files) == 0\n    shutil.rmtree(tmp_dir)\n\n\ndef test_rediscache_get_set():\n    \"\"\"\n    test basic RedisCache capabilities\n    \"\"\"\n    cache = RedisCache()\n    cache.set('foo', 'bar')\n    assert cache.get('foo') == 'bar'\n\n\ndef test_rediscache_expire():\n    \"\"\"\n    test RedisCache handling expire time on keys\n    \"\"\"\n    ", "suffix": "\n\ndef test_rediscache_add():\n    \"\"\"\n    test if RedisCache.add() preserves existing keys\n    \"\"\"\n    cache = RedisCache()\n    # sanity check that add() works like set()\n    cache.add('foo', 'bar')\n    assert cache.get('foo') ==  'bar'\n    cache.add('foo', 'qux')\n    assert cache.get('foo') ==  'bar'\n\n\ndef test_rediscache_delete():\n    \"\"\"\n    test if RedisCache correctly deletes single key\n    \"\"\"\n    cache = RedisCache()\n    cache.add('foo', 'bar')\n    assert cache.get('foo') ==  'bar'\n    cache.delete('foo')\n    assert cache.get('foo') is None\n\n\ndef test_rediscache_delete_many():\n    \"\"\"\n    test if RedisCache correctly deletes many keys\n    \"\"\"\n    cache = RedisCache()\n    cache.add('foo', 'bar')\n    cache.add('spam', 'eggs')\n    cache.delete_many('foo', 'spam')\n    assert cache.get('foo') is None\n    assert cache.get('spam') is None\n", "archive": "pallets__werkzeug-7fd02ca598a29681f1c0b27377b9751f9c8f8ce0.zip"}
{"id": "e3216b", "repo": "pallets/werkzeug", "revision": "87568c058ec853f74d58fc1dcc8d7ae0d0363ecc", "path": "tests/sansio/test_multipart.py", "modified": ["src/werkzeug/sansio/multipart.py", "tests/sansio/test_multipart.py"], "prefix": "from werkzeug.datastructures import Headers\nfrom werkzeug.sansio.multipart import Data\nfrom werkzeug.sansio.multipart import Epilogue\nfrom werkzeug.sansio.multipart import Field\nfrom werkzeug.sansio.multipart import File\nfrom werkzeug.sansio.multipart import MultipartDecoder\nfrom werkzeug.sansio.multipart import MultipartEncoder\nfrom werkzeug.sansio.multipart import Preamble\n\n\ndef test_decoder_simple() -> None:\n    boundary = b\"---------------------------9704338192090380615194531385\"\n    decoder = MultipartDecoder(boundary)\n    data = \"\"\"\n-----------------------------9704338192090380615194531385\nContent-Disposition: form-data; name=\"fname\"\n\n\u00df\u2211\u0153\u00df\u2202\u0192\u00e5\u2202\n-----------------------------9704338192090380615194531385\nContent-Disposition: form-data; name=\"lname\"; filename=\"bob\"\n\nasdasd\n-----------------------------9704338192090380615194531385--\n    \"\"\".replace(\n        \"\\n\", \"\\r\\n\"\n    ).encode(\n        \"utf-8\"\n    )\n    decoder.receive_data(data)\n    decoder.receive_data(None)\n    events = [decoder.next_event()]\n    while not isinstance(events[-1], Epilogue) and len(events) < 6:\n        events.append(decoder.next_event())\n    assert events == [\n        Preamble(data=b\"\"),\n        Field(\n            name=\"fname\",\n            headers=Headers([(\"Content-Disposition\", 'form-data; name=\"fname\"')]),\n        ),\n        Data(data=\"\u00df\u2211\u0153\u00df\u2202\u0192\u00e5\u2202\".encode(), more_data=False),\n        File(\n            name=\"lname\",\n            filename=\"bob\",\n            headers=Headers(\n                [(\"Content-Disposition\", 'form-data; name=\"lname\"; filename=\"bob\"')]\n            ),\n        ),\n        Data(data=b\"asdasd\", more_data=False),\n        Epilogue(data=b\"    \"),\n    ]\n    encoder = MultipartEncoder(boundary)\n    result = b\"\"\n    for event in events:\n        result += encoder.send_event(event)\n    assert data == result\n\n\ndef test_chunked_boundaries() -> None:\n    boundary = b\"--boundary\"\n    decoder = MultipartDecoder(boundary)\n    decoder", "suffix": "    decoder.receive_data(b'name=\"fname\"\\r\\n\\r\\n')\n    assert isinstance(decoder.next_event(), Field)\n    decoder.receive_data(b\"longer than the boundary\")\n    assert isinstance(decoder.next_event(), Data)\n    decoder.receive_data(b\"also longer, but includes a linebreak\\r\\n--\")\n    assert isinstance(decoder.next_event(), Data)\n    assert isinstance(decoder.next_event(), NeedData)\n    decoder.receive_data(b\"--boundary--\\r\\n\")\n    event = decoder.next_event()\n    assert isinstance(event, Data)\n    assert not event.more_data\n    decoder.receive_data(None)\n    assert isinstance(decoder.next_event(), Epilogue)", "archive": "pallets__werkzeug-87568c058ec853f74d58fc1dcc8d7ae0d0363ecc.zip"}
{"id": "9eed8c", "repo": "pallets/werkzeug", "revision": "8aef581c1b84cc4e5e468defa59aa03ea721ce66", "path": "werkzeug/testsuite/contrib/iterio.py", "modified": ["werkzeug/contrib/iterio.py", "werkzeug/testsuite/contrib/iterio.py", "werkzeug/testsuite/wsgi.py", "werkzeug/wsgi.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.testsuite.iterio\n    ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Tests the iterio object.\n\n    :copyright: (c) 2011 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport unittest\nfrom functools import partial\n\nfrom werkzeug.testsuite import WerkzeugTestCase\nfrom werkzeug.contrib.iterio import IterIO, greenlet\n\n\nclass IterOTestSuite(WerkzeugTestCase):\n\n    def test_basic_native(self):\n        io = IterIO([\"Hello\", \"World\", \"1\", \"2\", \"3\"])\n        self.assert_equal(io.tell(), 0)\n        self.assert_equal(io.read(2), \"He\")\n        self.assert_equal(io.tell(), 2)\n        self.assert_equal(io.read(3), \"llo\")\n        self.assert_equal(io.tell(), 5)\n        io.seek(0)\n        self.assert_equal(io.read(5), \"Hello\")\n        self.assert_equal(io.tell(), 5)\n        self.assert_equal(io._buf, \"Hello\")\n        self.assert_equal(io.read(), \"World123\")\n        self.assert_equal(io.tell(), 13)\n        io.close()\n        assert io.closed\n\n        io = IterIO([\"Hello\\n\", \"World!\"])\n        self.assert_equal(io.readline(), 'Hello\\n')\n        self.assert_equal(io._buf, 'Hello\\n')\n        self.assert_equal(io.read(), 'World!')\n        self.assert_equal(io._buf, 'Hello\\nWorld!')\n        self.assert_equal(io.tell(), 12)\n        io.seek(0)\n        self.assert_equal(io.readlines(), ['Hello\\n', 'World!'])\n\n        io = IterIO([\"foo\\n\", \"bar\"])\n        io.seek(-4, 2)\n        self.assert_equal(io.read(4), '\\nbar')\n\n        self.assert_raises(IOError, io.seek, 2, 100)\n        io.close()\n        self.assert_raises(ValueError, io.read)\n\n    def test_basic_bytes(self):\n        io = IterIO([b\"Hello\", b\"World\", b\"1\", b\"2\", b\"3\"])\n        self.assert_equal(io.tell(), 0)\n        self.assert_equal(io.read(2), b\"He\")\n        self.assert_equal(io.tell(), 2)\n        self.assert_equal(io.read(3), b\"llo\")\n        self.assert_equal(io.tell(), 5)\n        io.seek(0)\n        self.assert_equal(io.read(5), b\"Hello\")\n        self.assert_equal(io.tell(), 5)\n        self.assert_equal(io._buf, b\"Hello\")\n        self.assert_equal(io.read(), b\"World123\")\n        self.assert_equal(io.tell(), 13)\n        io.close()\n        assert io.closed\n\n        io = IterIO([b\"Hello\\n\", b\"World!\"])\n        self.assert_equal(io.readline(), b'Hello\\n')\n        self.assert_equal(io._buf, b'Hello\\n')\n        self.assert_equal(io.read(), b'World!')\n        self.assert_equal(io._buf, b'Hello\\nWorld!')\n        self.assert_equal(io.tell(), 12)\n        io.seek(0)\n        self.assert_equal(io.readlines(), [b'Hello\\n', b'World!'])\n\n        io = IterIO([b\"foo\\n\", b\"bar\"])\n        io.seek(-4, 2)\n        self.assert_equal(io.read(4), b'\\nbar')\n\n        self.assert_raises(IOError, io.seek, 2, 100)\n        io.close()\n        self.assert_raises(ValueError, io.read)\n\n    def test_basic_unicode(self):\n        io = IterIO([u\"Hello\", u\"World\", u\"1\", u\"2\", u\"3\"])\n        self.assert_equal(io.tell(), 0)\n        self.assert_equal(io.read(2), u\"He\")\n        self.assert_equal(io.tell(), 2)\n        self.assert_equal(io.read(3), u\"llo\")\n        self.assert_equal(io.tell(), 5)\n        io.seek(0)\n        self.assert_equal(io.read(5), u\"Hello\")\n        self.assert_equal(io.tell(), 5)\n        self.assert_equal(io._buf, u\"Hello\")\n        self.assert_equal(io.read(), u\"World123\")\n        self.assert_equal(io.tell(), 13)\n        io.close()\n        assert io.closed\n\n        io = IterIO([u\"Hello\\n\", u\"World!\"])\n        self.assert_equal(io.readline(), u'Hello\\n')\n        self.assert_equal(io._buf, u'Hello\\n')\n        self.assert_equal(io.read(), u'World!')\n        self.assert_equal(io._buf, u'Hello\\nWorld!')\n        self.assert_equal(io.tell(), 12)\n        io.seek(0)\n        self.assert_equal(io.readlines(), [u'Hello\\n', u'World!'])\n\n        io = IterIO([u\"foo\\n\", u\"bar\"])\n        io.seek(-4, 2)\n        self.assert_equal(io.read(4), u'\\nbar')\n\n        self.assert_raises(IOError, io.seek, 2, 100)\n        io.close()\n        self.assert_raises(ValueError, io.read)\n\n    def test_sentinel_cases(self):\n        io = IterIO([])\n        self.assert_strict_equal(io.read(), '')\n        io = IterIO([], b'')\n        self.assert_strict_equal(io.read(), b'')\n        io = IterIO(", "suffix": "        io = IterIO([b''])\n        self.assert_strict_equal(io.read(), b'')\n        io = IterIO([u''])\n        self.assert_strict_equal(io.read(), u'')\n\n        io = IterIO([])\n        self.assert_strict_equal(io.readline(), '')\n        io = IterIO([], b'')\n        self.assert_strict_equal(io.readline(), b'')\n        io = IterIO([], u'')\n        self.assert_strict_equal(io.readline(), u'')\n\n        io = IterIO([])\n        self.assert_strict_equal(io.readline(), '')\n        io = IterIO([b''])\n        self.assert_strict_equal(io.readline(), b'')\n        io = IterIO([u''])\n        self.assert_strict_equal(io.readline(), u'')\n\n\nclass IterITestSuite(WerkzeugTestCase):\n\n    def test_basic(self):\n        def producer(out):\n            out.write('1\\n')\n            out.write('2\\n')\n            out.flush()\n            out.write('3\\n')\n        iterable = IterIO(producer)\n        self.assert_equal(next(iterable), '1\\n2\\n')\n        self.assert_equal(next(iterable), '3\\n')\n        self.assert_raises(StopIteration, partial(next, iterable))\n\n\ndef suite():\n    suite = unittest.TestSuite()\n    suite.addTest(unittest.makeSuite(IterOTestSuite))\n    if greenlet is not None:\n        suite.addTest(unittest.makeSuite(IterITestSuite))\n    return suite", "archive": "pallets__werkzeug-8aef581c1b84cc4e5e468defa59aa03ea721ce66.zip"}
{"id": "5149eb", "repo": "pallets/werkzeug", "revision": "8c8324f0b45333e304b1b62aa31f9a60fbb1a124", "path": "werkzeug/serving.py", "modified": ["werkzeug/serving.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.serving\n    ~~~~~~~~~~~~~~~~\n\n    This module wraps the `wsgiref` module so that it reloads code\n    automatically. Works with any WSGI application but it won't help in\n    non `wsgiref` environments. Use it only for development.\n\n    Usage::\n\n        from werkzeug.serving import run_simple\n        from myproject import make_app\n        run_simple('localhost', 8080, make_app())\n\n    :copyright: 2007 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport os\nimport socket\nimport sys\nimport time\nimport thread\nfrom wsgiref.simple_server import ServerHandler, WSGIRequestHandler, \\\n     WSGIServer\nfrom SocketServer import ThreadingMixIn, ForkingMixIn\n\n\nclass BaseRequestHandler(WSGIRequestHandler):\n    \"\"\"\n    Subclass of the normal request handler that thinks it is\n    threaded or something like that. The default wsgiref handler\n    has wrong information so we need this class.\n    \"\"\"\n    multithreaded = False\n    multiprocess = False\n    _handler_class = None\n\n    def get_handler(self):\n        handler = self._handler_class\n        if handler is None:\n            class handler(ServerHandler):\n                wsgi_multithread = self.multithreaded\n                wsgi_multiprocess = self.multipro", "suffix": "        return rv\n\n    def handle(self):\n        self.raw_requestline = self.rfile.readline()\n        if self.parse_request():\n            self.get_handler().run(self.server.get_app())\n\n\ndef make_server(host, port, app=None, threaded=False, processes=1):\n    \"\"\"\n    Create a new wsgiref server that is either threaded, or forks\n    or just processes one request after another.\n    \"\"\"\n    if threaded and processes > 1:\n        raise ValueError(\"cannot have a multithreaded and \"\n                         \"multi process server.\")\n    elif threaded:\n        class handler(BaseRequestHandler):\n            multithreaded = True\n        class server(ThreadingMixIn, WSGIServer):\n            pass\n    elif processes > 1:\n        class handler(BaseRequestHandler):\n            multiprocess = True\n            max_children = processes - 1\n        class server(ForkingMixIn, WSGIServer):\n            pass\n    else:\n        handler = BaseRequestHandler\n        server = WSGIServer\n    srv = server((host, port), handler)\n    srv.set_app(app)\n    return srv\n\n\ndef reloader_loop(extra_files):\n    \"\"\"When this function is run from the main thread, it will force other\n    threads to exit when any modules currently loaded change.\n\n    :param extra_files: a list of additional files it should watch.\n    \"\"\"\n    mtimes = {}\n    while True:\n        for filename in filter(None, [getattr(module, '__file__', None)\n                                      for module in sys.modules.values()] +\n                                     extra_files):\n            while not os.path.isfile(filename):\n                filename = os.path.dirname(filename)\n                if not filename:\n                    break\n            if not filename:\n                continue\n\n            if filename[-4:] in ('.pyc', '.pyo'):\n                filename = filename[:-1]\n\n            mtime = os.stat(filename).st_mtime\n            if filename not in mtimes:\n                mtimes[filename] = mtime\n                continue\n            if mtime > mtimes[filename]:\n                sys.exit(3)\n        time.sleep(1)\n\n\ndef restart_with_reloader():\n    \"\"\"Spawn a new Python interpreter with the same arguments as this one,\n    but running the reloader thread.\"\"\"\n    while True:\n        print '* Restarting with reloader...'\n        args = [sys.executable] + sys.argv\n        if sys.platform == 'win32':\n            args = ['\"%s\"' % arg for arg in args]\n        new_environ = os.environ.copy()\n        new_environ['RUN_MAIN'] = 'true'\n        exit_code = os.spawnve(os.P_WAIT, sys.executable, args, new_environ)\n        if exit_code != 3:\n            return exit_code\n\n\ndef run_with_reloader(main_func, extra_watch):\n    \"\"\"\n    Run the given function in an independent python interpreter.\n    \"\"\"\n    if os.environ.get('RUN_MAIN') == 'true':\n        thread.start_new_thread(main_func, ())\n        try:\n            reloader_loop(extra_watch)\n        except KeyboardInterrupt:\n            return\n    try:\n        sys.exit(restart_with_reloader())\n    except KeyboardInterrupt:\n        pass\n\n\ndef run_simple(hostname, port, application, use_reloader=False,\n               extra_files=None):\n    \"\"\"\n    Start an application using wsgiref and with an optional reloader.\n    \"\"\"\n    from wsgiref.simple_server import make_server\n    def inner():\n        srv = make_server(hostname, port, application)\n        try:\n            srv.serve_forever()\n        except KeyboardInterrupt:\n            pass\n\n    if os.environ.get('RUN_MAIN') != 'true':\n        print '* Running on http://%s:%d/' % (hostname, port)\n    if use_reloader:\n        # Create and destroy a socket so that any exceptions are raised before we\n        # spawn a separate Python interpreter and loose this ability.\n        test_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        test_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        test_socket.bind((hostname, port))\n        test_socket.close()\n        run_with_reloader(inner, extra_files or [])\n    else:\n        inner()", "archive": "pallets__werkzeug-8c8324f0b45333e304b1b62aa31f9a60fbb1a124.zip"}
{"id": "6ddeac", "repo": "pallets/werkzeug", "revision": "931444743a249e24b04f7989cfc14559c60139f0", "path": "werkzeug/testsuite/utils.py", "modified": ["werkzeug/testsuite/utils.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.testsuite.utils\n    ~~~~~~~~~~~~~~~~~~~~~~~~\n\n    General utilities.\n\n    :copyright: (c) 2011 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport unittest\n\nfrom werkzeug.testsuite import WerkzeugTestCase\n\nfrom werkzeug import utils\n\n\nclass GeneralUtilityTestCase(WerkzeugTestCase):\n\n    def test_redirect(self):\n        resp = utils.redirect(u'/f\u00fc\u00fcb\u00e4r')\n        assert '/f%C3%BC%C3%BCb%C3%A4r' in resp.data\n        assert resp.headers['Location'] == '/f%C3%BC%C3%BCb%C3%A4r'\n        assert resp.status_code == 302\n\n        resp = utils.redirect(u'http://\u2603.net/', 307)\n        assert 'http://xn--n3h.net/' in resp.data\n        assert resp.headers['Location'] == 'http://xn--n3h.net/'\n        assert resp.status_code == 307\n\n        resp = utils.redirect('http://example.com/', 305)\n        assert resp.headers['Location'] == 'http://example.com/'\n        assert resp.status_code == 305\n\n    def test_cached_property(self):\n        foo = []\n        class A(object):\n            def prop(self):\n                foo.append(42)\n                return 42\n            prop = utils.cached_property(prop)\n\n        a = A()\n        p = a.prop\n        q = a.prop\n        assert p == q == 42\n        assert foo == [42]\n\n        foo = []\n        class A(object):\n            def _prop(self):\n                foo.append(42)\n                return 42\n            prop = utils.cached_property(_prop, name='prop')\n            del _prop\n\n        a = A()\n        p = a.prop\n        q = a.prop\n        assert p == q == 42\n        assert foo == [42]\n\n    def test_environ_property(self):\n        class A(object):\n            environ = {'string': 'abc', 'number': '42'}\n\n            string = utils.environ_property('string')\n            missing = utils.environ_property('missing', 'spam')\n            read_only = utils.environ_property('number')\n            number = utils.environ_property('number', load_func=int)\n            broken_number = utils.environ_property('broken_number', load_func=int)\n            date = utils.environ_property('date', None, parse_date, http_date,\n                                    read_only=False)\n            foo = utils.environ_property('foo')\n\n        a = A()\n        assert a.string == 'abc'\n        assert a.missing == 'spam'\n        def test_assign():\n            a.read_only = 'something'\n        self.assert_raises(AttributeError, test_assign)\n        assert a.number == 42\n        assert a.broken_number == None\n        assert a.date is None\n        a.date = datetime(2008, 1, 22, 10, 0, 0, 0)\n        assert a.environ['date'] == 'Tue, 22 Jan 2008 10:00:00 GMT'\n\n    def test_escape(self):\n        class Foo(str):\n            def __html__(self):\n                return unicode(self)\n        assert utils.escape(None) == ''\n        assert utils.escape(42) == '42'\n        assert utils.escape('<>') == '&lt;&gt;'\n        assert utils.escape('\"foo\"') == '\"foo\"'\n        assert utils.escape('\"foo\"', True) == '&quot;foo&quot;'\n        assert utils.escape(Foo('<foo>')) == '<foo>'\n\n    def test_unescape(self):\n        assert utils.unescape('&lt;&auml;&gt;') == u'<\u00e4>'\n\n    def test_run_wsgi_app(self):\n        def foo(environ, start_response):\n            start_response('200 OK', [('Content-Type', 'text/plain')])\n            yield '1'\n            yield '2'\n            yield '3'\n\n        app_iter, status, headers = run_wsgi_app(foo, {})\n        assert status == '200 OK'\n        assert headers == [('Content-Type', 'text/plain')]\n        assert app_iter.next() == '1'\n        assert app_iter.next() == '2'\n        assert app_iter.next() == '3'\n        self.assert_raises(StopIteration, app_iter.next)\n\n        got_close = []\n        class CloseIter(object):\n            def __init__(self):\n                self.iterated = False\n            def __iter__(self):\n                ", "suffix": "\n        def bar(environ, start_response):\n            start_response('200 OK', [('Content-Type', 'text/plain')])\n            return CloseIter()\n\n        app_iter, status, headers = run_wsgi_app(bar, {})\n        assert status == '200 OK'\n        assert headers == [('Content-Type', 'text/plain')]\n        assert app_iter.next() == 'bar'\n        self.assert_raises(StopIteration, app_iter.next)\n        app_iter.close()\n\n        assert run_wsgi_app(bar, {}, True)[0] == ['bar']\n\n        assert len(got_close) == 2\n\n    def test_import_string(self):\n        import cgi\n        from werkzeug.debug import DebuggedApplication\n        assert utils.import_string('cgi.escape') is cgi.escape\n        assert utils.import_string(u'cgi.escape') is cgi.escape\n        assert utils.import_string('cgi:escape') is cgi.escape\n        assert utils.import_string('XXXXXXXXXXXX', True) is None\n        assert utils.import_string('cgi.XXXXXXXXXXXX', True) is None\n        assert utils.import_string(u'cgi.escape') is cgi.escape\n        assert utils.import_string(u'werkzeug.debug.DebuggedApplication') is DebuggedApplication\n        self.assert_raises(ImportError, utils.import_string, 'XXXXXXXXXXXXXXXX')\n        self.assert_raises(ImportError, utils.import_string, 'cgi.XXXXXXXXXX')\n\n    def test_find_modules(self):\n        assert list(utils.find_modules('werkzeug.debug')) == \\\n            ['werkzeug.debug.console', 'werkzeug.debug.repr',\n             'werkzeug.debug.tbtools']\n\n    def test_html_builder(self):\n        html = utils.html\n        xhtml = utils.xhtml\n        assert html.p('Hello World') == '<p>Hello World</p>'\n        assert html.a('Test', href='#') == '<a href=\"#\">Test</a>'\n        assert html.br() == '<br>'\n        assert xhtml.br() == '<br />'\n        assert html.img(src='foo') == '<img src=\"foo\">'\n        assert xhtml.img(src='foo') == '<img src=\"foo\" />'\n        assert html.html(\n            html.head(\n                html.title('foo'),\n                html.script(type='text/javascript')\n            )\n        ) == '<html><head><title>foo</title><script type=\"text/javascript\">' \\\n             '</script></head></html>'\n        assert html('<foo>') == '&lt;foo&gt;'\n        assert html.input(disabled=True) == '<input disabled>'\n        assert xhtml.input(disabled=True) == '<input disabled=\"disabled\" />'\n        assert html.input(disabled='') == '<input>'\n        assert xhtml.input(disabled='') == '<input />'\n        assert html.input(disabled=None) == '<input>'\n        assert xhtml.input(disabled=None) == '<input />'\n        assert html.script('alert(\"Hello World\");') == '<script>' \\\n            'alert(\"Hello World\");</script>'\n        assert xhtml.script('alert(\"Hello World\");') == '<script>' \\\n            '/*<![CDATA[*/alert(\"Hello World\");/*]]>*/</script>'\n\n    def test_validate_arguments(self):\n        take_none = lambda: None\n        take_two = lambda a, b: None\n        take_two_one_default = lambda a, b=0: None\n\n        assert utils.validate_arguments(take_two, (1, 2,), {}) == ((1, 2), {})\n        assert utils.validate_arguments(take_two, (1,), {'b': 2}) == ((1, 2), {})\n        assert utils.validate_arguments(take_two_one_default, (1,), {}) == ((1, 0), {})\n        assert utils.validate_arguments(take_two_one_default, (1, 2), {}) == ((1, 2), {})\n\n        self.assert_raises(utils.ArgumentValidationError,\n            utils.validate_arguments, take_two, (), {})\n\n        assert utils.validate_arguments(take_none, (1, 2,), {'c': 3}) == ((), {})\n        self.assert_raises(utils.ArgumentValidationError,\n               utils.validate_arguments, take_none, (1,), {}, drop_extra=False)\n        self.assert_raises(utils.ArgumentValidationError,\n               utils.validate_arguments, take_none, (), {'a': 1}, drop_extra=False)\n\n    def test_header_set_duplication_bug(self):\n        headers = Headers([\n            ('Content-Type', 'text/html'),\n            ('Foo', 'bar'),\n            ('Blub', 'blah')\n        ])\n        headers['blub'] = 'hehe'\n        headers['blafasel'] = 'humm'\n        assert headers == Headers([\n            ('Content-Type', 'text/html'),\n            ('Foo', 'bar'),\n            ('blub', 'hehe'),\n            ('blafasel', 'humm')\n        ])\n\n    def test_append_slash_redirect(self):\n        def app(env, sr):\n            return utils.append_slash_redirect(env)(env, sr)\n        client = Client(app, BaseResponse)\n        response = client.get('foo', base_url='http://example.org/app')\n        assert response.status_code == 301\n        assert response.headers['Location'] == 'http://example.org/app/foo/'\n\n    def test_cached_property_doc(self):\n        @utils.cached_property\n        def foo():\n            \"\"\"testing\"\"\"\n            return 42\n        assert foo.__doc__ == 'testing'\n        assert foo.__name__ == 'foo'\n        assert foo.__module__ == __name__\n\n\ndef suite():\n    suite = unittest.TestSuite()\n    suite.addTest(unittest.makeSuite(GeneralUtilityTestCase))\n    return suite", "archive": "pallets__werkzeug-931444743a249e24b04f7989cfc14559c60139f0.zip"}
{"id": "a4a1ff", "repo": "pallets/werkzeug", "revision": "9d53c19dd0b95a354b9760e33ea7d227b71e2cd1", "path": "werkzeug/testsuite/local.py", "modified": ["werkzeug/local.py", "werkzeug/testsuite/local.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.testsuite.local\n    ~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Local and local proxy tests.\n\n    :copyright: (c) 2011 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport time\nimport unittest\nfrom threading import Thread\n\nfrom werkzeug.testsuite import WerkzeugTestCase\n\nfrom werkzeug import local\n\n\nclass LocalTestCase(WerkzeugTestCase):\n\n    def test_basic_local(self):\n        l = local.Local()\n        l.foo = 0\n        values = []\n        def value_setter(idx):\n            time.sleep(0.01 * idx)\n            l.foo = idx\n            time.sleep(0.02)\n            values.append(l.foo)\n        threads = [Thread(target=value_setter, args=(x,))\n                   for x in [1, 2, 3]]\n        for thread in threads:\n            thread.start()\n        time.sleep(0.2)\n        assert sorted(values) == [1, 2, 3]\n\n        def delfoo():\n            del l.foo\n        delfoo()\n        self.assert_raises(AttributeError, lambda: l.foo)\n        self.assert_raises(AttributeError, delfoo)\n\n        local.release_local(l)\n\n    def test_local_release(self):\n        loc = local.Local()\n        loc.foo = 42\n        local.release_local(loc)\n        assert not hasattr(loc, 'foo')\n\n        ls = local.LocalStack()\n        ls.push(42)\n        local.release_local(ls)\n        assert ls.top is None\n\n    def test_local_proxy(self):\n        foo = []\n        ls = local.LocalProxy(lambda: foo)\n        ls.append(42)\n        ls.append(23)\n        ls[1:] = [1, 2, 3]\n        assert foo == [42, 1, 2, 3]\n        assert repr(foo) == repr(ls)\n        assert foo[0] == 42\n        foo += [1]\n        assert list(foo) == [42, 1, 2, 3, 1]\n\n    def test_local_proxy_operations_math(self):\n        foo = 2\n        ls = local.LocalProxy(lambda: foo)\n        assert ls + 1 == 3\n        assert 1 + ls == 3\n        assert ls - 1 == 1\n        assert 1 - ls == -1\n        assert ls * 1 == 2\n        assert 1 * ls == 2\n        assert ls / 1 == 2\n        assert 1.0 / ls == 0.5\n        assert ls // 1.0 == 2.0\n        assert 1.0 // ls == 0.0\n        assert ls % 2 == 0\n        assert 2 % ls == 0\n\n    def test_local_proxy_operations_strings(self):\n        _foo = \"foo\"\n        foo = local.LocalProxy(lambda: foo)\n        assert", "suffix": "        assert foo * 2 == \"foofoo\"\n\n        _foo = \"foo %s\"\n        assert foo % (\"bar\",) == \"foo bar\"\n\n    def test_local_stack(self):\n        ident = local.get_ident()\n\n        ls = local.LocalStack()\n        assert ident not in ls._local.__storage__\n        assert ls.top is None\n        ls.push(42)\n        assert ident in ls._local.__storage__\n        assert ls.top == 42\n        ls.push(23)\n        assert ls.top == 23\n        ls.pop()\n        assert ls.top == 42\n        ls.pop()\n        assert ls.top is None\n        assert ls.pop() is None\n        assert ls.pop() is None\n\n        proxy = ls()\n        ls.push([1, 2])\n        assert proxy == [1, 2]\n        ls.push((1, 2))\n        assert proxy == (1, 2)\n        ls.pop()\n        ls.pop()\n        assert repr(proxy) == '<LocalProxy unbound>'\n\n        assert ident not in ls._local.__storage__\n\n    def test_local_proxies_with_callables(self):\n        foo = 42\n        ls = local.LocalProxy(lambda: foo)\n        assert ls == 42\n        foo = [23]\n        ls.append(42)\n        assert ls == [23, 42]\n        assert foo == [23, 42]\n\n    def test_custom_idents(self):\n        ident = 0\n        loc = local.Local()\n        stack = local.LocalStack()\n        mgr = local.LocalManager([loc, stack], ident_func=lambda: ident)\n\n        loc.foo = 42\n        stack.push({'foo': 42})\n        ident = 1\n        loc.foo = 23\n        stack.push({'foo': 23})\n        ident = 0\n        assert loc.foo == 42\n        assert stack.top['foo'] == 42\n        stack.pop()\n        assert stack.top is None\n        ident = 1\n        assert loc.foo == 23\n        assert stack.top['foo'] == 23\n        stack.pop()\n        assert stack.top is None\n\n\ndef suite():\n    suite = unittest.TestSuite()\n    suite.addTest(unittest.makeSuite(LocalTestCase))\n    return suite", "archive": "pallets__werkzeug-9d53c19dd0b95a354b9760e33ea7d227b71e2cd1.zip"}
{"id": "0800bd", "repo": "pallets/werkzeug", "revision": "b1194bf164ee6d8e14b32b6714046622a13f9075", "path": "tests/test_wsgi.py", "modified": ["tests/test_wsgi.py", "werkzeug/wsgi.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.wsgi test\n    ~~~~~~~~~~~~~~~~~~\n\n    Tests the WSGI utilities.\n\n    :copyright: (c) 2010 by the Werkzeug Team, see AUTHORS for more details.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nfrom os import path\nfrom cStringIO import StringIO\n\nfrom nose.tools import assert_raises\n\nfrom werkzeug import Client, create_environ, BaseResponse, run_wsgi_app\nfrom werkzeug.exceptions import BadRequest\n\nfrom werkzeug.wsgi import SharedDataMiddleware, get_host, responder, \\\n     LimitedStream, pop_path_info, peek_path_info, extract_path_info\n\n\ndef test_shareddatamiddleware_get_file_loader():\n    \"\"\"Shared middleware file loader lookup\"\"\"\n    app = SharedDataMiddleware(None, {})\n    assert callable(app.get_file_loader('foo'))\n\n\ndef test_shared_data_middleware():\n    \"\"\"Shared data middleware\"\"\"\n    def null_application(environ, start_response):\n        start_response('404 NOT FOUND', [('Content-Type', 'text/plain')])\n        yield 'NOT FOUND'\n    app = SharedDataMiddleware(null_application, {\n        '/':        path.join(path.dirname(__file__), 'res'),\n        '/sources': path.join(path.dirname(__file__), 'res'),\n        '/pkg':     ('werkzeug.debug', 'shared')\n    })\n\n    for p in '/test.txt', '/sources/test.txt':\n        app_iter, status, headers = run_wsgi_app(app, create_environ(p))\n        assert status == '200 OK'\n        assert ''.join(app_iter).strip() == 'FOUND'\n\n    app_iter, status, headers = run_wsgi_app(app, create_environ('/pkg/body.tmpl'))\n    contents = ''.join(app_iter)\n    assert 'Werkzeug Debugger' in contents\n\n    app_iter, status, headers = run_wsgi_app(app, create_environ('/missing'))\n    assert status == '404 NOT FOUND'\n    assert ''.join(app_iter).strip() == 'NOT FOUND'\n\n\ndef test_get_host():\n    \"\"\"Host lookup\"\"\"\n    env = {'HTTP_X_FORWARDED_HOST': 'example.org',\n           'SERVER_NAME': 'bullshit', 'HOST_NAME': 'ignore me dammit'}\n    assert get_host(env) == 'example.org'\n    assert get_host(create_environ('/', 'http://example.org')) \\\n        == 'example.org'\n\n\ndef test_responder():\n    \"\"\"Responder decorator\"\"\"\n    def foo(environ, start_response):\n        return BaseResponse('Test')\n    client = Client(responder(foo), BaseResponse)\n    response = client.get('/')\n    assert response.status_code == 200\n    assert response.data == 'Test'\n\n\ndef test_pop_path_info():\n    \"\"\"Test path info popping in the utils\"\"\"\n    original_env = {'SCRIPT_NAME': '/foo', 'PATH_INFO': '/a/b///c'}\n\n    # regular path info popping\n    def assert_tuple(script_name, path_info):\n        assert env.get('SCRIPT_NAME') == script_name\n        assert env.get('PATH_INFO') == path_info\n    env = original_env.copy()\n    pop = lambda: pop_path_info(env)\n\n    assert_tuple('/foo', '/a/b///c')\n    assert pop() == 'a'\n    assert_tuple('/foo/a', '/b///c')\n    assert pop() == 'b'\n    assert_tuple('/foo/a/b', '///c')\n    assert pop() == 'c'\n    assert_tuple('/foo/a/b///c', '')\n    assert pop() is None\n\n\ndef test_peek_path_info():\n    \"\"\"Test path info peeking in wrappers and utils\"\"\"\n    env = {'SCRIPT_NAME': '/foo', 'PATH_INFO': '/aaa/b///c'}\n\n    assert peek_path_info(env) == 'aaa'\n    assert peek_path_info(env) == 'aaa'\n\n\nclass RaisingLimitedStream(LimitedStream):\n\n    def on_exhausted(self):\n        raise BadRequest('input stream exhausted')\n\n\ndef test_limited_stream():\n    \"\"\"Test the LimitedStream\"\"\"\n    io = StringIO('123456')\n    stream = RaisingLimitedStream(io, 3)\n    assert stream.read() == '123'\n    assert_raises(BadRequest, stream.read)\n\n    io = StringIO('123456')\n    stream = RaisingLimitedStream(io, 3)\n    assert stream.read(1) == '1'\n    assert stream.read(1) == '2'\n    assert stream.read(1) == '3'\n    assert_raises(BadRequest, stream.read)\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readline() == '123456\\n'\n    assert stream.readline() == 'ab'\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readlines() == ['123456\\n', 'ab']\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readlines(2) == ['12']\n    assert stream.readlines(2) == ['34']\n    assert stream.readlines() == ['56\\n', 'ab']\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readline(100) == '123456\\n'\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readlines(100) == ['123456\\n', 'ab']\n\n    io = StringIO('123456')\n    stream = LimitedStream(io, 3)\n    assert stream.read(1) == '1'\n    assert stream.read(1) == '2'\n    assert stream.read() == '3'\n    assert stream.read() == ''\n\n\ndef test_path_info_extraction():\n    \"\"\"PATH INFO extraction feature\"\"\"\n    x = extract_path_info('http://example.com/app', '/app/hello')\n    assert x == u'/hello'\n    x = extract_path_info('http://example.com/app',\n                          'https://example.com/app/hello')\n    assert x == u'/hello'\n    x = extract_path_info('http://example.com/app/',\n                          'https://example.com/app/hello')\n    assert x == u'/hello'\n    x = extract_path_info('http://example.com/app/',\n                          'https://example.com/app')\n    assert x == u'/'\n    x = extract_path_info(u'http://\u2603.net/', u'/f\u00f6\u00f6b\u00e4r')\n    assert x == u'/f\u00f6\u00f6b\u00e4r'\n    x = extract_path_info(u'http://\u2603.net/x', u'http://\u2603.net/x/f\u00f6\u00f6b\u00e4r')\n    assert x == u'/f\u00f6\u00f6b\u00e4r'\n\n    env = create_environ(u'/f\u00f6\u00f6b\u00e4r', u'http://\u2603.net/x/')\n    x = extract_path_info(env, u'http://\u2603.net/x/f\u00f6\u00f6b\u00e4r')\n    assert x == u'/f\u00f6\u00f6b\u00e4r'\n\n    x = extract_path_info('http://example.com/app/',\n                          'https://example.com/a/hello')\n    assert x is None\n    x = extract_path_info('http://example.com/app/',\n                          'https://example.com/app/hello',\n                          collapse_http_schemes=False)\n    assert x is None\n\n\ndef test_get_host_fallback():\n    \"\"\"Test non Host header server name guessing\"\"\"\n    assert get_host({\n        'SERVER_NAME':      'foobar.example.com',\n        'wsgi.url_scheme':  'http',\n        'SERVER_PORT':      '80'\n    }) == 'foobar.example.com'\n    assert get_host({\n        'SERVER_NAME':      'foobar.example.com',\n        'wsgi.url_scheme':  'http',\n        'SERVER_PORT':      '81'\n    }) == 'foobar.example.com:81'\n\n\ndef test_multi_part_line_breaks():\n    test_stream = StringIO('abcdef\\r\\nghijkl\\r\\nmnopqrstuvwxyz\\r\\nABCDEFGHIJK')\n    lines = list(make_line_iter(test_stream, limit=1024, buffer_size=16))\n    asse", "suffix": "    assert lines == ['abc\\r\\n', 'This line is broken by the buffer length.\\r\\n', 'Foo bar baz']", "archive": "pallets__werkzeug-b1194bf164ee6d8e14b32b6714046622a13f9075.zip"}
{"id": "b18d47", "repo": "pallets/werkzeug", "revision": "ca7e0e64863a5d337245a894dd429c60caf4a5e4", "path": "werkzeug/testsuite/security.py", "modified": ["werkzeug/security.py", "werkzeug/testsuite/security.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.testsuite.security\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Tests the security helpers.\n\n    :copyright: (c) 2013 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport os\nimport unittest\n\nfrom werkzeug.testsuite import WerkzeugTestCase\n\nfrom werkzeug.security import check_password_hash, generate_password_hash, \\\n     safe_join\n\n\nclass SecurityTestCase(WerkzeugTestCase):\n\n    def test_password_hashing(self):\n        hash1 = generate_password_hash('default')\n        hash2 = generate_password_hash(u'default', method='sha1')\n        assert hash1 != hash2\n        assert check_password_hash(hash1, 'default')\n        assert check_password_hash(hash2, 'default')\n        assert hash1.startswith('sha1$')\n        assert hash2.startswith('sha1$')\n\n        fakehash = generate_password_hash('default', method='plain')\n        assert fakehash == 'plain$$default'\n        assert check_password_hash(fakehash, 'default')\n\n        mhash = generate_password_hash(u'default', method='md5')\n        assert mhash.startswith('md5$')\n        assert check_password_hash(mhash, 'default')\n\n        legacy = 'md5$$c21f969b5f03d33d43e04f8f136e7682'\n        assert check_password_hash(legacy, 'default')\n\n        legacy = u'md5$$c21f969b5f03d33d43e04f8f136e7682'\n        assert check_password_hash(legacy, 'default')\n\n    def test_safe_join(self):\n        assert safe_join('foo', 'bar/baz') == os.path.join('foo', 'bar/baz')\n        assert safe_join('foo', '../bar/baz') is None\n        if os.name == 'nt':\n            assert safe_join('foo', 'foo\\\\bar') is None\n\n    def test_pbkdf2(self):\n        def check(data, salt, iterations, keylen, expected):\n            rv = pbkdf2_hex(data, salt, iterations, keylen)\n            self.assert_equal(rv, expected)\n\n        # From RFC 6070\n        check('password', 'salt', 1, 20,\n              '0c60c80f961f0e71f3a9b524af6012062fe037a6')\n        check('password', 'salt', 2, 20,\n              'ea6c014dc72d6f8ccd1ed92ace1d41f0d8de8957')\n        check('password', 'salt', 4096, 20,\n              '4b007901b765489abead49d926f721d065a429c1')\n        check('passwordPASSWORDpassword', 'saltSALTsaltSALTsaltSALTsaltSALTsalt',\n              4096, 25, '3d2eec4fe41c849b80c8d83662c0e44a8b291a964cf2f07038')\n        check('pass\\x00word', 'sa\\x00lt', 4096, 16,\n              '56fa6aa75548099dcc37d7f03425e0c3')\n        # This one is from the RFC but it just takes for ages\n        ##check('password', 'salt', ", "suffix": "        check('password', 'ATHENA.MIT.EDUraeburn', 2, 32,\n              '01dbee7f4a9e243e988b62c73cda935da05378b93244ec8f48a99e61ad799d86')\n        check('password', 'ATHENA.MIT.EDUraeburn', 1200, 32,\n              '5c08eb61fdf71e4e4ec3cf6ba1f5512ba7e52ddbc5e5142f708a31e2e62b1e13')\n        check('X' * 64, 'pass phrase equals block size', 1200, 32,\n              '139c30c0966bc32ba55fdbf212530ac9c5ec59f1a452f5cc9ad940fea0598ed1')\n        check('X' * 65, 'pass phrase exceeds block size', 1200, 32,\n              '9ccad6d468770cd51b10e6a68721be611a8b4d282601db3b36be9246915ec82a')\n\n\ndef suite():\n    suite = unittest.TestSuite()\n    suite.addTest(unittest.makeSuite(SecurityTestCase))\n    return suite", "archive": "pallets__werkzeug-ca7e0e64863a5d337245a894dd429c60caf4a5e4.zip"}
{"id": "524af9", "repo": "pallets/werkzeug", "revision": "cfc58eee21872d853bfcb4fd06bac637fb4b2ef4", "path": "examples/manage-simplewiki.py", "modified": ["examples/manage-coolmagic.py", "examples/manage-couchy.py", "examples/manage-cupoftee.py", "examples/manage-i18nurls.py", "examples/manage-plnt.py", "examples/manage-shorty.py", "examples/manage-simplewiki.py", "examples/manage-webpylike.py"], "prefix": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"\n    Manage SimpleWiki\n    ~~~~~~~~~~~~~~~~~\n\n    This script provides some basic commands to debug and test SimpleWiki.\n\n    :copyright: (c) 2009 by the Werkzeug Team, see AUTHORS for more details.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport os\nfrom werkzeug import script\n\n\ndef make_wiki():\n    \"\"\"Helper function that creates a new wiki instance.\"\"\"\n    from simplewiki import SimpleWiki\n    database_uri = os.environ.get('SIMPLEWIKI_DATABASE_URI')\n    return SimpleWiki(database_uri or 'sqlite:////tmp/simplewiki.db')\n\n\ndef shell_init_func():\n    \"\"\"\n    Called on shell initialization.  Adds useful stuff to the namespace.\n    \"\"\"\n    from simplewiki import database\n    wiki = make_wiki()\n    wiki.bind_to_context()\n    return {\n        'wiki':     wiki,\n        'db':       database\n    }\n\n\naction_runserver = script.make_runserver(make_wiki, use_reloader=True)\naction_shell = script.make_shell(shell_init_func)\n\n\ndef action_initdb():\n    \"\"\"Initialize the database\"\"\"\n    make_wiki().init_database()\n\n\n@cl", "suffix": "@click.option('--no-reloader', is_flag=True, default=False)\n@click.option('--debugger', is_flag=True)\n@click.option('--no-evalex', is_flag=True, default=False)\n@click.option('--threaded', is_flag=True)\n@click.option('--processes', type=int, default=1, help=\"1\")\ndef runserver(hostname, port, no_reloader, debugger, no_evalex, threaded, processes):\n    \"\"\"Start a new development server.\"\"\"\n    app = make_wiki()\n    reloader = not no_reloader\n    evalex = not no_evalex\n    run_simple(hostname, port, app,\n               use_reloader=reloader, use_debugger=debugger,\n               use_evalex=evalex, threaded=threaded, processes=processes)\n\n\n@cli.command()\n@click.option('--no-ipython', is_flag=True, default=False)\ndef shell(no_ipython):\n    \"\"\"Start a new interactive python session.\"\"\"\n    banner = 'Interactive Werkzeug Shell'\n    namespace = make_shell()\n    if not no_ipython:\n        try:\n            try:\n                from IPython.frontend.terminal.embed import InteractiveShellEmbed\n                sh = InteractiveShellEmbed.instance(banner1=banner)\n            except ImportError:\n                from IPython.Shell import IPShellEmbed\n                sh = IPShellEmbed(banner=banner)\n        except ImportError:\n            pass\n        else:\n            sh(local_ns=namespace)\n            return\n    from code import interact\n    interact(banner, local=namespace)\n\nif __name__ == '__main__':\n    script.run()", "archive": "pallets__werkzeug-cfc58eee21872d853bfcb4fd06bac637fb4b2ef4.zip"}
{"id": "e8c39d", "repo": "pallets/werkzeug", "revision": "d3e0e015bc569fb9df1c7293726780b507ca3370", "path": "tests/sansio/test_utils.py", "modified": ["tests/sansio/test_utils.py"], "prefix": "import typing as t\n\nimport pytest\n\nfrom werkzeug.sansio.utils import get_host\n\n\n@pytest.mark.parametrize(\n    (\"scheme\", \"host_header\", \"server\", \"expected\"),\n    [\n        (\"http\", \"spam\", None, \"spam\"),\n        (\"http\", \"spam:80\", None, \"spam\"),\n        (\"https\", \"spam\", None, \"spam\"),\n        (\"https\", \"spam:443\", None, \"spam\"),\n        (\"http\", \"spam:8080\", None, \"spam:8080\"),\n        (\"ws\", \"spam\", None, \"spam\"),\n        (\"ws\", \"spam:80\", None, \"spam\"),\n        (\"wss\", \"spam\", None, \"spam\"),\n        (\"wss\", \"spam:443\", None, \"spam\"),\n        (\"http\", None, (\"spam\", 80), \"spam\"),\n        (\"http\", None, (\"spam\", 8080), \"spam:8080\"),\n        (\"http\", None, (\"unix/socket\", None), \"unix/socket\"),\n        (\"http\", \"spam\", (\"eggs\", 80), \"spam\"),\n    ],\n)\ndef test_get_host(\n    scheme: str,\n    host_header: t.Optional[str],\n    server: t.Optional[t.Tuple[str, t.Optional[int]]],\n    expected: str,\n) -> None:\n    assert get_host(scheme, host_header, server) == expected\n\n\n@pytest.mark.parametrize(\n    (\"http_content_length\", \"http_transfer_encoding\", \"expected\"),\n    [\n        (\"2\", None, 2),\n        ", "suffix": "def test_get_content_length(\n    http_content_length: str | None,\n    http_transfer_encoding: str | None,\n    expected: int | None,\n) -> None:\n    assert get_content_length(http_content_length, http_transfer_encoding) == expected", "archive": "pallets__werkzeug-d3e0e015bc569fb9df1c7293726780b507ca3370.zip"}
{"id": "5c5970", "repo": "pallets/werkzeug", "revision": "dc985a5da62143fa84b4142fa353ee98733ea833", "path": "werkzeug/debug/repr.py", "modified": ["werkzeug/debug/console.py", "werkzeug/debug/repr.py", "werkzeug/debug/tbtools.py"], "prefix": "# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.debug.repr\n    ~~~~~~~~~~~~~~~~~~~\n\n    This module implements object representations for debugging purposes.\n    Unlike the default repr these reprs expose a lot more information and\n    produce HTML instead of ASCII.\n\n    Together with the CSS and JavaScript files of the debugger this gives\n    a colorful and more compact output.\n\n    :copyright: Copyright 2008 by Armin Ronacher.\n    :license: BSD.\n\"\"\"\nimport sys\nimport re\nfrom traceback import format_exception_only\ntry:\n    from collections import deque\nexcept ImportError:\n    deque = None\nfrom cgi import escape\ntry:\n    set\nexcept NameError:\n    from sets import Set as set, ImmutableSet as frozenset\n\n\nRegexType = type(re.compile(''))\n\n\ndef debug_repr(obj):\n    \"\"\"Creates a debug repr of an object as HTML unicode string.\"\"\"\n    return DebugReprGenerator().repr(obj)\n\n\ndef _add_subclass_info(inner, obj, base):\n    if isinstance(base, tuple):\n        for base in base:\n            if type(obj) is base:\n                return inner\n    elif type(obj) is base:\n        return inner\n    module = ''\n    if obj.__class__.__module__ not in ('__builtin__', 'exceptions'):\n        module = '<span class=\"module\">%s.</span>' % obj.__class__.__module__\n    return '%s%s(%s)' % (module, obj.__class__.__name__, inner)\n\n\nclass DebugReprGenerator(object):\n\n    def __init__(self):\n        self._stack = []\n\n    def _sequence_repr_maker(left, right, base=object(), limit=8):\n        def proxy(self, obj, recursive):\n            if recursive:\n                return _add_subclass_info(left + '...' + right, obj, base)\n            buf = [left]\n            have_extended_section = False\n            for idx, item in enumerate(obj):\n                if idx:\n                    buf.append(', ')\n                if idx == limit:\n                    buf.append('<span class=\"extended\">')\n                    have_extended_section = True\n                buf.append(self.repr(item))\n            if have_extended_section:\n                buf.append('</span>')\n            buf.append(right)\n            return _add_subclass_info(u''.join(buf), obj, base)\n        return proxy\n\n    list_repr = _sequence_repr_maker('[', ']', list)\n    tuple_repr = _sequence_repr_maker('(', ')', tuple)\n    set_repr = _sequence_repr_maker('set([', '])', set)\n    frozenset_repr = _sequence_repr_maker('frozenset([', '])', frozenset)\n    if deque is not None:\n        deque_repr = _sequence_repr_maker('<span class=\"module\">collections.'\n                                          '</span>deque([', '])', deque)\n    del _sequence_repr_maker\n\n    def regex_repr(self, obj):\n        pattern = repr(obj.pattern).decode('string-escape', 'ignore')\n        if pattern[:1] == 'u':\n            pattern = 'ur' + pattern[1:]\n        else:\n            pattern = 'r' + pattern\n        return u're.compile(<span class=\"string regex\">%s</span>)' % pattern\n\n    def string_repr(self, obj, limit=70):\n        buf = ['<span class=\"string\">']\n        escaped = escape(obj)\n        a = repr(escaped[:limit])\n        b = repr(escaped[limit:])\n        if isinstance(obj, unicode):\n            buf.append('u')\n            a = a[1:]\n            b = b[1:]\n        if b != \"''\":\n            buf.extend((a[:-1], '<span class=\"extended\">', b[1:], '</span>'))\n        else:\n            buf.append(a)\n        buf.append('</span>')\n        return _add_subclass_info(u''.join(buf), obj, (str, unicode))\n\n    def dict_repr(self, d, recursive, limit=5):\n        if recursive:\n            return _add_subclass_info(u'{...}', d, dict)\n        buf = ['{']\n        have_extended_section = False\n        for idx, (key, value) in enumerate(d.iteritems()):\n            if idx:\n                buf.append(', ')\n            if idx == limit - 1:\n                buf.append('<span class=\"extended\">')\n                have_extended_section = True\n            buf.append('<span class=\"pair\"><span class=\"key\">%s</span>: '\n                       '<span class=\"value\">%s</span></span>' %\n                       (self.repr(key), self.repr(value)))\n        if have_extended_section:\n            buf.append('</span>')\n        buf.append('}')\n        return _add_subclass_info(u''.join(buf), d, dict)\n\n    def object_repr(self, obj):\n        return u'<span class=\"object\">%s</span>' % \\\n               escape(repr(obj).decode('utf-8', 'replace'))\n\n    def dispatch_repr(self, obj, recursive):\n        if isinstance(obj, (int, long, float, complex)):\n            return u'<span class=\"number\">%r</span>' % obj\n        if isinstance(obj, basestring):\n            return self.string_repr(obj)\n        if isinstance(obj, RegexType):\n            return self.regex_repr(obj)\n        if isinstance(obj, list):\n            return self.list_repr(obj, recursive)\n        if isinstance(obj, tuple):\n            return self.tuple_repr(obj, recursive)\n        if isinstance(obj, set):\n            return self.set_repr(obj, recursive)\n        if isinstance(obj, frozenset):\n            return self.frozenset_repr(obj, recursive)\n        if isinstance(obj, dict):\n            return self.dict_repr(obj, recursive)\n        if deque is not None and isinstance(obj, deque):\n            return self.deque_repr(obj, recursive)\n        return self.object_repr(obj)\n\n    def fallback_repr(self):\n        try:\n            info = ''.join(format_exception_only(*sys.exc_info()[:2]))\n        except:\n            info = '?'\n        return u'<span class=\"brokenrepr\">&lt;broken repr (%s)&gt;' \\\n               u'</span>' % escape(info.decode('utf-8', 'ignore').strip())\n\n    def repr(self, obj):\n        recursive = False\n        for item in self._stack:\n            if item is obj:\n                recursive = True\n                break\n        self._stack.append(obj)\n        try:\n            try:\n                return self.dispatch_repr(obj, recursive)\n            except:\n                return self.fallback_repr()\n        finally:\n            self._stack.pop()\n\n    def dump_object(self, obj):\n        attributes = []\n        for key in dir(obj):\n            try:\n                ", "suffix": "        title = 'Details for ' + object.__repr__(obj)[1:-1]\n        return render_template('dump_object.html', attributes=attributes,\n                               title=title, repr=self.repr(obj))\n\n    def dump_locals(self, d):\n        attributes = [(key, self.repr(value)) for key, value in d.items()]\n        return render_template('dump_object.html', attributes=attributes,\n                               title='Local variables in frame', repr=None)", "archive": "pallets__werkzeug-dc985a5da62143fa84b4142fa353ee98733ea833.zip"}
