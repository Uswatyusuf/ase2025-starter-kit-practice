{"context": "<|file_sep|>t\\integration\\test_redis.py\nfrom __future__ import absolute_import, unicode_literals\n\nimport os\n\nimport pytest\nimport kombu\n\nfrom .common import BasicFunctionality, BaseExchangeTypes\n\n\ndef get_connection(\n        hostname, port, vhost):\n    return kombu.Connection('redis://{}:{}'.format(hostname, port))\n\n\n@pytest.fixture()\ndef connection(request):\n    # this fixture yields plain connections to broker and TLS encrypted\n    return get_connection(\n        hostname=os.environ.get('REDIS_HOST', 'localhost'),\n        port=os.environ.get('REDIS_6379_TCP', '6379'),\n        vhost=getattr(\n            request.config, \"slaveinput\", {}\n        ).get(\"slaveid\", None),\n    )\n\n\n@pytest.mark.env('redis')\n@pytest.mark.flaky(reruns=5, reruns_delay=2)\nclass test_RedisBasicFunctionality(BasicFunctionality):\n    pass\n\n\n@pytest.mark.env('redis')\n@pytest.mark.flaky(reruns=5, reruns_delay=2)\nclass test_RedisBaseExchangeTypes(BaseExchangeTypes):\n    pass\n"}
{"context": "<|file_sep|>kombu\\transport\\amqplib.py\n\"\"\"\nkombu.transport.amqplib\n=======================\n\namqplib transport.\n\n:copyright: (c) 2009 - 2012 by Ask Solem.\n:license: BSD, see LICENSE for more details.\n\n\"\"\"\nfrom __future__ import absolute_import\n\nimport socket\n\ntry:\n    from ssl import SSLError\nexcept ImportError:\n    class SSLError(Exception):  # noqa\n        pass\n\nfrom amqplib import client_0_8 as amqp\nfrom amqplib.client_0_8 import transport\nfrom amqplib.client_0_8.channel import Channel as _Channel\nfrom amqplib.client_0_8.exceptions import AMQPConnectionException\nfrom amqplib.client_0_8.exceptions import AMQPChannelException\n\nfrom . import base\nfrom ..utils.encoding import str_to_bytes\n\nDEFAULT_PORT = 5672\n\n# amqplib's handshake mistakenly identifies as protocol version 1191,\n# this breaks in RabbitMQ tip, which no longer falls back to\n# 0-8 for unknown ids.\ntransport.AMQP_PROTOCOL_HEADER = str_to_bytes(\"AMQP\\x01\\x01\\x08\\x00\")\n\n\nclass Connection(amqp.Connection):  # pragma: no cover\n\n    def _dispatch_basic_return(self, channel, args, msg):\n        reply_code = args.read_short()\n        reply_text = args.read_shortstr()\n        exchange = args.read_shortstr()\n        routing_key = args.read_shortstr()\n\n        exc = AMQPChannelException(reply_code, reply_text, (50, 60))\n        if channel.events[\"basic_return\"]:\n            for callback in channel.events[\"basic_return\"]:\n                callback(exc, exchange, routing_key, msg)\n        else:\n            raise exc\n\n    def __init__(self, *args, **kwargs):\n        super(Connection, self).__init__(*args, **kwargs)\n        self._method_override = {(60, 50): self._dispatch_basic_return}\n\n    def drain_events(self, allowed_methods=None, timeout=None):\n        \"\"\"Wait for an event on any channel.\"\"\"\n        return self.wait_multi(self.channels.values(), timeout=timeout)\n\n    def wait_multi(self, channels, allowed_methods=None, timeout=None):\n        \"\"\"Wait for an event on a channel.\"\"\"\n        chanmap = dict((chan.channel_id, chan) for chan in channels)\n        chanid, method_sig, args, content = self._wait_multiple(\n                chanmap.keys(), allowed_methods, timeout=timeout)\n\n        channel = chanmap[chanid]\n\n        if content \\\n        and channel.auto_decode \\\n        and hasattr(content, 'content_encoding'):\n            try:\n                content.body = content.body.decode(content.content_encoding)\n            except Exception:\n                pass\n\n        amqp_method = self._method_override.get(method_sig) or \\\n                        channel._METHOD_MAP.get(method_sig, None)\n\n        if amqp_method is None:\n            raise Exception('Unknown AMQP method (%d, %d)' % method_sig)\n\n        if content is None:\n            return amqp_method(channel, args)\n        else:\n            return amqp_method(channel, args, content)\n\n    def read_timeout(self, timeout=None):\n        if timeout is None:\n            return self.method_reader.read_method()\n        sock = self.transport.sock\n        prev = sock.gettimeout()\n        if prev != timeout:\n            sock.settimeout(timeout)\n        try:\n            try:\n                return self.method_reader.read_method()\n            except SSLError, exc:\n                # http://bugs.python.org/issue10272\n                if \"timed out\" in str(exc):\n                    raise socket.timeout()\n                raise\n        finally:\n            if prev != timeout:\n                sock.settimeout(prev)\n\n    def _wait_multiple(self, channel_ids, allowed_methods, timeout=None):\n        for channel_id in channel_ids:\n            method_queue = self.channels[channel_id].method_queue\n            for queued_method in method_queue:\n                method_sig = queued_method[0]\n                if (allowed_methods is None) \\\n                or (method_sig in allowed_methods) \\\n                or (method_sig == (20, 40)):\n                    method_queue.remove(queued_method)\n                    method_sig, args, content = queued_method\n                    return channel_id, method_sig, args, content\n\n        # Nothing queued, need to wait for a method from the peer\n        read_timeout = self.read_timeout\n        channels = self.channels\n        wait = self.wait\n        while 1:\n            channel, method_sig, args, content = read_timeout(timeout)\n\n            if (channel in channel_ids) \\\n            and ((allowed_methods is None) \\\n                or (method_sig in allowed_methods) \\\n                or (method_sig == (20, 40))):\n                return channel, method_sig, args, content\n\n            # Not the channel and/or method we were looking for. Queue\n            # this method for later\n            channels[channel].method_queue.append((method_sig, args, content))\n\n            #\n            # If we just queued up a method for channel 0 (the Connection\n            # itself) it's probably a close method in reaction to some\n            # error, so deal with it right away.\n            #\n            if channel == 0:\n                wait()\n\n    def channel(self, channel_id=None):\n        try:\n            return self.channels[channel_id]\n        except KeyError:\n            return Channel(self, channel_id)\n\n\nclass Message(base.Message):\n\n    def __init__(self, channel, msg, **kwargs):\n        props = msg.properties\n        super(Message, self).__init__(channel,\n                body=msg.body,\n                delivery_tag=msg.delivery_tag,\n                content_type=props.get(\"content_type\"),\n                content_encoding=props.get(\"content_encoding\"),\n                delivery_info=msg.delivery_info,\n                properties=msg.properties,\n                headers=props.get(\"application_headers\") or {},\n                **kwargs)\n\n\nclass Channel(_Channel, base.StdChannel):\n    Message = Message\n    events = {\"basic_return\": []}\n\n    def __init__(self, *args, **kwargs):\n        self.no_ack_consumers = set()\n        super(Channel, self).__init__(*args, **kwargs)\n\n    def prepare_message(self, message_data, priority=None,\n                content_type=None, content_encoding=None, headers=None,\n                properties=None):\n        \"\"\"Encapsulate data into a AMQP message.\"\"\"\n        return amqp.Message(message_data, priority=priority,\n                            content_type=content_type,\n                            content_encoding=content_encoding,\n                            application_headers=headers,\n                            **properties)\n\n    def message_to_python(self, raw_message):\n        \"\"\"Convert encoded message body back to a Python value.\"\"\"\n        return self.Message(self, raw_message)\n\n    def close(self):\n        try:\n            super(Channel, self).close()\n        finally:\n            self.connection = None\n\n    def basic_consume(self, *args, **kwargs):\n        consumer_tag = super(Channel, self).basic_consume(*args, **kwargs)\n        if kwargs[\"no_ack\"]:\n            self.no_ack_consumers.add(consumer_tag)\n        return consumer_tag\n\n    def basic_cancel(self, consumer_tag, **kwargs):\n        self.no_ack_consumers.discard(consumer_tag)\n        return super(Channel, self).basic_cancel(consumer_tag, **kwargs)\n\n\nclass Transport(base.Transport):\n    Connection = Connection\n\n    default_port = DEFAULT_PORT\n\n    # it's very annoying that amqplib sometimes raises AttributeError\n    # if the connection is lost, but nothing we can do about that here.\n    connection_errors = (AMQPConnectionException,\n                         socket.error,\n                         IOError,\n                         OSError,\n                         AttributeError)\n    channel_errors = (AMQPChannelException, )\n\n    def __init__(self, client, **kwargs):\n        self.client = client\n        self.default_port = kwargs.get(\"default_port\") or self.default_port\n\n    def create_channel(self, connection):\n        return connection.channel()\n\n    def drain_events(self, connection, **kwargs):\n        return connection.drain_events(**kwargs)\n\n    def establish_connection(self):\n        \"\"\"Establish connection to the AMQP broker.\"\"\"\n        conninfo = self.client\n        for name, default_value in self.default_connection_params.items():\n            if not getattr(conninfo, name, None):\n                setattr(conninfo, name, default_value)\n        if conninfo.hostname == \"localhost\":\n            conninfo.hostname = \"127.0.0.1\"\n        conn = self.Connection(host=conninfo.host,\n                               userid=conninfo.userid,\n                               password=conninfo.password,\n                               login_method=conninfo.login_method,\n                               virtual_host=conninfo.virtual_host,\n                               insist=conninfo.insist,\n                               ssl=conninfo.ssl,\n                               connect_timeout=conninfo.connect_timeout)\n        conn.client = self.client\n        return conn\n\n    def close_connection(self, connection):\n        \"\"\"Close the AMQP broker connection.\"\"\"\n        connection.client = None\n        connection.close()\n\n    def verify_connection(self, connection):\n        return connection.channels is not None\n\n    @property\n    def default_connection_params(self):\n        return {\"userid\": \"guest\", \"password\": \"guest\",\n                \"port\": self.default_port,\n                \"hostname\": \"localhost\", \"login_method\": \"AMQPLAIN\"}\n"}
{"context": "<|file_sep|>kombu\\utils\\compat.py\nfrom __future__ import absolute_import, unicode_literals\n\nimport numbers\nimport sys\n\nfrom functools import wraps\n\nfrom contextlib import contextmanager\n\nfrom kombu.five import reraise\n\ntry:\n    from io import UnsupportedOperation\n    FILENO_ERRORS = (AttributeError, ValueError, UnsupportedOperation)\nexcept ImportError:  # pragma: no cover\n    # Py2\n    FILENO_ERRORS = (AttributeError, ValueError)  # noqa\n\ntry:\n    from billiard.util import register_after_fork\nexcept ImportError:  # pragma: no cover\n    try:\n        from multiprocessing.util import register_after_fork  # noqa\n    except ImportError:\n        register_after_fork = None  # noqa\n\n\ndef coro(gen):\n\n    @wraps(gen)\n    def wind_up(*args, **kwargs):\n        it = gen(*args, **kwargs)\n        next(it)\n        return it\n    return wind_up\n\n\ndef entrypoints(namespace):\n    try:\n        from pkg_resources import iter_entry_points\n    except ImportError:\n        return iter([])\n    return ((ep, ep.load()) for ep in iter_entry_points(namespace))\n\n\ndef fileno(f):\n    if isinstance(f, numbers.Integral):\n        return f\n    return f.fileno()\n\n\ndef maybe_fileno(f):\n    \"\"\"Get object fileno, or :const:`None` if not defined.\"\"\"\n    try:\n        return fileno(f)\n    except FILENO_ERRORS:\n        pass\n\n\n@contextmanager\ndef nested(*managers):  # pragma: no cover\n    # flake8: noqa\n    \"\"\"Combine multiple context managers into a single nested\n    context manager.\"\"\"\n    exits = []\n    vars = []\n    exc = (None, None, None)\n    try:\n        try:\n            for mgr in managers:\n                exit = mgr.__exit__\n                enter = mgr.__enter__\n                vars.append(enter())\n                exits.append(exit)\n            yield vars\n        except:\n            exc = sys.exc_info()\n        finally:\n            while exits:\n                exit = exits.pop()\n                try:\n                    if exit(*exc):\n                        exc = (None, None, None)\n                except:\n                    exc = sys.exc_info()\n            if exc != (None, None, None):\n                # Don't rely on sys.exc_info() still containing\n                # the right information.  Another exception may\n                # have been raised and caught by an exit method\n                reraise(exc[0], exc[1], exc[2])\n    finally:\n        del(exc)\n"}
{"context": "<|file_sep|>kombu\\clocks.py\n\"\"\"\nkombu.clocks\n============\n\nLogical Clocks and Synchronization.\n\n:copyright: (c) 2009 - 2012 by Ask Solem.\n:license: BSD, see LICENSE for more details.\n\n\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import with_statement\n\nimport threading\n\n__all__ = ['LamportClock']\n\n\nclass LamportClock(object):\n    \"\"\"Lamport's logical clock.\n\n    From Wikipedia:\n\n    A Lamport logical clock is a monotonically incrementing software counter\n    maintained in each process.  It follows some simple rules:\n\n        * A process increments its counter before each event in that process;\n        * When a process sends a message, it includes its counter value with\n          the message;\n        * On receiving a message, the receiver process sets its counter to be\n          greater than the maximum of its own value and the received value\n          before it considers the message received.\n\n    Conceptually, this logical clock can be thought of as a clock that only\n    has meaning in relation to messages moving between processes.  When a\n    process receives a message, it resynchronizes its logical clock with\n    the sender.\n\n    .. seealso::\n\n        * `Lamport timestamps`_\n\n        * `Lamports distributed mutex`_\n\n    .. _`Lamport Timestamps`: http://en.wikipedia.org/wiki/Lamport_timestamps\n    .. _`Lamports distributed mutex`: http://bit.ly/p99ybE\n\n    *Usage*\n\n    When sending a message use :meth:`forward` to increment the clock,\n    when receiving a message use :meth:`adjust` to sync with\n    the time stamp of the incoming message.\n\n    \"\"\"\n    #: The clocks current value.\n    value = 0\n\n    def __init__(self, initial_value=0):\n        self.value = initial_value\n        self.mutex = threading.Lock()\n\n    def adjust(self, other):\n        with self.mutex:\n            self.value = max(self.value, other) + 1\n\n    def forward(self):\n        with self.mutex:\n            self.value += 1\n            return self.value\n\n    def __str__(self):\n        return str(self.value)\n\n    def __repr__(self):\n        return '<LamportClock: %r>' % (self.value, )\n"}
{"context": "<|file_sep|>kombu\\transport\\mongodb.py\n\"\"\"\nkombu.transport.mongodb\n=======================\n\nMongoDB transport.\n\n:copyright: (c) 2010 - 2012 by Flavio Percoco Premoli.\n:license: BSD, see LICENSE for more details.\n\n\"\"\"\nfrom __future__ import absolute_import\n\nfrom Queue import Empty\n\nimport pymongo\nfrom pymongo import errors\nfrom anyjson import loads, dumps\nfrom pymongo.connection import Connection\n\nfrom . import virtual\n\nDEFAULT_HOST = \"127.0.0.1\"\nDEFAULT_PORT = 27017\n\n__author__ = \"Flavio [FlaPer87] Percoco Premoli <flaper87@flaper87.org>\"\n\n\nclass Channel(virtual.Channel):\n    _client = None\n\n    def _new_queue(self, queue, **kwargs):\n        pass\n\n    def _get(self, queue):\n        try:\n            msg = self.client.database.command(\"findandmodify\", \"messages\",\n                    query={\"queue\": queue},\n                    sort={\"_id\": pymongo.ASCENDING}, remove=True)\n        except errors.OperationFailure, exc:\n            if \"No matching object found\" in exc.args[0]:\n                raise Empty()\n            raise\n        # as of mongo 2.0 empty results won't raise an error\n        if msg['value'] is None:\n            raise Empty()\n        return loads(msg[\"value\"][\"payload\"])\n\n    def _size(self, queue):\n        return self.client.find({\"queue\": queue}).count()\n\n    def _put(self, queue, message, **kwargs):\n        self.client.insert({\"payload\": dumps(message), \"queue\": queue})\n\n    def _purge(self, queue):\n        size = self._size(queue)\n        self.client.remove({\"queue\": queue})\n        return size\n\n    def close(self):\n        super(Channel, self).close()\n        if self._client:\n            self._client.database.connection.end_request()\n\n    def _open(self):\n        conninfo = self.connection.client\n        mongoconn = Connection(host=conninfo.hostname, port=conninfo.port)\n        dbname = conninfo.virtual_host\n        version = mongoconn.server_info()[\"version\"]\n        if tuple(map(int, version.split(\".\")[:2])) < (1, 3):\n            raise NotImplementedError(\n                \"Kombu requires MongoDB version 1.3+, but connected to %s\" % (\n                    version, ))\n        if not dbname or dbname == \"/\":\n            dbname = \"kombu_default\"\n        database = getattr(mongoconn, dbname)\n        if conninfo.userid:\n            database.authenticate(conninfo.userid, conninfo.password)\n        col = database.messages\n        col.ensure_index([(\"queue\", 1)])\n        return col\n\n    @property\n    def client(self):\n        if self._client is None:\n            self._client = self._open()\n        return self._client\n\n\nclass Transport(virtual.Transport):\n    Channel = Channel\n\n    polling_interval = 1\n    default_port = DEFAULT_PORT\n    connection_errors = (errors.ConnectionFailure, )\n    channel_errors = (errors.ConnectionFailure,\n                      errors.OperationFailure, )\n"}
{"context": "<|file_sep|>kombu\\tests\\utils\\test_json.py\nfrom __future__ import absolute_import, unicode_literals\n\nfrom kombu.utils.encoding import str_to_bytes\nfrom kombu.utils.json import _DecodeError, dumps, loads\n\nfrom kombu.tests.case import Case, MagicMock, Mock, skip\n\n\nclass Custom(object):\n\n    def __init__(self, data):\n        self.data = data\n\n    def __json__(self):\n        return self.data\n\n\nclass test_dumps_loads(Case):\n\n    def test_dumps_custom_object(self):\n        x = {'foo': Custom({'a': 'b'})}\n        self.assertEqual(loads(dumps(x)), {'foo': x['foo'].__json__()})\n\n    def test_dumps_custom_object_no_json(self):\n        x = {'foo': object()}\n        with self.assertRaises(TypeError):\n            dumps(x)\n\n    def test_loads_memoryview(self):\n        self.assertEqual(\n            loads(memoryview(bytearray(dumps({'x': 'z'}), encoding='utf-8'))),\n            {'x': 'z'},\n        )\n\n    def test_loads_bytearray(self):\n        self.assertEqual(\n            loads(bytearray(dumps({'x': 'z'}), encoding='utf-8')),\n            {'x': 'z'})\n\n    def test_loads_bytes(self):\n        self.assertEqual(\n            loads(str_to_bytes(dumps({'x': 'z'})), decode_bytes=True),\n            {'x': 'z'},\n        )\n\n    @skip.if_python3()\n    def test_loads_buffer(self):\n        self.assertEqual(loads(buffer(dumps({'x': 'z'}))), {'x': 'z'})\n\n    def test_loads_DecodeError(self):\n        _loads = Mock(name='_loads')\n        _loads.side_effect = _DecodeError(\n            MagicMock(), MagicMock(), MagicMock())\n        self.assertEqual(loads(dumps({'x': 'z'}), _loads=_loads), {'x': 'z'})\n"}
{"context": "<|file_sep|>kombu\\tests\\transport\\test_sqlalchemy.py\nfrom __future__ import absolute_import\nfrom __future__ import with_statement\n\nfrom mock import patch\nfrom nose import SkipTest\n\nfrom kombu import Connection\nfrom kombu.tests.utils import TestCase\n\n\nclass test_sqlalchemy(TestCase):\n\n    def setUp(self):\n        try:\n            import sqlalchemy  # noqa\n        except ImportError:\n            raise SkipTest('sqlalchemy not installed')\n\n    def test_url_parser(self):\n        with patch('kombu.transport.sqlalchemy.Channel._open'):\n            url = 'sqlalchemy+sqlite:///celerydb.sqlite'\n            Connection(url).connect()\n\n            url = 'sqla+sqlite:///celerydb.sqlite'\n            Connection(url).connect()\n\n            # Should prevent regression fixed by f187ccd\n            url = 'sqlb+sqlite:///celerydb.sqlite'\n            with self.assertRaises(KeyError):\n                Connection(url).connect()\n\n    def test_clone(self):\n        hostname = 'sqlite:///celerydb.sqlite'\n        x = Connection('+'.join(['sqla', hostname]))\n        self.assertEqual(x.uri_prefix, 'sqla')\n        self.assertEqual(x.hostname, hostname)\n        clone = x.clone()\n        self.assertEqual(clone.hostname, hostname)\n        self.assertEqual(clone.uri_prefix, 'sqla')\n"}
{"context": "<|file_sep|>kombu\\utils\\url.py\n\"\"\"URL Utilities.\"\"\"\n# flake8: noqa\n\nfrom __future__ import absolute_import, unicode_literals\n\ntry:\n    from collections.abc import Mapping\nexcept ImportError:\n    from collections import Mapping\n\nfrom functools import partial\n\ntry:\n    from urllib.parse import parse_qsl, quote, unquote, urlparse\nexcept ImportError:\n    from urllib import quote, unquote                  # noqa\n    from urlparse import urlparse, parse_qsl    # noqa\n\nfrom kombu.five import bytes_if_py2, string_t\n\nfrom .compat import NamedTuple\n\nsafequote = partial(quote, safe=bytes_if_py2(''))\n\n\nurlparts = NamedTuple('urlparts', [\n    ('scheme', str),\n    ('hostname', str),\n    ('port', int),\n    ('username', str),\n    ('password', str),\n    ('path', str),\n    ('query', Mapping),\n])\n\n\ndef parse_url(url):\n    # type: (str) -> Dict\n    \"\"\"Parse URL into mapping of components.\"\"\"\n    scheme, host, port, user, password, path, query = _parse_url(url)\n    return dict(transport=scheme, hostname=host,\n                port=port, userid=user,\n                password=password, virtual_host=path, **query)\n\n\ndef url_to_parts(url):\n    # type: (str) -> urlparts\n    \"\"\"Parse URL into :class:`urlparts` tuple of components.\"\"\"\n    scheme = urlparse(url).scheme\n    schemeless = url[len(scheme) + 3:]\n    # parse with HTTP URL semantics\n    parts = urlparse('http://' + schemeless)\n    path = parts.path or ''\n    path = path[1:] if path and path[0] == '/' else path\n    return urlparts(\n        scheme,\n        unquote(parts.hostname or '') or None,\n        parts.port,\n        unquote(parts.username or '') or None,\n        unquote(parts.password or '') or None,\n        unquote(path or '') or None,\n        dict(parse_qsl(parts.query)),\n    )\n_parse_url = url_to_parts  # noqa\n\n\ndef as_url(scheme, host=None, port=None, user=None, password=None,\n           path=None, query=None, sanitize=False, mask='**'):\n    # type: (str, str, int, str, str, str, str, bool, str) -> str\n    \"\"\"Generate URL from component parts.\"\"\"\n    parts = ['{0}://'.format(scheme)]\n    if user or password:\n        if user:\n            parts.append(safequote(user))\n        if password:\n            if sanitize:\n                parts.extend([':', mask] if mask else [':'])\n            else:\n                parts.extend([':', safequote(password)])\n        parts.append('@')\n    parts.append(safequote(host) if host else '')\n    if port:\n        parts.extend([':', port])\n    parts.extend(['/', path])\n    return ''.join(str(part) for part in parts if part)\n\n\ndef sanitize_url(url, mask='**'):\n    # type: (str, str) -> str\n    \"\"\"Return copy of URL with password removed.\"\"\"\n    return as_url(*_parse_url(url), sanitize=True, mask=mask)\n\n\ndef maybe_sanitize_url(url, mask='**'):\n    # type: (Any, str) -> Any\n    \"\"\"Sanitize url, or do nothing if url undefined.\"\"\"\n    if isinstance(url, string_t) and '://' in url:\n        return sanitize_url(url, mask)\n    return url\n"}
{"context": "<|file_sep|>kombu\\tests\\test_pidbox.py\nfrom __future__ import absolute_import\n\nimport socket\n\nfrom kombu import Connection\nfrom kombu import pidbox\nfrom kombu.utils import uuid\n\nfrom .case import Case, Mock\n\n\nclass test_Mailbox(Case):\n\n    def _handler(self, state):\n        return self.stats['var']\n\n    def setUp(self):\n\n        class Mailbox(pidbox.Mailbox):\n\n            def _collect(self, *args, **kwargs):\n                return 'COLLECTED'\n\n        self.mailbox = Mailbox('test_pidbox')\n        self.connection = Connection(transport='memory')\n        self.state = {'var': 1}\n        self.handlers = {'mymethod': self._handler}\n        self.bound = self.mailbox(self.connection)\n        self.default_chan = self.connection.channel()\n        self.node = self.bound.Node(\n            'test_pidbox',\n            state=self.state, handlers=self.handlers,\n            channel=self.default_chan,\n        )\n\n    def test_reply__collect(self):\n        mailbox = pidbox.Mailbox('test_reply__collect')(self.connection)\n        exchange = mailbox.reply_exchange.name\n        channel = self.connection.channel()\n        mailbox.reply_queue(channel).declare()\n\n        ticket = uuid()\n        mailbox._publish_reply({'foo': 'bar'}, exchange, mailbox.oid, ticket)\n        _callback_called = [False]\n\n        def callback(body):\n            _callback_called[0] = True\n\n        reply = mailbox._collect(ticket, limit=1,\n                                 callback=callback, channel=channel)\n        self.assertEqual(reply, [{'foo': 'bar'}])\n        self.assertTrue(_callback_called[0])\n\n        ticket = uuid()\n        mailbox._publish_reply({'biz': 'boz'}, exchange, mailbox.oid, ticket)\n        reply = mailbox._collect(ticket, limit=1, channel=channel)\n        self.assertEqual(reply, [{'biz': 'boz'}])\n\n        de = mailbox.connection.drain_events = Mock()\n        de.side_effect = socket.timeout\n        mailbox._collect(ticket, limit=1, channel=channel)\n\n    def test_constructor(self):\n        self.assertIsNone(self.mailbox.connection)\n        self.assertTrue(self.mailbox.exchange.name)\n        self.assertTrue(self.mailbox.reply_exchange.name)\n\n    def test_bound(self):\n        bound = self.mailbox(self.connection)\n        self.assertIs(bound.connection, self.connection)\n\n    def test_Node(self):\n        self.assertTrue(self.node.hostname)\n        self.assertTrue(self.node.state)\n        self.assertIs(self.node.mailbox, self.bound)\n        self.assertTrue(self.handlers)\n\n        # No initial handlers\n        node2 = self.bound.Node('test_pidbox2', state=self.state)\n        self.assertDictEqual(node2.handlers, {})\n\n    def test_Node_consumer(self):\n        consumer1 = self.node.Consumer()\n        self.assertIs(consumer1.channel, self.default_chan)\n        self.assertTrue(consumer1.no_ack)\n\n        chan2 = self.connection.channel()\n        consumer2 = self.node.Consumer(channel=chan2, no_ack=False)\n        self.assertIs(consumer2.channel, chan2)\n        self.assertFalse(consumer2.no_ack)\n\n    def test_handler(self):\n        node = self.bound.Node('test_handler', state=self.state)\n\n        @node.handler\n        def my_handler_name(state):\n            return 42\n\n        self.assertIn('my_handler_name', node.handlers)\n\n    def test_dispatch(self):\n        node = self.bound.Node('test_dispatch', state=self.state)\n\n        @node.handler\n        def my_handler_name(state, x=None, y=None):\n            return x + y\n\n        self.assertEqual(node.dispatch('my_handler_name',\n                                       arguments={'x': 10, 'y': 10}), 20)\n\n    def test_dispatch_raising_SystemExit(self):\n        node = self.bound.Node('test_dispatch_raising_SystemExit',\n                               state=self.state)\n\n        @node.handler\n        def my_handler_name(state):\n            raise SystemExit\n\n        with self.assertRaises(SystemExit):\n            node.dispatch('my_handler_name')\n\n    def test_dispatch_raising(self):\n        node = self.bound.Node('test_dispatch_raising', state=self.state)\n\n        @node.handler\n        def my_handler_name(state):\n            raise KeyError('foo')\n\n        res = node.dispatch('my_handler_name')\n        self.assertIn('error', res)\n        self.assertIn('KeyError', res['error'])\n\n    def test_dispatch_replies(self):\n        _replied = [False]\n\n        def reply(data, **options):\n            _replied[0] = True\n\n        node = self.bound.Node('test_dispatch', state=self.state)\n        node.reply = reply\n\n        @node.handler\n        def my_handler_name(state, x=None, y=None):\n            return x + y\n\n        node.dispatch('my_handler_name',\n                      arguments={'x': 10, 'y': 10},\n                      reply_to={'exchange': 'foo', 'routing_key': 'bar'})\n        self.assertTrue(_replied[0])\n\n    def test_reply(self):\n        _replied = [(None, None, None)]\n\n        def publish_reply(data, exchange, routing_key, ticket, **kwargs):\n            _replied[0] = (data, exchange, routing_key, ticket)\n\n        mailbox = self.mailbox(self.connection)\n        mailbox._publish_reply = publish_reply\n        node = mailbox.Node('test_reply')\n\n        @node.handler\n        def my_handler_name(state):\n            return 42\n\n        node.dispatch('my_handler_name',\n                      reply_to={'exchange': 'exchange',\n                                'routing_key': 'rkey'},\n                      ticket='TICKET')\n        data, exchange, routing_key, ticket = _replied[0]\n        self.assertEqual(data, {'test_reply': 42})\n        self.assertEqual(exchange, 'exchange')\n        self.assertEqual(routing_key, 'rkey')\n        self.assertEqual(ticket, 'TICKET')\n\n    def test_handle_message(self):\n        node = self.bound.Node('test_dispatch_from_message')\n\n        @node.handler\n        def my_handler_name(state, x=None, y=None):\n            return x * y\n\n        body = {'method': 'my_handler_name',\n                'arguments': {'x': 64, 'y': 64}}\n\n        self.assertEqual(node.handle_message(body, None), 64 * 64)\n\n        # message not for me should not be processed.\n        body['destination'] = ['some_other_node']\n        self.assertIsNone(node.handle_message(body, None))\n\n    def test_listen(self):\n        consumer = self.node.listen()\n        self.assertEqual(consumer.callbacks[0],\n                         self.node.handle_message)\n        self.assertEqual(consumer.channel, self.default_chan)\n\n    def test_cast(self):\n        self.bound.cast(['somenode'], 'mymethod')\n        consumer = self.node.Consumer()\n        self.assertIsCast(self.get_next(consumer))\n\n    def test_abcast(self):\n        self.bound.abcast('mymethod')\n        consumer = self.node.Consumer()\n        self.assertIsCast(self.get_next(consumer))\n\n    def test_call_destination_must_be_sequence(self):\n        with self.assertRaises(ValueError):\n            self.bound.call('some_node', 'mymethod')\n\n    def test_call(self):\n        self.assertEqual(\n            self.bound.call(['some_node'], 'mymethod'),\n            'COLLECTED',\n        )\n        consumer = self.node.Consumer()\n        self.assertIsCall(self.get_next(consumer))\n\n    def test_multi_call(self):\n        self.assertEqual(self.bound.multi_call('mymethod'), 'COLLECTED')\n        consumer = self.node.Consumer()\n        self.assertIsCall(self.get_next(consumer))\n\n    def get_next(self, consumer):\n        m = consumer.queues[0].get()\n        if m:\n            return m.payload\n\n    def assertIsCast(self, message):\n        self.assertTrue(message['method'])\n\n    def assertIsCall(self, message):\n        self.assertTrue(message['method'])\n        self.assertTrue(message['reply_to'])\n"}
{"context": "<|file_sep|>kombu\\tests\\test_serialization.py\n#!/usr/bin/python\n# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import with_statement\n\nimport sys\n\nfrom ..serialization import (registry, register, SerializerNotInstalled,\n                             raw_encode, register_yaml, register_msgpack,\n                             decode, bytes_type, pickle,\n                             unregister, register_pickle)\n\nfrom .utils import unittest\nfrom .utils import mask_modules, skip_if_not_module\n\n# For content_encoding tests\nunicode_string = u'abcdé\\u8463'\nunicode_string_as_utf8 = unicode_string.encode('utf-8')\nlatin_string = u'abcdé'\nlatin_string_as_latin1 = latin_string.encode('latin-1')\nlatin_string_as_utf8 = latin_string.encode('utf-8')\n\n\n# For serialization tests\npy_data = {\"string\": \"The quick brown fox jumps over the lazy dog\",\n        \"int\": 10,\n        \"float\": 3.14159265,\n        \"unicode\": u\"Thé quick brown fox jumps over thé lazy dog\",\n        \"list\": [\"george\", \"jerry\", \"elaine\", \"cosmo\"],\n}\n\n# JSON serialization tests\njson_data = ('{\"int\": 10, \"float\": 3.1415926500000002, '\n             '\"list\": [\"george\", \"jerry\", \"elaine\", \"cosmo\"], '\n             '\"string\": \"The quick brown fox jumps over the lazy '\n             'dog\", \"unicode\": \"Th\\\\u00e9 quick brown fox jumps over '\n             'th\\\\u00e9 lazy dog\"}')\n\n# Pickle serialization tests\npickle_data = pickle.dumps(py_data)\n\n# YAML serialization tests\nyaml_data = ('float: 3.1415926500000002\\nint: 10\\n'\n             'list: [george, jerry, elaine, cosmo]\\n'\n             'string: The quick brown fox jumps over the lazy dog\\n'\n             'unicode: \"Th\\\\xE9 quick brown fox '\n             'jumps over th\\\\xE9 lazy dog\"\\n')\n\n\nmsgpack_py_data = dict(py_data)\n# msgpack only supports tuples\nmsgpack_py_data[\"list\"] = tuple(msgpack_py_data[\"list\"])\n# Unicode chars are lost in transmit :(\nmsgpack_py_data[\"unicode\"] = 'Th quick brown fox jumps over th lazy dog'\nmsgpack_data = ('\\x85\\xa3int\\n\\xa5float\\xcb@\\t!\\xfbS\\xc8\\xd4\\xf1\\xa4list'\n                '\\x94\\xa6george\\xa5jerry\\xa6elaine\\xa5cosmo\\xa6string\\xda'\n                '\\x00+The quick brown fox jumps over the lazy dog\\xa7unicode'\n                '\\xda\\x00)Th quick brown fox jumps over th lazy dog')\n\n\ndef say(m):\n    sys.stderr.write(\"%s\\n\" % (m, ))\n\n\nclass test_Serialization(unittest.TestCase):\n\n    def test_content_type_decoding(self):\n        self.assertEqual(unicode_string,\n                          registry.decode(\n                              unicode_string_as_utf8,\n                              content_type='plain/text',\n                              content_encoding='utf-8'))\n        self.assertEqual(latin_string,\n                          registry.decode(\n                              latin_string_as_latin1,\n                              content_type='application/data',\n                              content_encoding='latin-1'))\n\n    def test_content_type_binary(self):\n        self.assertIsInstance(registry.decode(unicode_string_as_utf8,\n                                              content_type='application/data',\n                                              content_encoding='binary'),\n                              bytes_type)\n\n        self.assertEqual(unicode_string_as_utf8,\n                          registry.decode(\n                              unicode_string_as_utf8,\n                              content_type='application/data',\n                              content_encoding='binary'))\n\n    def test_content_type_encoding(self):\n        # Using the \"raw\" serializer\n        self.assertEqual(unicode_string_as_utf8,\n                          registry.encode(\n                              unicode_string, serializer=\"raw\")[-1])\n        self.assertEqual(latin_string_as_utf8,\n                          registry.encode(\n                              latin_string, serializer=\"raw\")[-1])\n        # And again w/o a specific serializer to check the\n        # code where we force unicode objects into a string.\n        self.assertEqual(unicode_string_as_utf8,\n                            registry.encode(unicode_string)[-1])\n        self.assertEqual(latin_string_as_utf8,\n                            registry.encode(latin_string)[-1])\n\n    def test_json_decode(self):\n        self.assertEqual(py_data,\n                          registry.decode(\n                              json_data,\n                              content_type='application/json',\n                              content_encoding='utf-8'))\n\n    def test_json_encode(self):\n        self.assertEqual(registry.decode(\n                              registry.encode(py_data, serializer=\"json\")[-1],\n                              content_type='application/json',\n                              content_encoding='utf-8'),\n                          registry.decode(\n                              json_data,\n                              content_type='application/json',\n                              content_encoding='utf-8'))\n\n    @skip_if_not_module('msgpack')\n    def test_msgpack_decode(self):\n        register_msgpack()\n        self.assertEqual(msgpack_py_data,\n                          registry.decode(\n                              msgpack_data,\n                              content_type='application/x-msgpack',\n                              content_encoding='binary'))\n\n    @skip_if_not_module('msgpack')\n    def test_msgpack_encode(self):\n        register_msgpack()\n        self.assertEqual(registry.decode(\n                registry.encode(msgpack_py_data, serializer=\"msgpack\")[-1],\n                content_type='application/x-msgpack',\n                content_encoding='binary'),\n                registry.decode(\n                    msgpack_data,\n                    content_type='application/x-msgpack',\n                    content_encoding='binary'))\n\n    @skip_if_not_module('yaml')\n    def test_yaml_decode(self):\n        register_yaml()\n        self.assertEqual(py_data,\n                          registry.decode(\n                              yaml_data,\n                              content_type='application/x-yaml',\n                              content_encoding='utf-8'))\n\n    @skip_if_not_module('yaml')\n    def test_yaml_encode(self):\n        register_yaml()\n        self.assertEqual(registry.decode(\n                              registry.encode(py_data, serializer=\"yaml\")[-1],\n                              content_type='application/x-yaml',\n                              content_encoding='utf-8'),\n                          registry.decode(\n                              yaml_data,\n                              content_type='application/x-yaml',\n                              content_encoding='utf-8'))\n\n    def test_pickle_decode(self):\n        self.assertEqual(py_data,\n                          registry.decode(\n                              pickle_data,\n                              content_type='application/x-python-serialize',\n                              content_encoding='binary'))\n\n    def test_pickle_encode(self):\n        self.assertEqual(pickle_data,\n                          registry.encode(py_data,\n                              serializer=\"pickle\")[-1])\n\n    def test_register(self):\n        register(None, None, None, None)\n\n    def test_unregister(self):\n        with self.assertRaises(SerializerNotInstalled):\n            unregister(\"nonexisting\")\n        registry.encode(\"foo\", serializer=\"pickle\")\n        unregister(\"pickle\")\n        with self.assertRaises(SerializerNotInstalled):\n            registry.encode(\"foo\", serializer=\"pickle\")\n        register_pickle()\n\n    def test_set_default_serializer_missing(self):\n        with self.assertRaises(SerializerNotInstalled):\n            registry._set_default_serializer(\"nonexisting\")\n\n    def test_encode_missing(self):\n        with self.assertRaises(SerializerNotInstalled):\n            registry.encode(\"foo\", serializer=\"nonexisting\")\n\n    def test_raw_encode(self):\n        self.assertTupleEqual(raw_encode(\"foo\".encode(\"utf-8\")),\n                              (\"application/data\", \"binary\",\n                                  \"foo\".encode(\"utf-8\")))\n\n    @mask_modules(\"yaml\")\n    def test_register_yaml__no_yaml(self):\n        register_yaml()\n        with self.assertRaises(SerializerNotInstalled):\n            decode(\"foo\", \"application/x-yaml\", \"utf-8\")\n\n    @mask_modules(\"msgpack\")\n    def test_register_msgpack__no_msgpack(self):\n        register_msgpack()\n        with self.assertRaises(SerializerNotInstalled):\n            decode(\"foo\", \"application/x-msgpack\", \"utf-8\")\n"}
{"context": "<|file_sep|>kombu\\pools.py\nfrom kombu.connection import Resource\nfrom kombu.messaging import Producer\n\n\nclass ProducerPool(Resource):\n    Producer = Producer\n\n    def __init__(self, connections, *args, **kwargs):\n        self.connections = connections\n        super(ProducerPool, self).__init__(*args, **kwargs)\n\n    def create_producer(self):\n        conn = self.connections.acquire(block=True)\n        channel = conn.channel()\n        producer = self.Producer(channel)\n        producer.connection = conn\n        conn._producer_chan = channel\n        return producer\n\n    def new(self):\n        return lambda: self.create_producer()\n\n    def setup(self):\n        if self.limit:\n            for _ in xrange(self.limit):\n                self._resource.put_nowait(self.new())\n\n    def prepare(self, p):\n        if callable(p):\n            p = p()\n        if not p.connection:\n            p.connection = self.connections.acquire(block=True)\n            if not getattr(p.connection, \"_producer_chan\", None):\n                p.connection._producer_chan = p.connection.channel()\n            p.revive(p.connection._producer_chan)\n        return p\n\n    def release(self, resource):\n        resource.connection.release()\n        resource.connection = None\n        super(ProducerPool, self).release(resource)\n"}
{"context": "<|file_sep|>t\\unit\\transport\\test_filesystem.py\nimport tempfile\n\nimport pytest\n\nimport t.skip\nfrom kombu import Connection, Consumer, Exchange, Producer, Queue\n\n\n@t.skip.if_win32\nclass test_FilesystemTransport:\n\n    def setup(self):\n        self.channels = set()\n        try:\n            data_folder_in = tempfile.mkdtemp()\n            data_folder_out = tempfile.mkdtemp()\n        except Exception:\n            pytest.skip('filesystem transport: cannot create tempfiles')\n        self.c = Connection(transport='filesystem',\n                            transport_options={\n                                'data_folder_in': data_folder_in,\n                                'data_folder_out': data_folder_out,\n                            })\n        self.channels.add(self.c.default_channel)\n        self.p = Connection(transport='filesystem',\n                            transport_options={\n                                'data_folder_in': data_folder_out,\n                                'data_folder_out': data_folder_in,\n                            })\n        self.channels.add(self.p.default_channel)\n        self.e = Exchange('test_transport_filesystem')\n        self.q = Queue('test_transport_filesystem',\n                       exchange=self.e,\n                       routing_key='test_transport_filesystem')\n        self.q2 = Queue('test_transport_filesystem2',\n                        exchange=self.e,\n                        routing_key='test_transport_filesystem2')\n\n    def teardown(self):\n        # make sure we don't attempt to restore messages at shutdown.\n        for channel in self.channels:\n            try:\n                channel._qos._dirty.clear()\n            except AttributeError:\n                pass\n            try:\n                channel._qos._delivered.clear()\n            except AttributeError:\n                pass\n\n    def _add_channel(self, channel):\n        self.channels.add(channel)\n        return channel\n\n    def test_produce_consume_noack(self):\n        producer = Producer(self._add_channel(self.p.channel()), self.e)\n        consumer = Consumer(self._add_channel(self.c.channel()), self.q,\n                            no_ack=True)\n\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem')\n\n        _received = []\n\n        def callback(message_data, message):\n            _received.append(message)\n\n        consumer.register_callback(callback)\n        consumer.consume()\n\n        while 1:\n            if len(_received) == 10:\n                break\n            self.c.drain_events()\n\n        assert len(_received) == 10\n\n    def test_produce_consume(self):\n        producer_channel = self._add_channel(self.p.channel())\n        consumer_channel = self._add_channel(self.c.channel())\n        producer = Producer(producer_channel, self.e)\n        consumer1 = Consumer(consumer_channel, self.q)\n        consumer2 = Consumer(consumer_channel, self.q2)\n        self.q2(consumer_channel).declare()\n\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem')\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem2')\n\n        _received1 = []\n        _received2 = []\n\n        def callback1(message_data, message):\n            _received1.append(message)\n            message.ack()\n\n        def callback2(message_data, message):\n            _received2.append(message)\n            message.ack()\n\n        consumer1.register_callback(callback1)\n        consumer2.register_callback(callback2)\n\n        consumer1.consume()\n        consumer2.consume()\n\n        while 1:\n            if len(_received1) + len(_received2) == 20:\n                break\n            self.c.drain_events()\n\n        assert len(_received1) + len(_received2) == 20\n\n        # compression\n        producer.publish({'compressed': True},\n                         routing_key='test_transport_filesystem',\n                         compression='zlib')\n        m = self.q(consumer_channel).get()\n        assert m.payload == {'compressed': True}\n\n        # queue.delete\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem')\n        assert self.q(consumer_channel).get()\n        self.q(consumer_channel).delete()\n        self.q(consumer_channel).declare()\n        assert self.q(consumer_channel).get() is None\n\n        # queue.purge\n        for i in range(10):\n            producer.publish({'foo': i},\n                             routing_key='test_transport_filesystem2')\n        assert self.q2(consumer_channel).get()\n        self.q2(consumer_channel).purge()\n        assert self.q2(consumer_channel).get() is None\n"}
{"context": "<|file_sep|>kombu\\transport\\pyredis.py\nfrom Queue import Empty\n\nfrom anyjson import serialize, deserialize\nfrom redis import Redis\nfrom redis import exceptions\n\nfrom kombu.transport import virtual\n\nDEFAULT_PORT = 6379\nDEFAULT_DB = 0\n\n\nclass Channel(virtual.Channel):\n    _client = None\n\n    def _new_queue(self, queue, **kwargs):\n        pass\n\n    def _get(self, queue):\n        item = self.client.rpop(queue)\n        if item:\n            return deserialize(item)\n        raise Empty()\n\n    def _size(self, queue):\n        return self.client.llen(queue)\n\n    def _get_many(self, queues, timeout=None):\n        dest__item = self.client.brpop(queues, timeout=timeout)\n        if dest__item:\n            dest, item = dest__item\n            return deserialize(item), dest\n        raise Empty()\n\n    def _put(self, queue, message, **kwargs):\n        self.client.lpush(queue, serialize(message))\n\n    def _purge(self, queue):\n        size = self.client.llen(queue)\n        self.client.delete(queue)\n        return size\n\n    def close(self):\n        super(Channel, self).close()\n        try:\n            self.client.bgsave()\n        except exceptions.ResponseError:\n            pass\n\n    def _open(self):\n        conninfo = self.connection.connection\n        database = conninfo.virtual_host\n        if not isinstance(database, int):\n            if not database or database == \"/\":\n                database = DEFAULT_DB\n            elif database.startswith(\"/\"):\n                database = database[1:]\n            try:\n                database = int(database)\n            except ValueError:\n                raise ValueError(\n                    \"Database name must be int between 0 and limit - 1\")\n\n        return Redis(host=conninfo.hostname,\n                     port=conninfo.port or DEFAULT_PORT,\n                     db=database,\n                     password=conninfo.password)\n\n    @property\n    def client(self):\n        if self._client is None:\n            self._client = self._open()\n        return self._client\n\n\nclass Transport(virtual.Transport):\n    Channel = Channel\n\n    default_port = DEFAULT_PORT\n    connection_errors = (exceptions.ConnectionError,\n                         exceptions.AuthenticationError)\n    channel_errors = (exceptions.ConnectionError,\n                      exceptions.InvalidData,\n                      exceptions.InvalidResponse,\n                      exceptions.ResponseError)\n"}
{"context": "<|file_sep|>kombu\\transport\\base.py\n\"\"\"\nkombu.transport.base\n====================\n\nBase transport interface.\n\n\"\"\"\nfrom __future__ import absolute_import\n\nfrom kombu.exceptions import ChannelError, ConnectionError\nfrom kombu.message import Message\nfrom kombu.utils import cached_property\n\n__all__ = ['Message', 'StdChannel', 'Management', 'Transport']\n\n\ndef _LeftBlank(obj, method):\n    return NotImplementedError(\n        'Transport {0.__module__}.{0.__name__} does not implement {1}'.format(\n            obj.__class__, method))\n\n\nclass StdChannel(object):\n    no_ack_consumers = None\n\n    def Consumer(self, *args, **kwargs):\n        from kombu.messaging import Consumer\n        return Consumer(self, *args, **kwargs)\n\n    def Producer(self, *args, **kwargs):\n        from kombu.messaging import Producer\n        return Producer(self, *args, **kwargs)\n\n    def get_bindings(self):\n        raise _LeftBlank(self, 'get_bindings')\n\n    def after_reply_message_received(self, queue):\n        \"\"\"reply queue semantics: can be used to delete the queue\n           after transient reply message received.\"\"\"\n        pass\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc_info):\n        self.close()\n\n\nclass Management(object):\n\n    def __init__(self, transport):\n        self.transport = transport\n\n    def get_bindings(self):\n        raise _LeftBlank(self, 'get_bindings')\n\n\nclass Transport(object):\n    \"\"\"Base class for transports.\"\"\"\n    Management = Management\n\n    #: The :class:`~kombu.Connection` owning this instance.\n    client = None\n\n    #: Default port used when no port has been specified.\n    default_port = None\n\n    #: Tuple of errors that can happen due to connection failure.\n    connection_errors = (ConnectionError, )\n\n    #: Tuple of errors that can happen due to channel/method failure.\n    channel_errors = (ChannelError, )\n\n    #: For non-blocking use, an eventloop should keep\n    #: draining events as long as ``connection.more_to_read`` is True.\n    nb_keep_draining = False\n\n    #: Type of driver, can be used to separate transports\n    #: using the AMQP protocol (driver_type: 'amqp'),\n    #: Redis (driver_type: 'redis'), etc...\n    driver_type = 'N/A'\n\n    #: Name of driver library (e.g. 'py-amqp', 'redis', 'beanstalkc').\n    driver_name = 'N/A'\n\n    #: Whether this transports support heartbeats,\n    #: and that the :meth:`heartbeat_check` method has any effect.\n    supports_heartbeats = False\n\n    #: Set to true if the transport supports the AIO interface.\n    supports_ev = False\n\n    def __init__(self, client, **kwargs):\n        self.client = client\n\n    def establish_connection(self):\n        raise _LeftBlank(self, 'establish_connection')\n\n    def close_connection(self, connection):\n        raise _LeftBlank(self, 'close_connection')\n\n    def create_channel(self, connection):\n        raise _LeftBlank(self, 'create_channel')\n\n    def close_channel(self, connection):\n        raise _LeftBlank(self, 'close_channel')\n\n    def drain_events(self, connection, **kwargs):\n        raise _LeftBlank(self, 'drain_events')\n\n    def heartbeat_check(self, connection, rate=2):\n        pass\n\n    def driver_version(self):\n        return 'N/A'\n\n    def register_with_event_loop(self, loop):\n        pass\n\n    def verify_connection(self, connection):\n        return True\n\n    @property\n    def default_connection_params(self):\n        return {}\n\n    def get_manager(self, *args, **kwargs):\n        return self.Management(self)\n\n    @cached_property\n    def manager(self):\n        return self.get_manager()\n"}
{"context": "<|file_sep|>kombu\\__init__.py\n\"\"\"Messaging Framework for Python\"\"\"\nfrom __future__ import absolute_import\n\nVERSION = (2, 4, 7)\n__version__ = '.'.join(map(str, VERSION[0:3])) + ''.join(VERSION[3:])\n__author__ = 'Ask Solem'\n__contact__ = 'ask@celeryproject.org'\n__homepage__ = 'http://kombu.readthedocs.org'\n__docformat__ = 'restructuredtext en'\n\n# -eof meta-\n\nimport os\nimport sys\n\nif sys.version_info < (2, 5):  # pragma: no cover\n    if sys.version_info >= (2, 4):\n        raise Exception(\n                'Python 2.4 is not supported by this version. '\n                'Please use Kombu versions 1.x.')\n    else:\n        raise Exception('Kombu requires Python versions 2.5 or later.')\n\n# Lazy loading.\n# - See werkzeug/__init__.py for the rationale behind this.\nfrom types import ModuleType\n\nall_by_module = {\n    'kombu.connection': ['Connection', 'BrokerConnection'],\n    'kombu.entity':     ['Exchange', 'Queue'],\n    'kombu.messaging':  ['Consumer', 'Producer'],\n    'kombu.pools':      ['connections', 'producers'],\n    'kombu.utils.url':  ['parse_url'],\n    'kombu.common':     ['eventloop', 'uuid']\n}\n\nobject_origins = {}\nfor module, items in all_by_module.iteritems():\n    for item in items:\n        object_origins[item] = module\n\n\nclass module(ModuleType):\n\n    def __getattr__(self, name):\n        if name in object_origins:\n            module = __import__(object_origins[name], None, None, [name])\n            for extra_name in all_by_module[module.__name__]:\n                setattr(self, extra_name, getattr(module, extra_name))\n            return getattr(module, name)\n        return ModuleType.__getattribute__(self, name)\n\n    def __dir__(self):\n        result = list(new_module.__all__)\n        result.extend(('__file__', '__path__', '__doc__', '__all__',\n                       '__docformat__', '__name__', '__path__', 'VERSION',\n                       '__package__', '__version__', '__author__',\n                       '__contact__', '__homepage__', '__docformat__'))\n        return result\n\n# 2.5 does not define __package__\ntry:\n    package = __package__\nexcept NameError:\n    package = 'kombu'\n\n# keep a reference to this module so that it's not garbage collected\nold_module = sys.modules[__name__]\n\nnew_module = sys.modules[__name__] = module(__name__)\nnew_module.__dict__.update({\n    '__file__': __file__,\n    '__path__': __path__,\n    '__doc__': __doc__,\n    '__all__': tuple(object_origins),\n    '__version__': __version__,\n    '__author__': __author__,\n    '__contact__': __contact__,\n    '__homepage__': __homepage__,\n    '__docformat__': __docformat__,\n    '__package__': package,\n    'VERSION': VERSION})\n\nif os.environ.get('KOMBU_LOG_DEBUG'):\n    os.environ.update(KOMBU_LOG_CHANNEL='1', KOMBU_LOG_CONNECTION='1')\n    from .utils import debug\n    debug.setup_logging()\n"}
{"context": "<|file_sep|>garlicsim\\garlicsim\\asynchronous_crunching\\crunchers\\process_cruncher\\__init__.py\n# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\nThis package defines the `ProcessCruncher` class.\n\nSee its documentation for more information.\n\nThis package requires the `multiprocessing` package to be installed. It is part of\nthe standard library for Python 2.6 and above, but not for earlier versions. A\nbackport of it for Python 2.5 is available at\nhttp://pypi.python.org/pypi/multiprocessing.\n'''\n\nfrom .process_cruncher import ProcessCruncher\n"}
{"context": "<|file_sep|>garlicsim\\garlicsim\\general_misc\\sys_tools.py\nimport os\nimport sys\nimport cStringIO\nimport subprocess\n\nfrom garlicsim.general_misc.temp_value_setters import TempValueSetter\n\n\nclass OutputCapturer(object):\n    '''\n\n    \n    with OutputCapturer as output_capturer:\n        do_stuff()\n    output_capturer.output # <-- String containing all output\n    '''\n    def __init__(self):\n        self.string_io = cStringIO.StringIO()\n        self._temp_stdout_setter = \\\n            TempValueSetter((sys, 'stdout'), self.string_io)\n        self.output = None\n    \n    def __enter__(self):\n        self._temp_stdout_setter.__enter__()\n        return self\n    \n    def __exit__(self, *args, **kwargs):\n        self._temp_stdout_setter.__exit__(*args, **kwargs)\n        self.output = self.string_io.getvalue()\n\n\ndef execute(command):\n    with OutputCapturer() as output_capturer:\n        subprocess.Popen('command', shell=True)\n    return output_capturer.output\n    "}
{"context": "<|file_sep|>garlicsim\\garlicsim\\general_misc\\sleek_refs\\cute_sleek_value_dictionary.py\nimport weakref\nimport UserDict\n\nfrom garlicsim.general_misc.third_party import inspect\n\nfrom .sleek_ref import SleekRef\n\n\n__all__ = ['CuteSleekValueDictionary']\n\n\nclass CuteSleekValueDictionary(UserDict.UserDict):\n    \"\"\"Mapping class that references values weakly.\n\n    Entries in the dictionary will be discarded when no strong\n    reference to the value exists anymore\n    \"\"\"\n    # We inherit the constructor without worrying about the input\n    # dictionary; since it uses our .update() method, we get the right\n    # checks (if the other dictionary is a WeakValueDictionary,\n    # objects are unwrapped on the way out, and we always wrap on the\n    # way in).\n\n    def __init__(self, callback, *args, **kw):\n        self.callback = callback\n        def remove(wr, selfref=weakref.ref(self)):\n            # print('removing') # tododoc: kill\n            self = selfref()\n            if self is not None:\n                del self.data[wr.key]\n                self.callback()\n        self._remove = remove\n        UserDict.UserDict.__init__(self, *args, **kw)\n\n    def __getitem__(self, key):\n        o = self.data[key]()\n        if o is None:\n            raise KeyError, key\n        else:\n            return o\n\n    def __contains__(self, key):\n        try:\n            o = self.data[key]()\n        except KeyError:\n            return False\n        return o is not None\n\n    def has_key(self, key):\n        try:\n            o = self.data[key]()\n        except KeyError:\n            return False\n        return o is not None\n\n    def __repr__(self): # tododoc\n        return \"<WeakValueDictionary at %s>\" % id(self)\n\n    def __setitem__(self, key, value):\n        self.data[key] = KeyedSleekRef(value, self._remove, key)\n\n    '''def copy(self):\n        new = WeakValueDictionary()\n        for key, wr in self.data.items():\n            o = wr()\n            if o is not None:\n                new[key] = o\n        return new''' # tododoc\n\n    def get(self, key, default=None):\n        try:\n            wr = self.data[key]\n        except KeyError:\n            return default\n        else:\n            o = wr()\n            if o is None:\n                # This should only happen\n                return default\n            else:\n                return o\n\n    def items(self):\n        L = []\n        for key, wr in self.data.items():\n            o = wr()\n            if o is not None:\n                L.append((key, o))\n        return L\n\n    def iteritems(self):\n        for wr in self.data.itervalues():\n            value = wr()\n            if value is not None:\n                yield wr.key, value\n\n    def iterkeys(self):\n        return self.data.iterkeys()\n\n    def __iter__(self):\n        return self.data.iterkeys()\n\n    def itervaluerefs(self):\n        \"\"\"Return an iterator that yields the weak references to the values.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the values around longer than needed.\n\n        \"\"\"\n        return self.data.itervalues()\n\n    def itervalues(self):\n        for wr in self.data.itervalues():\n            obj = wr()\n            if obj is not None:\n                yield obj\n\n    def popitem(self):\n        while 1:\n            key, wr = self.data.popitem()\n            o = wr()\n            if o is not None:\n                return key, o\n\n    def pop(self, key, *args):\n        try:\n            o = self.data.pop(key)()\n        except KeyError:\n            if args:\n                return args[0]\n            raise\n        if o is None:\n            raise KeyError, key\n        else:\n            return o\n\n    def setdefault(self, key, default=None):\n        try:\n            wr = self.data[key]\n        except KeyError:\n            self.data[key] = KeyedSleekRef(default, self._remove, key)\n            return default\n        else:\n            return wr()\n\n    def update(self, dict=None, **kwargs):\n        d = self.data\n        if dict is not None:\n            if not hasattr(dict, \"items\"):\n                dict = type({})(dict)\n            for key, o in dict.items():\n                d[key] = KeyedSleekRef(o, self._remove, key)\n        if len(kwargs):\n            self.update(kwargs)\n\n    def valuerefs(self):\n        \"\"\"Return a list of weak references to the values.\n\n        The references are not guaranteed to be 'live' at the time\n        they are used, so the result of calling the references needs\n        to be checked before being used.  This can be used to avoid\n        creating references that will cause the garbage collector to\n        keep the values around longer than needed.\n\n        \"\"\"\n        return self.data.values()\n\n    def values(self):\n        L = []\n        for wr in self.data.values():\n            o = wr()\n            if o is not None:\n                L.append(o)\n        return L\n\n\nclass KeyedSleekRef(SleekRef):\n    \"\"\"Specialized reference that includes a key corresponding to the value.\n\n    This is used in the WeakValueDictionary to avoid having to create\n    a function object for each key stored in the mapping.  A shared\n    callback object can use the 'key' attribute of a KeyedSleekRef instead\n    of getting a reference to the key from an enclosing scope.\n\n    \"\"\"\n\n    def __new__(type, ob, callback, key):\n        self = SleekRef.__new__(type)\n        return self\n\n    def __init__(self, ob, callback, key):\n        super(KeyedSleekRef, self).__init__(ob, callback)\n        if self.ref:\n            self.ref.key = key\n\n"}
{"context": "<|file_sep|>garlicsim\\garlicsim\\data_structures\\path.py\n# Copyright 2009-2010 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\nA module that defines the Path class and a few related exceptions.\n\nSee its documentation for more information.\n'''\n\nimport copy as copy_module # Avoiding name clash.\n\nfrom node import Node\nfrom block import Block\n# We are doing `from tree import Tree` in the bottom of the file.\n\nimport garlicsim.general_misc.binary_search as binary_search\n\n__all__ = ['Path', 'PathError', 'PathOutOfRangeError', 'EndNotReached',\n           'StartNotReached']\n\nclass PathError(Exception):\n    '''An exception related to the class Path.'''\n    pass\n\nclass PathOutOfRangeError(PathError):\n    '''\n    Nodes are requested from the path which are out of its range.\n    '''\n    pass\n\nclass EndNotReached(PathError):\n    '''\n    An end node/block is specified but it turns out not to be on the path.\n    '''\n    pass\n\nclass StartNotReached(PathError):\n    '''\n    A start node/block is specified but it turns out not to be on the path.\n    '''\n    pass\n\nclass Path(object):\n    '''\n    A path symbolizes a line of nodes in a tree. A tree may be complex and\n    contain many junctions, but a path is a direct line through it. Therefore,\n    a path object contains information about which child to choose when going\n    through a node which has multiple children.\n    \n    The attribute \".decisions\" is a dictionary of the form {node_which_forks: \n    node_to_continue_to, ... }. It usually contains as keys only nodes that\n    have more than one child.\n    \n    The attribute \".root\" says from which node the path begins.\n    \n    Some of Path's method accept `start` and `end` parameters for specifying a\n    sub-range inside the path. It should be noted that this range will include\n    both endpoints.\n    '''\n    def __init__(self, tree, root=None, decisions={}):\n\n        self.tree = tree\n        \n        self.root = root\n        '''The root node.'''\n        \n        self.decisions = dict(decisions)\n        '''\n        The decisions dict says which fork of the road the path chooses.\n        It's of the form {node_which_forks: node_to_continue_to, ... }\n        '''\n         # todo: Use shallow copy instead of dict.__init__. Will allow\n         # dictoids.\n\n         \n    def __len__(self, start=None, end=None):\n        '''\n        Get the length of the path in nodes.\n        \n        You can optionally specify `start` and/or `end`, which may be either\n        nodes or blocks.\n        '''\n        if start is None and self.root is None:\n            return 0\n            \n        return sum(len(thing) for thing in \n                   self.iterate_blockwise(start=start, end=end))\n\n\n    def __iter__(self, start=None, end=None):\n        '''\n        Iterate over the nodes in the path.\n        \n        You can optionally specify `start` and/or `end`, which may be either\n        nodes or blocks.\n        '''\n        if start is None:\n            if self.root is None:\n                raise StopIteration\n            current = self.root\n        else:\n            current = start\n        \n        current = current if isinstance(current, Node) else current[0]\n            \n        while True:\n            \n            yield current\n            \n            if end is not None:\n                if current is end:\n                    raise StopIteration\n                elif isinstance(end, Block) and (current in end):\n                    if current.is_last_on_block():\n                        raise StopIteration\n                        \n            try:\n                current = self.next_node(current)           \n            except PathOutOfRangeError:\n                if end is not None:\n                    raise EndNotReached\n                raise StopIteration\n            \n            \n    def iterate_blockwise(self, start=None, end=None):\n        '''\n        Iterate on the path, yielding blocks when possible.\n        \n        You can optionally specify `start` and/or `end`, which may be either\n        nodes or blocks.\n        '''\n\n        if start is None:\n            if self.root is None:\n                raise StopIteration\n            current = self.root.soft_get_block()\n        else: # start is not None\n            current = start\n            if isinstance(start, Node) and start.block is not None and \\\n               start.is_first_on_block() is False:\n                # We are starting iteration on a node in a block. (And it's not\n                # the first one on the block.) We will not yield its block at\n                # all. We'll yield all the nodes one by one until the next\n                # node/block in the tree.\n                index_of_start = start.block.index(start)\n                for current in start.block[index_of_start:]:\n                    yield current\n                    if current is end:\n                        raise StopIteration\n                    \n                assert current is start.block[-1]\n                \n                try:\n                    current = self.next_node(current)\n                except PathOutOfRangeError:\n                    if end is not None:\n                        raise EndNotReached\n                    raise StopIteration\n                \n        while True:\n            if current.block is not None:\n                if end is not None:\n                    if end is current.block:\n                        yield current.block\n                        raise StopIteration\n                    elif end in current.block:\n                        index_of_end = current.block.index(end)\n                        for thing in current.block[ 0 : (index_of_end + 1) ]:\n                            yield thing\n                        raise StopIteration\n                else: # end is None\n                    current = current.block\n                    yield current\n            else: # current.block is None\n                yield current\n                if current.is_overlapping(end):\n                    raise StopIteration\n            try:\n                current = self.next_node(current)\n            except PathOutOfRangeError:\n                if end is not None:\n                    raise EndNotReached\n                raise StopIteration\n    \n            \n    def iterate_blockwise_reversed(self, end, start=None):\n        '''\n        Iterate backwards on the path, yielding blocks when possible.\n        \n        You must specify an `end`. You may optionally specify a `start`. Both of\n        these may be either nodes or blocks.\n        '''\n        current = end\n        if isinstance(end, Node) and end.block is not None and \\\n           end.is_last_on_block() is False:\n            # We are starting iteration on a node in a block. (And it's not the\n            # last one on the block.) We will not yield its block at all. We'll\n            # yield all the nodes one by one until the previous node/block in\n            # the tree.\n            index_of_end = end.block.index(end)\n            for current in end.block[ index_of_end : : -1 ]:\n                yield current\n                if current is start:\n                    raise StopIteration\n\n            assert current is end.block[0]\n            \n            if isinstance(current, Node):\n                current = current.parent\n            else: # isinstance(current, Block)\n                current = current[0].parent\n            if current is None:\n                if start is not None:\n                    raise StartNotReached\n                raise StopIteration\n                \n        while True:\n            if current.block is not None:\n                if start is not None:\n                    if start is current.block:\n                        yield current.block\n                        raise StopIteration\n                    elif start in current.block:\n                        index_of_start = current.block.index(start)\n                        for thing in current.block[ : (index_of_start - 1) : -1 ]:\n                            yield thing\n                        raise StopIteration\n                else: # start is None\n                    current = current.block\n                    yield current\n            else: # current.block is None\n                yield current\n                if current.is_overlapping(start):\n                    raise StopIteration\n\n            if isinstance(current, Node):\n                current = current.parent\n            else: # isinstance(current, Block)\n                current = current[0].parent\n            if current is None:\n                if start is not None:\n                    raise StartNotReached\n                raise StopIteration\n            \n\n    def __contains__(self, thing):\n        '''\n        Return whether the path contains the specified node/block.\n        '''\n        assert isinstance(thing, Node) or isinstance(thing, Block)\n\n        for candidate in self.iterate_blockwise():\n            if candidate is thing:\n                return True\n            elif isinstance(candidate, Block) and thing in candidate:\n                return True\n            \n        return False\n\n\n    def next_node(self, thing):\n        '''\n        Return the node on the path which is next after `thing`.\n        \n        If we've come to a fork for which we have no key in the decisions dict,\n        we choose the most recent child node, and update the decisions dict to\n        point to it as well.\n        '''\n        \n        # We're dealing with the case of 1 child first, because it's the most\n        # common.\n        real_thing = thing if isinstance(thing, Node) else thing[-1]\n        kids = real_thing.children\n        if len(kids) == 1:\n            return kids[0]\n        \n        if (thing in self.decisions) or (real_thing in self.decisions):\n            return self.decisions.get(thing, None) or \\\n                   self.decisions.get(real_thing, None)\n        \n        if len(kids) > 1:\n            kid = kids[-1]\n            self.decisions[real_thing] = kid\n            return kid\n\n        else: # no kids\n            raise PathOutOfRangeError\n            \n\n    def __getitem__(self, index, end=None):\n        '''\n        Get a node by its index number in the path.\n\n        You can optionally specify an end node in which the path ends.\n        '''\n        assert isinstance(index, int)\n        \n        if index >= 0:\n            return self.__get_item_positive(index, end=end)\n        else:\n            return self.__get_item_negative(index, end=end)\n\n        \n    def __get_item_negative(self, index, end=None):\n        '''\n        Get a node by its index number in the path. Negative indices only.\n\n        You can optionally specify an end node in which the path ends.\n        '''\n        if end is None:\n            end = self.get_last_node()\n        else:\n            assert isinstance(end, Node)\n        if index == -1:\n            return end\n        \n        my_index = 0\n        \n        if end.block:\n            block = end.block\n            index_of_end = block.index(end)\n            \n            my_index -= (index_of_end + 1)\n            \n            if my_index <= index:\n                return block[index - my_index]\n        \n        for thing in self.iterate_blockwise_reversed(end=end):\n            my_index -= len(thing)\n            if my_index <= index:\n                if isinstance(thing, Block):\n                    return thing[(index - my_index)]\n                else:\n                    assert my_index == index\n                    return thing\n                \n        raise PathOutOfRangeError\n        \n    \n    def __get_item_positive(self, index, end=None):\n        '''\n        Get a node by its index number in the path. Positive indices only.\n\n        You can optionally specify an end node in which the path ends.\n        '''\n        my_index = -1\n        answer = None\n        for thing in self.iterate_blockwise(end=end):\n            my_index += len(thing)\n            if my_index >= index:\n                if isinstance(thing, Block):\n                    answer = thing[(index-my_index) - 1]\n                    break \n                else:\n                    assert my_index == index\n                    answer = thing\n                    break\n        if answer is not None:\n            return answer\n        raise PathOutOfRangeError\n\n    def get_last_node(self, start=None):\n        '''\n        Get the last node in the path.\n        \n        You can optionally specify `start`, which may be either a node or block.\n        '''\n        for thing in self.iterate_blockwise(start=start):\n            pass\n\n        if isinstance(thing, Block):\n            return thing[-1]\n        else:\n            return thing\n    \n        \n    def get_node_by_clock(self, clock, rounding=\"closest\", end_node=None):\n        '''\n        Get a node according to its clock.\n        \n        See documentation of garlicsim.general_misc.binary_search.binary_search\n        for details about rounding options.\n        '''\n        \n        my_function = lambda node: node.state.clock\n        return self.get_node_by_monotonic_function(function=my_function,\n                                                   value=clock,\n                                                   rounding=rounding,\n                                                   end_node=end_node)    \n        \n    \n    def get_node_by_monotonic_function(self, function, value,\n                                       rounding=\"closest\", end_node=None):\n        '''\n        Get a node by specifying a measure function and a desired value.\n        \n        The function must be a monotonic rising function on the timeline.\n        \n        See documentation of garlicsim.general_misc.binary_search.binary_search\n        for details about rounding options.\n        '''\n        \n        assert rounding in [\"high\", \"low\", \"exact\", \"both\", \"closest\"]        \n\n        if end_node is None:\n            correct_both_for_end_node = lambda both: both\n        else:\n            def correct_both_for_end_node(both):\n                new_both = list(both)\n                end_clock = end_node.state.clock\n                if new_both[0] and new_both[0].state.clock >= end_clock:\n                    new_both[0] = end_node\n                if new_both[1] and new_both[1].state.clock >= end_clock:\n                    new_both[1] = None\n                return tuple(new_both)\n        \n        low = self.root\n        \n        if function(low) >= value:\n            both = correct_both_for_end_node((None, low))\n            return binary_search.make_both_data_into_preferred_rounding \\\n                   (both, function, value, rounding)\n        \n        '''\n        Now we've established that the first node in the path has a lower value\n        than what we're looking for.\n        '''\n        \n        for thing in self.iterate_blockwise():\n            if isinstance(thing, Block):\n                first = thing[0]\n                if function(first) >= value:\n                    both = correct_both_for_end_node((low, first))\n                    return binary_search.make_both_data_into_preferred_rounding \\\n                           (both, function, value, rounding)\n                    \n                last = thing[-1]\n                if function(last) >= value:\n                    # It's in the block\n                    both = binary_search.binary_search(thing, function, value,\n                                                       rounding=\"both\")\n                    both = correct_both_for_end_node(both)\n                    return binary_search.make_both_data_into_preferred_rounding \\\n                           (both, function, value, rounding)\n                else:\n                    low = last\n                    continue\n            else: # thing is a Node\n                if function(thing) >= value:\n                    both = correct_both_for_end_node((low, thing))\n                    return binary_search.make_both_data_into_preferred_rounding \\\n                           (both, function, value, rounding)\n                else:\n                    low = thing\n                    continue\n        \n        '''\n        If the flow reached here, that means that even the last node\n        in the path has lower value than the value we're looking for.\n        '''\n        \n        both = correct_both_for_end_node((low, None))\n        return binary_search.make_both_data_into_preferred_rounding \\\n               (both, function, value, rounding)\n            \n    \n    def get_node_occupying_timepoint(self, timepoint):\n        '''\n        Get the node which \"occupies\" the given timepoint.\n        \n        A node is considered to \"occupy\" a timepoint if it is the\n        highest-clocked node before the timepoint, AND there exists another\n        node which has a clock higher than timepoint (that higher node is not\n        returned, it just has to exist for the first node to qualify as\n        \"occupying\".)\n        \n        If no such node exists, returns None.\n        '''\n        temp = self.get_node_by_clock(timepoint, rounding=\"both\")\n        if list(temp).count(None) == 0:\n            return temp[0]\n        else:\n            return None\n        \n\n    def get_existing_time_segment(self, start_time, end_time):\n        '''\n        Get the existing time segment between `start_time` and `end_time`.\n        \n        Example: In the path the first node's clock reading is 3.2, the last is\n        7.6.\n        `start_time` is 2 and `end_time` is 5.\n        The function will return [3.2, 5].\n        '''\n\n        clock_of_first = self.root.state.clock\n        clock_of_last = self.get_last_node().state.clock\n        \n        if clock_of_first <= end_time and clock_of_last >= start_time:            \n            return [max(clock_of_first, start_time),\n                    min(clock_of_last, end_time)]\n        else:\n            return None\n    \n        \n    def modify_to_include_node(self, node):\n        '''\n        Modifiy the path to include the specified node.\n        '''\n        new_path = node.make_containing_path()\n        self.root = new_path.root\n        self.decisions.update(new_path.decisions)\n    \n        \n    def __repr__(self):\n        '''\n        Get a string representation of the path.\n        \n        Example output:\n        <garlicsim.data_structures.path.Path of length 43 at 0x1c822d0>\n        '''\n        return '<%s.%s of length %s at %s>' % \\\n               (\n                   self.__class__.__module__,\n                   self.__class__.__name__,\n                   len(self),\n                   hex(id(self))\n               )\n    \n    \n    def copy(self):\n        '''\n        Make a shallow copy of the path.\n        '''\n        \n        # Most of these things don't need duplicating, but just for\n        # completeness' sake:\n        tree = self.tree\n        root = self.root\n        decisions = self.decisions.copy()\n        \n        path = Path(tree=tree, root=root, decisions=decisions)\n        \n        return path\n    \n    \n    __copy__ = copy\n    \n    \nfrom tree import Tree"}
{"context": "<|file_sep|>garlicsim\\tests\\general_misc\\cute_profile\\cute_profile.py\n\nfrom garlicsim.general_misc import cute_profile\n\nfrom .shared import call_and_check_if_profiled\n\n\ndef func(x, y, z=3):\n    sum([1, 2, 3])\n    set([1, 2]) | set([2, 3])\n    return x, y, z\n\n\n\ndef test_profile_ready():\n    \n    f = cute_profile.profile_ready(start_on=True, off_after=False)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    "}
{"context": "<|file_sep|>garlicsim\\garlicsim\\asynchronous_crunching\\crunchers\\thread_cruncher.py\n# Copyright 2009-2010 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\nThis module defines the ThreadCruncher class.\n\nSee its documentation for more information.\n'''\n\nimport threading\nimport Queue\nimport copy\n\nimport garlicsim\nfrom garlicsim.asynchronous_crunching import \\\n     BaseCruncher, HistoryBrowser, ObsoleteCruncherError, CrunchingProfile\n\n\n__all__ = ['ThreadCruncher']\n\n\nclass ThreadCruncher(BaseCruncher, threading.Thread):\n    '''\n    ThreadCruncher is cruncher that works from a thread.\n    \n    A cruncher is a worker which crunches the simulation. It receives a state\n    from the main program, and then it repeatedly applies the step function of\n    the simulation to produce more states. Those states are then put in the\n    cruncher's work_queue. They are then taken by the main program when\n    Project.sync_crunchers is called, and put into the tree.\n        \n    Read more about crunchers in the documentation of the crunchers package.\n    \n    The advantages of ThreadCruncher over ProcessCruncher are:\n    1. ThreadCruncher is able to handle simulations that are history-dependent,\n       which would have been very hard to implement in a Process, since\n       processes don't share memory, and threads do share memory trivially.\n    2. ThreadCruncher is based on the threading module, which is stabler and\n       more mature than the multiprocessing module.\n    3. ThreadCruncher is much easier to debug than ProcessCruncher, since there\n       are currently many more tools for debugging Python threads than Python\n       processes.\n    4. On a single-core computer, ThreadCruncher may be faster than\n       ProcessCruncher because of shared memory.\n    '''\n    def __init__(self, crunching_manager, initial_state, crunching_profile):\n        BaseCruncher.__init__(self, crunching_manager,\n                              initial_state, crunching_profile)\n        threading.Thread.__init__(self)\n        \n        self.step_iterator_getter = \\\n            self.project.simpack_grokker.get_step_iterator\n        self.history_dependent = self.project.simpack_grokker.history_dependent\n        \n        self.last_clock = initial_state.clock\n        \n        self.daemon = True\n\n        self.work_queue = Queue.Queue()\n        '''\n        Queue for putting completed work to be picked up by the main thread.\n        \n        In this queue the cruncher will put the states that it produces, in\n        chronological order. If the cruncher is being given a new crunching\n        profile which has a new and different step profile, the cruncher\n        will put the new step profile in this queue in order to signal that\n        from that point on, all states were crunched with that step profile.\n        '''\n\n        self.order_queue = Queue.Queue()\n        '''Queue for receiving instructions from the main thread.'''\n\n        \n    def run(self):\n        '''\n        Internal method.\n        \n        This is called when the cruncher is started. It just calls the main_loop\n        method in a try clause, excepting ObsoleteCruncherError; That exception\n        means that the cruncher has been retired in the middle of its job, so it\n        is propagated up to this level, where it causes the cruncher to\n        terminate.\n        '''\n        try:\n            self.main_loop()\n        except ObsoleteCruncherError:\n            return\n\n    def main_loop(self):\n        '''\n        The main loop of the cruncher.\n        \n        Crunches the simulations repeatedly until the crunching profile is\n        satisfied or a 'retire' order is received.\n        '''\n        \n        self.step_profile = self.crunching_profile.step_profile\n        \n        if self.history_dependent:\n            self.history_browser = HistoryBrowser(cruncher=self)\n            thing = self.history_browser\n        else:\n            thing = self.initial_state\n\n        self.iterator = self.step_iterator_getter(thing, self.step_profile)\n            \n        order = None\n        \n        try:\n            for state in self.iterator:\n                self.work_queue.put(state)\n                self.check_crunching_profile(state)\n                order = self.get_order()\n                if order:\n                    self.process_order(order)\n        except garlicsim.misc.WorldEnd:\n            self.work_queue.put(garlicsim.asynchronous_crunching.misc.EndMarker())\n\n        \n    def check_crunching_profile(self, state):\n        '''\n        Check if the cruncher crunched enough states. If so retire.\n        \n        The crunching manager specifies how much the cruncher should crunch.\n        We consult with it to check if the cruncher has finished, and if it did\n        we retire the cruncher.\n        '''\n        if self.crunching_profile.state_satisfies(state):\n            raise ObsoleteCruncherError(\"We're done working, the clock target \"\n                                        \"has been reached. Shutting down.\")\n\n        \n    def get_order(self):\n        '''\n        Attempt to read an order from the order_queue, if one has been sent.\n        \n        Returns the order.\n        '''\n        try:\n            return self.order_queue.get(block=False)\n        except Queue.Empty:\n            return None\n\n        \n    def process_order(self, order):\n        '''Process an order receieved from order_queue.'''\n        if order == 'retire':\n            raise ObsoleteCruncherError(\"Cruncher received a 'retire' order; \"\n                                        \"Shutting down.\")\n        \n        elif isinstance(order, CrunchingProfile):\n            self.process_crunching_profile_order(order)\n            \n            \n    def process_crunching_profile_order(self, order):\n        '''Process an order to update the crunching profile.'''\n        if self.crunching_profile.step_profile != order.step_profile:\n            raise ObsoleteCruncherError('Step profile changed; Shutting down. '\n                                        'Crunching manager should create a '\n                                        'new cruncher.')\n        self.crunching_profile = order\n\n        \n    def retire(self):\n        '''\n        Retire the cruncher. Thread-safe.\n        \n        Causes it to shut down as soon as it receives the order.\n        '''\n        self.order_queue.put('retire')        \n        \n        \n    def update_crunching_profile(self, profile):\n        '''Update the cruncher's crunching profile. Thread-safe.'''\n        self.order_queue.put(profile)\n        \n        \n    is_alive = threading.Thread.isAlive\n    '''Crutch for Python 2.5 and below.'''\n    \n\n"}
{"context": "<|file_sep|>garlicsim\\garlicsim\\misc\\simpack_grokker\\get_step_type.py\n# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\nimport types\n\nfrom garlicsim.general_misc.third_party import decorator\n\nfrom garlicsim.misc import GarlicSimException\n\nfrom .step_types import (SimpleStep, StepGenerator, HistoryStep,\n                         HistoryStepGenerator, InplaceStep,\n                         InplaceStepGenerator)\n\n\ndef get_step_type(step_function):\n    # todo: have this raise a specific exception when getting something other\n    # than a step function\n    \n    # blocktodo: figure out if this raises exception or returns false. It's a\n    # problem if I'm relying on it to raise while it just returns False.\n    step_type_attribute = getattr(step_function, 'step_type', None)\n    if step_type_attribute:\n        return step_type_attribute\n    else:\n        step_type = _get_step_type(step_function)\n        actual_function = (\n            step_function.im_func if\n            isinstance(step_function, types.MethodType)\n            else step_function\n        )\n        actual_function.step_type = step_type\n        return step_type\n\n\ndef _get_step_type(step_function):\n    if not callable(step_function):\n        raise GarlicSimException(\"%s is not a callable object, so it can't be \"\n                                 \"a step function.\" % step_function)\n    name = step_function.__name__\n    \n    if 'step' not in name:\n        raise GarlicSimException(\n            \"%s is not a step function-- It doesn't have the word 'step' in \"\n            \"it. If you want GarlicSim to use it as a step function, give it \"\n            \"a `.step_type` attribute pointing to a step type. (Like \"\n            \"`garlicsim.misc.simpack_grokker.step_types.SimpleStep`.)\" \\\n            % step_function)\n    \n    if 'inplace_step_generator' in name:\n        raise NotImplementedError('`inplace_step_generator` not yet '\n                                  'supported. It will probably become '\n                                  'available in GarlicSim 0.7 in mid-2011.')\n        return InplaceStepGenerator\n    \n    elif 'inplace_step' in name:\n        raise NotImplementedError('`inplace_step` not yet '\n                                  'supported. It will probably become '\n                                  'available in GarlicSim 0.7 in mid-2011.')\n        return InplaceStep\n    \n    elif 'history_step_generator' in name:\n        raise NotImplementedError('`history_step_generator` not yet. '\n                                  'supported. It will probably become '\n                                  'available in GarlicSim 0.7 in mid-2011.')\n        return HistoryStepGenerator\n    \n    elif 'step_generator' in name:\n        return StepGenerator\n    \n    elif 'history_step' in name:\n        return HistoryStep\n    \n    else:\n        assert 'step' in name\n        return SimpleStep\n    "}
{"context": "<|file_sep|>garlicsim\\test_garlicsim\\test_general_misc\\test_sys_tools\\test_output_capturer.py\n# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''Testing module for `garlicsim.general_misc.sys_tools.OutputCapturer`.'''\n\nfrom __future__ import with_statement\n\nfrom garlicsim.general_misc.sys_tools import OutputCapturer\n\n\ndef test():\n    '''Test the basic workings of `OutputCapturer`.'''\n    with OutputCapturer() as output_capturer:\n        print('meow')\n    assert output_capturer.output == 'meow\\n'\n    \n    \ndef test_nested():\n    '''Test an `OutputCapturer` inside an `OutputCapturer`.'''\n    with OutputCapturer() as output_capturer_1:\n        print('123')\n        with OutputCapturer() as output_capturer_2:\n            print('456')\n        assert output_capturer_2.output == '456\\n'\n    assert output_capturer_1.output == '123\\n'\n"}
{"context": "<|file_sep|>garlicsim\\test_garlicsim\\test_general_misc\\test_cute_profile\\test_cute_profile.py\n# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\nTesting module for `garlicsim.general_misc.cute_profile`.\n'''\n\nfrom garlicsim.general_misc import cute_profile\nfrom garlicsim.general_misc import cute_testing\n\nfrom .shared import call_and_check_if_profiled\n\n\ndef func(x, y, z=3):\n    '''Function that does some meaningless number-juggling.'''\n    sum([1, 2, 3])\n    set([1, 2]) | set([2, 3])\n    return x, y, z\n\n\n\ndef test_simple():\n    '''Test the basic workings of `profile_ready`.'''\n    f = cute_profile.profile_ready()(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    \n    f = cute_profile.profile_ready(condition=True)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    \n    f = cute_profile.profile_ready(condition=True, off_after=False)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    \n    \n    f = cute_profile.profile_ready(off_after=True)(func)\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.profiling_on = True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    f.condition = lambda f, *args, **kwargs: True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is True\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    assert call_and_check_if_profiled(lambda: f(1, 2)) is False\n    \n    \n    \ndef test_method():\n    '''Test that `profile_ready` works as a method decorator.'''\n    \n    class A(object):\n        def __init__(self):\n            self.x = 0\n                \n        @cute_profile.profile_ready(off_after=False)\n        def increment(self):\n            sum([1, 2, 3])\n            self.x += 1\n            \n    a = A()\n    assert a.x == 0\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 1\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 2\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 3\n\n    a.increment.im_func.profiling_on = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 4\n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 5\n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 6\n    \n    a.increment.im_func.off_after = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 7\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 8\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 9\n    \n    a.increment.im_func.profiling_on = True\n    \n    assert call_and_check_if_profiled(a.increment) is True\n    assert a.x == 10\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 11\n    assert call_and_check_if_profiled(a.increment) is False\n    assert a.x == 12\n    \n    \n\ndef test_condition():\n    '''Test the `condition` argument of `profile_ready`.'''\n\n    x = 7\n    \n    @cute_profile.profile_ready(condition=lambda function, y: x == y,\n                                off_after=False)\n    def f(y):\n        pass\n    \n    # Condition is `False`:\n    assert call_and_check_if_profiled(lambda: f(5)) is False\n    assert call_and_check_if_profiled(lambda: f(6)) is False\n    \n    # Condition is `True`:\n    assert call_and_check_if_profiled(lambda: f(7)) is True\n    \n    # So now profiling is on regardless of condition:\n    assert call_and_check_if_profiled(lambda: f(8)) is True\n    assert call_and_check_if_profiled(lambda: f(9)) is True\n    assert call_and_check_if_profiled(lambda: f(4)) is True\n    assert call_and_check_if_profiled(lambda: f('frr')) is True\n    \n    # Setting profiling off:\n    f.profiling_on = False\n        \n    # So no profiling now:\n    assert call_and_check_if_profiled(lambda: f(4)) is False\n    assert call_and_check_if_profiled(lambda: f('frr')) is False\n    \n    # Until the condition becomes `True` again: (And this time, for fun, with a\n    # different `x`:)\n    x = 9\n    assert call_and_check_if_profiled(lambda: f(9)) is True\n    \n    # So now, again, profiling is on regardless of condition:\n    assert call_and_check_if_profiled(lambda: f(4)) is True\n    assert call_and_check_if_profiled(lambda: f('frr')) is True\n    \n    # Let's give it a try with `.off_after = True`:\n    f.off_after = True\n    \n    # Setting profiling off again:\n    f.profiling_on = False\n    \n    # And for fun set a different `x`:\n    x = 'wow'\n    \n    # Now profiling is on only when the condition is fulfilled, and doesn't\n    # stay on after:\n    assert call_and_check_if_profiled(lambda: f('ooga')) is False\n    assert call_and_check_if_profiled(lambda: f('booga')) is False\n    assert call_and_check_if_profiled(lambda: f('wow')) is True\n    assert call_and_check_if_profiled(lambda: f('meow')) is False\n    assert call_and_check_if_profiled(lambda: f('kabloom')) is False\n    \n    # In fact, after successful profiling the condition gets reset to `None`:\n    assert f.condition is None\n    \n    # So now if we'll call the function again, even if the (former) condition\n    # is `True`, there will be no profiling:\n    assert call_and_check_if_profiled(lambda: f(9)) is False\n    \n    # So if we want to use a condition again, we have to set it ourselves:\n    f.condition = lambda f, y: isinstance(y, float)\n    \n    # And again (since `.off_after == True`) profiling will turn on for just\n    # one time when the condition evaluates to `True` :\n    assert call_and_check_if_profiled(lambda: f('kabloom')) is False\n    assert call_and_check_if_profiled(lambda: f(3)) is False\n    assert call_and_check_if_profiled(lambda: f(3.1)) is True\n    assert call_and_check_if_profiled(lambda: f(3.1)) is False\n    assert call_and_check_if_profiled(lambda: f(-4.9)) is False\n    \n    \ndef test_perfects():\n    \n    def get_divisors(x):\n        return [i for i in xrange(1, x) if (x % i == 0)]\n    \n    def is_perfect(x):\n        return sum(get_divisors(x)) == x\n    \n    @cute_profile.profile_ready()\n    def get_perfects(top):\n        return [i for i in xrange(1, top) if is_perfect(i)]\n    \n    result = get_perfects(30)\n    get_perfects.profiling_on = True\n    def f():\n        assert get_perfects(30) == result\n    assert call_and_check_if_profiled(f) is True\n    \n    \ndef test_polite_wrapper():\n    '''tododocTest that the `profile_ready` decorator preserves function signature.'''\n    cute_testing.assert_polite_wrapper(\n        cute_profile.profile_ready()(func),\n        func\n    )"}
{"context": "<|file_sep|>misc\\testing\\zip\\make_zip.py\n#!/usr/bin/env python\n# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''\n'''\n\nimport os.path\nimport zipfile\n\n# tododoc: helpful error messages:\nassert __name__ == '__main__'\nassert os.path.realpath('.') == \\\n       os.path.realpath(os.path.join(os.getcwd(), 'misc', 'testing', 'zip'))\n\n# todo: define function for zipping a folder, then use it to make garlicsim,\n# garlicsim_lib and garlicsim_wx in build folder\n"}
{"context": "<|file_sep|>garlicsim\\garlicsim\\general_misc\\cute_inspect\\forked_inspect.py\n\"\"\"Get useful information from live Python objects.\n\nThis module encapsulates the interface provided by the internal special\nattributes (func_*, co_*, im_*, tb_*, etc.) in a friendlier fashion.\nIt also provides some help for examining source code and class layout.\n\nHere are some of the useful functions provided by this module:\n\n    ismodule(), isclass(), ismethod(), isfunction(), isgeneratorfunction(),\n        isgenerator(), istraceback(), isframe(), iscode(), isbuiltin(),\n        isroutine() - check object types\n    getmembers() - get members of an object that satisfy a given condition\n\n    getfile(), getsourcefile(), getsource() - find an object's source code\n    getdoc(), getcomments() - get documentation on an object\n    getmodule() - determine the module that an object came from\n    getclasstree() - arrange classes so as to represent their hierarchy\n\n    getargspec(), getargvalues(), getcallargs() - get info about function arguments\n    formatargspec(), formatargvalues() - format an argument spec\n    getouterframes(), getinnerframes() - get info about frames\n    currentframe() - get the current stack frame\n    stack(), trace() - get info about frames on the stack or in a traceback\n\"\"\"\n\n# This module is in the public domain.  No warranties.\n\n__author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__date__ = '1 Jan 2001'\n\nimport sys\nimport os\nimport types\nimport string\nimport re\nimport dis\nimport imp\nimport tokenize\nimport linecache\nfrom operator import attrgetter\nfrom garlicsim.general_misc.third_party.namedtuple import namedtuple\n\n# These constants are from Include/code.h.\nCO_OPTIMIZED, CO_NEWLOCALS, CO_VARARGS, CO_VARKEYWORDS = 0x1, 0x2, 0x4, 0x8\nCO_NESTED, CO_GENERATOR, CO_NOFREE = 0x10, 0x20, 0x40\n# See Include/object.h\nTPFLAGS_IS_ABSTRACT = 1 << 20\n\n# ----------------------------------------------------------- type-checking\ndef ismodule(object):\n    \"\"\"Return true if the object is a module.\n\n    Module objects provide these attributes:\n        __doc__         documentation string\n        __file__        filename (missing for built-in modules)\"\"\"\n    return isinstance(object, types.ModuleType)\n\ndef isclass(object):\n    \"\"\"Return true if the object is a class.\n\n    Class objects provide these attributes:\n        __doc__         documentation string\n        __module__      name of module in which this class was defined\"\"\"\n    return isinstance(object, (type, types.ClassType))\n\ndef ismethod(object):\n    \"\"\"Return true if the object is an instance method.\n\n    Instance method objects provide these attributes:\n        __doc__         documentation string\n        __name__        name with which this method was defined\n        im_class        class object in which this method belongs\n        im_func         function object containing implementation of method\n        im_self         instance to which this method is bound, or None\"\"\"\n    return isinstance(object, types.MethodType)\n\ndef ismethoddescriptor(object):\n    \"\"\"Return true if the object is a method descriptor.\n\n    But not if ismethod() or isclass() or isfunction() are true.\n\n    This is new in Python 2.2, and, for example, is true of int.__add__.\n    An object passing this test has a __get__ attribute but not a __set__\n    attribute, but beyond that the set of attributes varies.  __name__ is\n    usually sensible, and __doc__ often is.\n\n    Methods implemented via descriptors that also pass one of the other\n    tests return false from the ismethoddescriptor() test, simply because\n    the other tests promise more -- you can, e.g., count on having the\n    im_func attribute (etc) when an object passes ismethod().\"\"\"\n    return (hasattr(object, \"__get__\")\n            and not hasattr(object, \"__set__\") # else it's a data descriptor\n            and not ismethod(object)           # mutual exclusion\n            and not isfunction(object)\n            and not isclass(object))\n\ndef isdatadescriptor(object):\n    \"\"\"Return true if the object is a data descriptor.\n\n    Data descriptors have both a __get__ and a __set__ attribute.  Examples are\n    properties (defined in Python) and getsets and members (defined in C).\n    Typically, data descriptors will also have __name__ and __doc__ attributes\n    (properties, getsets, and members have both of these attributes), but this\n    is not guaranteed.\"\"\"\n    return (hasattr(object, \"__set__\") and hasattr(object, \"__get__\"))\n\nif hasattr(types, 'MemberDescriptorType'):\n    # CPython and equivalent\n    def ismemberdescriptor(object):\n        \"\"\"Return true if the object is a member descriptor.\n\n        Member descriptors are specialized descriptors defined in extension\n        modules.\"\"\"\n        return isinstance(object, types.MemberDescriptorType)\nelse:\n    # Other implementations\n    def ismemberdescriptor(object):\n        \"\"\"Return true if the object is a member descriptor.\n\n        Member descriptors are specialized descriptors defined in extension\n        modules.\"\"\"\n        return False\n\nif hasattr(types, 'GetSetDescriptorType'):\n    # CPython and equivalent\n    def isgetsetdescriptor(object):\n        \"\"\"Return true if the object is a getset descriptor.\n\n        getset descriptors are specialized descriptors defined in extension\n        modules.\"\"\"\n        return isinstance(object, types.GetSetDescriptorType)\nelse:\n    # Other implementations\n    def isgetsetdescriptor(object):\n        \"\"\"Return true if the object is a getset descriptor.\n\n        getset descriptors are specialized descriptors defined in extension\n        modules.\"\"\"\n        return False\n\ndef isfunction(object):\n    \"\"\"Return true if the object is a user-defined function.\n\n    Function objects provide these attributes:\n        __doc__         documentation string\n        __name__        name with which this function was defined\n        func_code       code object containing compiled function bytecode\n        func_defaults   tuple of any default values for arguments\n        func_doc        (same as __doc__)\n        func_globals    global namespace in which this function was defined\n        func_name       (same as __name__)\"\"\"\n    return isinstance(object, types.FunctionType)\n\ndef isgeneratorfunction(object):\n    \"\"\"Return true if the object is a user-defined generator function.\n\n    Generator function objects provides same attributes as functions.\n\n    See help(isfunction) for attributes listing.\"\"\"\n    return bool((isfunction(object) or ismethod(object)) and\n                object.func_code.co_flags & CO_GENERATOR)\n\ndef isgenerator(object):\n    \"\"\"Return true if the object is a generator.\n\n    Generator objects provide these attributes:\n        __iter__        defined to support interation over container\n        close           raises a new GeneratorExit exception inside the\n                        generator to terminate the iteration\n        gi_code         code object\n        gi_frame        frame object or possibly None once the generator has\n                        been exhausted\n        gi_running      set to 1 when generator is executing, 0 otherwise\n        next            return the next item from the container\n        send            resumes the generator and \"sends\" a value that becomes\n                        the result of the current yield-expression\n        throw           used to raise an exception inside the generator\"\"\"\n    return isinstance(object, types.GeneratorType)\n\ndef istraceback(object):\n    \"\"\"Return true if the object is a traceback.\n\n    Traceback objects provide these attributes:\n        tb_frame        frame object at this level\n        tb_lasti        index of last attempted instruction in bytecode\n        tb_lineno       current line number in Python source code\n        tb_next         next inner traceback object (called by this level)\"\"\"\n    return isinstance(object, types.TracebackType)\n\ndef isframe(object):\n    \"\"\"Return true if the object is a frame object.\n\n    Frame objects provide these attributes:\n        f_back          next outer frame object (this frame's caller)\n        f_builtins      built-in namespace seen by this frame\n        f_code          code object being executed in this frame\n        f_exc_traceback traceback if raised in this frame, or None\n        f_exc_type      exception type if raised in this frame, or None\n        f_exc_value     exception value if raised in this frame, or None\n        f_globals       global namespace seen by this frame\n        f_lasti         index of last attempted instruction in bytecode\n        f_lineno        current line number in Python source code\n        f_locals        local namespace seen by this frame\n        f_restricted    0 or 1 if frame is in restricted execution mode\n        f_trace         tracing function for this frame, or None\"\"\"\n    return isinstance(object, types.FrameType)\n\ndef iscode(object):\n    \"\"\"Return true if the object is a code object.\n\n    Code objects provide these attributes:\n        co_argcount     number of arguments (not including * or ** args)\n        co_code         string of raw compiled bytecode\n        co_consts       tuple of constants used in the bytecode\n        co_filename     name of file in which this code object was created\n        co_firstlineno  number of first line in Python source code\n        co_flags        bitmap: 1=optimized | 2=newlocals | 4=*arg | 8=**arg\n        co_lnotab       encoded mapping of line numbers to bytecode indices\n        co_name         name with which this code object was defined\n        co_names        tuple of names of local variables\n        co_nlocals      number of local variables\n        co_stacksize    virtual machine stack space required\n        co_varnames     tuple of names of arguments and local variables\"\"\"\n    return isinstance(object, types.CodeType)\n\ndef isbuiltin(object):\n    \"\"\"Return true if the object is a built-in function or method.\n\n    Built-in functions and methods provide these attributes:\n        __doc__         documentation string\n        __name__        original name of this function or method\n        __self__        instance to which a method is bound, or None\"\"\"\n    return isinstance(object, types.BuiltinFunctionType)\n\ndef isroutine(object):\n    \"\"\"Return true if the object is any kind of function or method.\"\"\"\n    return (isbuiltin(object)\n            or isfunction(object)\n            or ismethod(object)\n            or ismethoddescriptor(object))\n\ndef isabstract(object):\n    \"\"\"Return true if the object is an abstract base class (ABC).\"\"\"\n    return bool(isinstance(object, type) and object.__flags__ & TPFLAGS_IS_ABSTRACT)\n\ndef getmembers(object, predicate=None):\n    \"\"\"Return all members of an object as (name, value) pairs sorted by name.\n    Optionally, only return members that satisfy a given predicate.\"\"\"\n    results = []\n    for key in dir(object):\n        try:\n            value = getattr(object, key)\n        except AttributeError:\n            continue\n        if not predicate or predicate(value):\n            results.append((key, value))\n    results.sort()\n    return results\n\nAttribute = namedtuple('Attribute', 'name kind defining_class object')\n\ndef classify_class_attrs(cls):\n    \"\"\"Return list of attribute-descriptor tuples.\n\n    For each name in dir(cls), the return list contains a 4-tuple\n    with these elements:\n\n        0. The name (a string).\n\n        1. The kind of attribute this is, one of these strings:\n               'class method'    created via classmethod()\n               'static method'   created via staticmethod()\n               'property'        created via property()\n               'method'          any other flavor of method\n               'data'            not a method\n\n        2. The class which defined this attribute (a class).\n\n        3. The object as obtained directly from the defining class's\n           __dict__, not via getattr.  This is especially important for\n           data attributes:  C.data is just a data object, but\n           C.__dict__['data'] may be a data descriptor with additional\n           info, like a __doc__ string.\n    \"\"\"\n\n    mro = getmro(cls)\n    names = dir(cls)\n    result = []\n    for name in names:\n        # Get the object associated with the name.\n        # Getting an obj from the __dict__ sometimes reveals more than\n        # using getattr.  Static and class methods are dramatic examples.\n        if name in cls.__dict__:\n            obj = cls.__dict__[name]\n        else:\n            obj = getattr(cls, name)\n\n        # Figure out where it was defined.\n        homecls = getattr(obj, \"__objclass__\", None)\n        if homecls is None:\n            # search the dicts.\n            for base in mro:\n                if name in base.__dict__:\n                    homecls = base\n                    break\n\n        # Get the object again, in order to get it from the defining\n        # __dict__ instead of via getattr (if possible).\n        if homecls is not None and name in homecls.__dict__:\n            obj = homecls.__dict__[name]\n\n        # Also get the object via getattr.\n        obj_via_getattr = getattr(cls, name)\n\n        # Classify the object.\n        if isinstance(obj, staticmethod):\n            kind = \"static method\"\n        elif isinstance(obj, classmethod):\n            kind = \"class method\"\n        elif isinstance(obj, property):\n            kind = \"property\"\n        elif (ismethod(obj_via_getattr) or\n              ismethoddescriptor(obj_via_getattr)):\n            kind = \"method\"\n        else:\n            kind = \"data\"\n\n        result.append(Attribute(name, kind, homecls, obj))\n\n    return result\n\n# ----------------------------------------------------------- class helpers\ndef _searchbases(cls, accum):\n    # Simulate the \"classic class\" search order.\n    if cls in accum:\n        return\n    accum.append(cls)\n    for base in cls.__bases__:\n        _searchbases(base, accum)\n\ndef getmro(cls):\n    \"Return tuple of base classes (including cls) in method resolution order.\"\n    if hasattr(cls, \"__mro__\"):\n        return cls.__mro__\n    else:\n        result = []\n        _searchbases(cls, result)\n        return tuple(result)\n\n# -------------------------------------------------- source code extraction\ndef indentsize(line):\n    \"\"\"Return the indent size, in spaces, at the start of a line of text.\"\"\"\n    expline = string.expandtabs(line)\n    return len(expline) - len(string.lstrip(expline))\n\ndef getdoc(object):\n    \"\"\"Get the documentation string for an object.\n\n    All tabs are expanded to spaces.  To clean up docstrings that are\n    indented to line up with blocks of code, any whitespace than can be\n    uniformly removed from the second line onwards is removed.\"\"\"\n    try:\n        doc = object.__doc__\n    except AttributeError:\n        return None\n    if not isinstance(doc, types.StringTypes):\n        return None\n    return cleandoc(doc)\n\ndef cleandoc(doc):\n    \"\"\"Clean up indentation from docstrings.\n\n    Any whitespace that can be uniformly removed from the second line\n    onwards is removed.\"\"\"\n    try:\n        lines = string.split(string.expandtabs(doc), '\\n')\n    except UnicodeError:\n        return None\n    else:\n        # Find minimum indentation of any non-blank lines after first line.\n        margin = sys.maxint\n        for line in lines[1:]:\n            content = len(string.lstrip(line))\n            if content:\n                indent = len(line) - content\n                margin = min(margin, indent)\n        # Remove indentation.\n        if lines:\n            lines[0] = lines[0].lstrip()\n        if margin < sys.maxint:\n            for i in range(1, len(lines)): lines[i] = lines[i][margin:]\n        # Remove any trailing or leading blank lines.\n        while lines and not lines[-1]:\n            lines.pop()\n        while lines and not lines[0]:\n            lines.pop(0)\n        return string.join(lines, '\\n')\n\ndef getfile(object):\n    \"\"\"Work out which source or compiled file an object was defined in.\"\"\"\n    if ismodule(object):\n        if hasattr(object, '__file__'):\n            return object.__file__\n        raise TypeError('{!r} is a built-in module'.format(object))\n    if isclass(object):\n        object = sys.modules.get(object.__module__)\n        if hasattr(object, '__file__'):\n            return object.__file__\n        raise TypeError('{!r} is a built-in class'.format(object))\n    if ismethod(object):\n        object = object.im_func\n    if isfunction(object):\n        object = object.func_code\n    if istraceback(object):\n        object = object.tb_frame\n    if isframe(object):\n        object = object.f_code\n    if iscode(object):\n        return object.co_filename\n    raise TypeError('{!r} is not a module, class, method, '\n                    'function, traceback, frame, or code object'.format(object))\n\nModuleInfo = namedtuple('ModuleInfo', 'name suffix mode module_type')\n\ndef getmoduleinfo(path):\n    \"\"\"Get the module name, suffix, mode, and module type for a given file.\"\"\"\n    filename = os.path.basename(path)\n    suffixes = map(lambda info:\n                   (-len(info[0]), info[0], info[1], info[2]),\n                    imp.get_suffixes())\n    suffixes.sort() # try longest suffixes first, in case they overlap\n    for neglen, suffix, mode, mtype in suffixes:\n        if filename[neglen:] == suffix:\n            return ModuleInfo(filename[:neglen], suffix, mode, mtype)\n\ndef getmodulename(path):\n    \"\"\"Return the module name for a given file, or None.\"\"\"\n    info = getmoduleinfo(path)\n    if info: return info[0]\n\ndef getsourcefile(object):\n    \"\"\"Return the filename that can be used to locate an object's source.\n    Return None if no way can be identified to get the source.\n    \"\"\"\n    filename = getfile(object)\n    if string.lower(filename[-4:]) in ('.pyc', '.pyo'):\n        filename = filename[:-4] + '.py'\n    for suffix, mode, kind in imp.get_suffixes():\n        if 'b' in mode and string.lower(filename[-len(suffix):]) == suffix:\n            # Looks like a binary file.  We want to only return a text file.\n            return None\n    if os.path.exists(filename):\n        return filename\n    # only return a non-existent filename if the module has a PEP 302 loader\n    if hasattr(getmodule(object, filename), '__loader__'):\n        return filename\n    # or it is in the linecache\n    if filename in linecache.cache:\n        return filename\n\ndef getabsfile(object, _filename=None):\n    \"\"\"Return an absolute path to the source or compiled file for an object.\n\n    The idea is for each object to have a unique origin, so this routine\n    normalizes the result as much as possible.\"\"\"\n    if _filename is None:\n        _filename = getsourcefile(object) or getfile(object)\n    return os.path.normcase(os.path.abspath(_filename))\n\nmodulesbyfile = {}\n_filesbymodname = {}\n\ndef getmodule(object, _filename=None):\n    \"\"\"Return the module an object was defined in, or None if not found.\"\"\"\n    if ismodule(object):\n        return object\n    if hasattr(object, '__module__'):\n        return sys.modules.get(object.__module__)\n    # Try the filename to modulename cache\n    if _filename is not None and _filename in modulesbyfile:\n        return sys.modules.get(modulesbyfile[_filename])\n    # Try the cache again with the absolute file name\n    try:\n        file = getabsfile(object, _filename)\n    except TypeError:\n        return None\n    if file in modulesbyfile:\n        return sys.modules.get(modulesbyfile[file])\n    # Update the filename to module name cache and check yet again\n    # Copy sys.modules in order to cope with changes while iterating\n    for modname, module in sys.modules.items():\n        if ismodule(module) and hasattr(module, '__file__'):\n            f = module.__file__\n            if f == _filesbymodname.get(modname, None):\n                # Have already mapped this module, so skip it\n                continue\n            _filesbymodname[modname] = f\n            f = getabsfile(module)\n            # Always map to the name the module knows itself by\n            modulesbyfile[f] = modulesbyfile[\n                os.path.realpath(f)] = module.__name__\n    if file in modulesbyfile:\n        return sys.modules.get(modulesbyfile[file])\n    # Check the main module\n    main = sys.modules['__main__']\n    if not hasattr(object, '__name__'):\n        return None\n    if hasattr(main, object.__name__):\n        mainobject = getattr(main, object.__name__)\n        if mainobject is object:\n            return main\n    # Check builtins\n    builtin = sys.modules['__builtin__']\n    if hasattr(builtin, object.__name__):\n        builtinobject = getattr(builtin, object.__name__)\n        if builtinobject is object:\n            return builtin\n\ndef findsource(object):\n    \"\"\"Return the entire source file and starting line number for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of all the lines\n    in the file and the line number indexes a line in that list.  An IOError\n    is raised if the source code cannot be retrieved.\"\"\"\n    file = getsourcefile(object)\n    if not file:\n        raise IOError('source code not available')\n    module = getmodule(object, file)\n    if module:\n        lines = linecache.getlines(file, module.__dict__)\n    else:\n        lines = linecache.getlines(file)\n    if not lines:\n        raise IOError('could not get source code')\n\n    if ismodule(object):\n        return lines, 0\n\n    if isclass(object):\n        name = object.__name__\n        pat = re.compile(r'^(\\s*)class\\s*' + name + r'\\b')\n        # make some effort to find the best matching class definition:\n        # use the one with the least indentation, which is the one\n        # that's most probably not inside a function definition.\n        candidates = []\n        for i in range(len(lines)):\n            match = pat.match(lines[i])\n            if match:\n                # if it's at toplevel, it's already the best one\n                if lines[i][0] == 'c':\n                    return lines, i\n                # else add whitespace to candidate list\n                candidates.append((match.group(1), i))\n        if candidates:\n            # this will sort by whitespace, and by line number,\n            # less whitespace first\n            candidates.sort()\n            return lines, candidates[0][1]\n        else:\n            raise IOError('could not find class definition')\n\n    if ismethod(object):\n        object = object.im_func\n    if isfunction(object):\n        object = object.func_code\n    if istraceback(object):\n        object = object.tb_frame\n    if isframe(object):\n        object = object.f_code\n    if iscode(object):\n        if not hasattr(object, 'co_firstlineno'):\n            raise IOError('could not find function definition')\n        lnum = object.co_firstlineno - 1\n        pat = re.compile(r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)')\n        while lnum > 0:\n            if pat.match(lines[lnum]): break\n            lnum = lnum - 1\n        return lines, lnum\n    raise IOError('could not find code object')\n\ndef getcomments(object):\n    \"\"\"Get lines of comments immediately preceding an object's source code.\n\n    Returns None when source can't be found.\n    \"\"\"\n    try:\n        lines, lnum = findsource(object)\n    except (IOError, TypeError):\n        return None\n\n    if ismodule(object):\n        # Look for a comment block at the top of the file.\n        start = 0\n        if lines and lines[0][:2] == '#!': start = 1\n        while start < len(lines) and string.strip(lines[start]) in ('', '#'):\n            start = start + 1\n        if start < len(lines) and lines[start][:1] == '#':\n            comments = []\n            end = start\n            while end < len(lines) and lines[end][:1] == '#':\n                comments.append(string.expandtabs(lines[end]))\n                end = end + 1\n            return string.join(comments, '')\n\n    # Look for a preceding block of comments at the same indentation.\n    elif lnum > 0:\n        indent = indentsize(lines[lnum])\n        end = lnum - 1\n        if end >= 0 and string.lstrip(lines[end])[:1] == '#' and \\\n            indentsize(lines[end]) == indent:\n            comments = [string.lstrip(string.expandtabs(lines[end]))]\n            if end > 0:\n                end = end - 1\n                comment = string.lstrip(string.expandtabs(lines[end]))\n                while comment[:1] == '#' and indentsize(lines[end]) == indent:\n                    comments[:0] = [comment]\n                    end = end - 1\n                    if end < 0: break\n                    comment = string.lstrip(string.expandtabs(lines[end]))\n            while comments and string.strip(comments[0]) == '#':\n                comments[:1] = []\n            while comments and string.strip(comments[-1]) == '#':\n                comments[-1:] = []\n            return string.join(comments, '')\n\nclass EndOfBlock(Exception): pass\n\nclass BlockFinder:\n    \"\"\"Provide a tokeneater() method to detect the end of a code block.\"\"\"\n    def __init__(self):\n        self.indent = 0\n        self.islambda = False\n        self.started = False\n        self.passline = False\n        self.last = 1\n\n    def tokeneater(self, type, token, srow_scol, erow_ecol, line):\n        srow, scol = srow_scol\n        erow, ecol = erow_ecol\n        if not self.started:\n            # look for the first \"def\", \"class\" or \"lambda\"\n            if token in (\"def\", \"class\", \"lambda\"):\n                if token == \"lambda\":\n                    self.islambda = True\n                self.started = True\n            self.passline = True    # skip to the end of the line\n        elif type == tokenize.NEWLINE:\n            self.passline = False   # stop skipping when a NEWLINE is seen\n            self.last = srow\n            if self.islambda:       # lambdas always end at the first NEWLINE\n                raise EndOfBlock\n        elif self.passline:\n            pass\n        elif type == tokenize.INDENT:\n            self.indent = self.indent + 1\n            self.passline = True\n        elif type == tokenize.DEDENT:\n            self.indent = self.indent - 1\n            # the end of matching indent/dedent pairs end a block\n            # (note that this only works for \"def\"/\"class\" blocks,\n            #  not e.g. for \"if: else:\" or \"try: finally:\" blocks)\n            if self.indent <= 0:\n                raise EndOfBlock\n        elif self.indent == 0 and type not in (tokenize.COMMENT, tokenize.NL):\n            # any other token on the same indentation level end the previous\n            # block as well, except the pseudo-tokens COMMENT and NL.\n            raise EndOfBlock\n\ndef getblock(lines):\n    \"\"\"Extract the block of code at the top of the given list of lines.\"\"\"\n    blockfinder = BlockFinder()\n    try:\n        tokenize.tokenize(iter(lines).next, blockfinder.tokeneater)\n    except (EndOfBlock, IndentationError):\n        pass\n    return lines[:blockfinder.last]\n\ndef getsourcelines(object):\n    \"\"\"Return a list of source lines and starting line number for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of the lines\n    corresponding to the object and the line number indicates where in the\n    original source file the first line of code was found.  An IOError is\n    raised if the source code cannot be retrieved.\"\"\"\n    lines, lnum = findsource(object)\n\n    if ismodule(object): return lines, 0\n    else: return getblock(lines[lnum:]), lnum + 1\n\ndef getsource(object):\n    \"\"\"Return the text of the source code for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a single string.  An\n    IOError is raised if the source code cannot be retrieved.\"\"\"\n    lines, lnum = getsourcelines(object)\n    return string.join(lines, '')\n\n# --------------------------------------------------- class tree extraction\ndef walktree(classes, children, parent):\n    \"\"\"Recursive helper function for getclasstree().\"\"\"\n    results = []\n    classes.sort(key=attrgetter('__module__', '__name__'))\n    for c in classes:\n        results.append((c, c.__bases__))\n        if c in children:\n            results.append(walktree(children[c], children, c))\n    return results\n\ndef getclasstree(classes, unique=0):\n    \"\"\"Arrange the given list of classes into a hierarchy of nested lists.\n\n    Where a nested list appears, it contains classes derived from the class\n    whose entry immediately precedes the list.  Each entry is a 2-tuple\n    containing a class and a tuple of its base classes.  If the 'unique'\n    argument is true, exactly one entry appears in the returned structure\n    for each class in the given list.  Otherwise, classes using multiple\n    inheritance and their descendants will appear multiple times.\"\"\"\n    children = {}\n    roots = []\n    for c in classes:\n        if c.__bases__:\n            for parent in c.__bases__:\n                if not parent in children:\n                    children[parent] = []\n                children[parent].append(c)\n                if unique and parent in classes: break\n        elif c not in roots:\n            roots.append(c)\n    for parent in children:\n        if parent not in classes:\n            roots.append(parent)\n    return walktree(roots, children, None)\n\n# ------------------------------------------------ argument list extraction\nArguments = namedtuple('Arguments', 'args varargs keywords')\n\ndef getargs(co):\n    \"\"\"Get information about the arguments accepted by a code object.\n\n    Three things are returned: (args, varargs, varkw), where 'args' is\n    a list of argument names (possibly containing nested lists), and\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\"\"\"\n\n    if not iscode(co):\n        raise TypeError('{!r} is not a code object'.format(co))\n\n    nargs = co.co_argcount\n    names = co.co_varnames\n    args = list(names[:nargs])\n    step = 0\n\n    # The following acrobatics are for anonymous (tuple) arguments.\n    for i in range(nargs):\n        if args[i][:1] in ('', '.'):\n            stack, remain, count = [], [], []\n            while step < len(co.co_code):\n                op = ord(co.co_code[step])\n                step = step + 1\n                if op >= dis.HAVE_ARGUMENT:\n                    opname = dis.opname[op]\n                    value = ord(co.co_code[step]) + ord(co.co_code[step+1])*256\n                    step = step + 2\n                    if opname in ('UNPACK_TUPLE', 'UNPACK_SEQUENCE'):\n                        remain.append(value)\n                        count.append(value)\n                    elif opname == 'STORE_FAST':\n                        stack.append(names[value])\n\n                        # Special case for sublists of length 1: def foo((bar))\n                        # doesn't generate the UNPACK_TUPLE bytecode, so if\n                        # `remain` is empty here, we have such a sublist.\n                        if not remain:\n                            stack[0] = [stack[0]]\n                            break\n                        else:\n                            remain[-1] = remain[-1] - 1\n                            while remain[-1] == 0:\n                                remain.pop()\n                                size = count.pop()\n                                stack[-size:] = [stack[-size:]]\n                                if not remain: break\n                                remain[-1] = remain[-1] - 1\n                            if not remain: break\n            args[i] = stack[0]\n\n    varargs = None\n    if co.co_flags & CO_VARARGS:\n        varargs = co.co_varnames[nargs]\n        nargs = nargs + 1\n    varkw = None\n    if co.co_flags & CO_VARKEYWORDS:\n        varkw = co.co_varnames[nargs]\n    return Arguments(args, varargs, varkw)\n\nArgSpec = namedtuple('ArgSpec', 'args varargs keywords defaults')\n\ndef getargspec(func):\n    \"\"\"Get the names and default values of a function's arguments.\n\n    A tuple of four things is returned: (args, varargs, varkw, defaults).\n    'args' is a list of the argument names (it may contain nested lists).\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\n    'defaults' is an n-tuple of the default values of the last n arguments.\n    \"\"\"\n\n    if ismethod(func):\n        func = func.im_func\n    if not isfunction(func):\n        raise TypeError('{!r} is not a Python function'.format(func))\n    args, varargs, varkw = getargs(func.func_code)\n    return ArgSpec(args, varargs, varkw, func.func_defaults)\n\nArgInfo = namedtuple('ArgInfo', 'args varargs keywords locals')\n\ndef getargvalues(frame):\n    \"\"\"Get information about arguments passed into a particular frame.\n\n    A tuple of four things is returned: (args, varargs, varkw, locals).\n    'args' is a list of the argument names (it may contain nested lists).\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\n    'locals' is the locals dictionary of the given frame.\"\"\"\n    args, varargs, varkw = getargs(frame.f_code)\n    return ArgInfo(args, varargs, varkw, frame.f_locals)\n\ndef joinseq(seq):\n    if len(seq) == 1:\n        return '(' + seq[0] + ',)'\n    else:\n        return '(' + string.join(seq, ', ') + ')'\n\ndef strseq(object, convert, join=joinseq):\n    \"\"\"Recursively walk a sequence, stringifying each element.\"\"\"\n    if type(object) in (list, tuple):\n        return join(map(lambda o, c=convert, j=join: strseq(o, c, j), object))\n    else:\n        return convert(object)\n\ndef formatargspec(args, varargs=None, varkw=None, defaults=None,\n                  formatarg=str,\n                  formatvarargs=lambda name: '*' + name,\n                  formatvarkw=lambda name: '**' + name,\n                  formatvalue=lambda value: '=' + repr(value),\n                  join=joinseq):\n    \"\"\"Format an argument spec from the 4 values returned by getargspec.\n\n    The first four arguments are (args, varargs, varkw, defaults).  The\n    other four arguments are the corresponding optional formatting functions\n    that are called to turn names and values into strings.  The ninth\n    argument is an optional function to format the sequence of arguments.\"\"\"\n    specs = []\n    if defaults:\n        firstdefault = len(args) - len(defaults)\n    for i, arg in enumerate(args):\n        spec = strseq(arg, formatarg, join)\n        if defaults and i >= firstdefault:\n            spec = spec + formatvalue(defaults[i - firstdefault])\n        specs.append(spec)\n    if varargs is not None:\n        specs.append(formatvarargs(varargs))\n    if varkw is not None:\n        specs.append(formatvarkw(varkw))\n    return '(' + string.join(specs, ', ') + ')'\n\ndef formatargvalues(args, varargs, varkw, locals,\n                    formatarg=str,\n                    formatvarargs=lambda name: '*' + name,\n                    formatvarkw=lambda name: '**' + name,\n                    formatvalue=lambda value: '=' + repr(value),\n                    join=joinseq):\n    \"\"\"Format an argument spec from the 4 values returned by getargvalues.\n\n    The first four arguments are (args, varargs, varkw, locals).  The\n    next four arguments are the corresponding optional formatting functions\n    that are called to turn names and values into strings.  The ninth\n    argument is an optional function to format the sequence of arguments.\"\"\"\n    def convert(name, locals=locals,\n                formatarg=formatarg, formatvalue=formatvalue):\n        return formatarg(name) + formatvalue(locals[name])\n    specs = []\n    for i in range(len(args)):\n        specs.append(strseq(args[i], convert, join))\n    if varargs:\n        specs.append(formatvarargs(varargs) + formatvalue(locals[varargs]))\n    if varkw:\n        specs.append(formatvarkw(varkw) + formatvalue(locals[varkw]))\n    return '(' + string.join(specs, ', ') + ')'\n\ndef getcallargs(func, *positional, **named):\n    \"\"\"Get the mapping of arguments to values.\n\n    A dict is returned, with keys the function argument names (including the\n    names of the * and ** arguments, if any), and values the respective bound\n    values from 'positional' and 'named'.\"\"\"\n    args, varargs, varkw, defaults = getargspec(func)\n    f_name = func.__name__\n    arg2value = {}\n\n    # The following closures are basically because of tuple parameter unpacking.\n    assigned_tuple_params = []\n    def assign(arg, value):\n        if isinstance(arg, str):\n            arg2value[arg] = value\n        else:\n            assigned_tuple_params.append(arg)\n            value = iter(value)\n            for i, subarg in enumerate(arg):\n                try:\n                    subvalue = next(value)\n                except StopIteration:\n                    raise ValueError('need more than %d %s to unpack' %\n                                     (i, 'values' if i > 1 else 'value'))\n                assign(subarg,subvalue)\n            try:\n                next(value)\n            except StopIteration:\n                pass\n            else:\n                raise ValueError('too many values to unpack')\n    def is_assigned(arg):\n        if isinstance(arg,str):\n            return arg in arg2value\n        return arg in assigned_tuple_params\n    if ismethod(func) and func.im_self is not None:\n        # implicit 'self' (or 'cls' for classmethods) argument\n        positional = (func.im_self,) + positional\n    num_pos = len(positional)\n    num_total = num_pos + len(named)\n    num_args = len(args)\n    num_defaults = len(defaults) if defaults else 0\n    for arg, value in zip(args, positional):\n        assign(arg, value)\n    if varargs:\n        if num_pos > num_args:\n            assign(varargs, positional[-(num_pos-num_args):])\n        else:\n            assign(varargs, ())\n    elif 0 < num_args < num_pos:\n        raise TypeError('%s() takes %s %d %s (%d given)' % (\n            f_name, 'at most' if defaults else 'exactly', num_args,\n            'arguments' if num_args > 1 else 'argument', num_total))\n    elif num_args == 0 and num_total:\n        raise TypeError('%s() takes no arguments (%d given)' %\n                        (f_name, num_total))\n    for arg in args:\n        if isinstance(arg, str) and arg in named:\n            if is_assigned(arg):\n                raise TypeError(\"%s() got multiple values for keyword \"\n                                \"argument '%s'\" % (f_name, arg))\n            else:\n                assign(arg, named.pop(arg))\n    if defaults:    # fill in any missing values with the defaults\n        for arg, value in zip(args[-num_defaults:], defaults):\n            if not is_assigned(arg):\n                assign(arg, value)\n    if varkw:\n        assign(varkw, named)\n    elif named:\n        unexpected = next(iter(named))\n        if isinstance(unexpected, unicode):\n            unexpected = unexpected.encode(sys.getdefaultencoding(), 'replace')\n        raise TypeError(\"%s() got an unexpected keyword argument '%s'\" %\n                        (f_name, unexpected))\n    unassigned = num_args - len([arg for arg in args if is_assigned(arg)])\n    if unassigned:\n        num_required = num_args - num_defaults\n        raise TypeError('%s() takes %s %d %s (%d given)' % (\n            f_name, 'at least' if defaults else 'exactly', num_required,\n            'arguments' if num_required > 1 else 'argument', num_total))\n    return arg2value\n\n# -------------------------------------------------- stack frame extraction\n\nTraceback = namedtuple('Traceback', 'filename lineno function code_context index')\n\ndef getframeinfo(frame, context=1):\n    \"\"\"Get information about a frame or traceback object.\n\n    A tuple of five things is returned: the filename, the line number of\n    the current line, the function name, a list of lines of context from\n    the source code, and the index of the current line within that list.\n    The optional second argument specifies the number of lines of context\n    to return, which are centered around the current line.\"\"\"\n    if istraceback(frame):\n        lineno = frame.tb_lineno\n        frame = frame.tb_frame\n    else:\n        lineno = frame.f_lineno\n    if not isframe(frame):\n        raise TypeError('{!r} is not a frame or traceback object'.format(frame))\n\n    filename = getsourcefile(frame) or getfile(frame)\n    if context > 0:\n        start = lineno - 1 - context//2\n        try:\n            lines, lnum = findsource(frame)\n        except IOError:\n            lines = index = None\n        else:\n            start = max(start, 1)\n            start = max(0, min(start, len(lines) - context))\n            lines = lines[start:start+context]\n            index = lineno - 1 - start\n    else:\n        lines = index = None\n\n    return Traceback(filename, lineno, frame.f_code.co_name, lines, index)\n\ndef getlineno(frame):\n    \"\"\"Get the line number from a frame object, allowing for optimization.\"\"\"\n    # FrameType.f_lineno is now a descriptor that grovels co_lnotab\n    return frame.f_lineno\n\ndef getouterframes(frame, context=1):\n    \"\"\"Get a list of records for a frame and all higher (calling) frames.\n\n    Each record contains a frame object, filename, line number, function\n    name, a list of lines of context, and index within the context.\"\"\"\n    framelist = []\n    while frame:\n        framelist.append((frame,) + getframeinfo(frame, context))\n        frame = frame.f_back\n    return framelist\n\ndef getinnerframes(tb, context=1):\n    \"\"\"Get a list of records for a traceback's frame and all lower frames.\n\n    Each record contains a frame object, filename, line number, function\n    name, a list of lines of context, and index within the context.\"\"\"\n    framelist = []\n    while tb:\n        framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n        tb = tb.tb_next\n    return framelist\n\nif hasattr(sys, '_getframe'):\n    currentframe = sys._getframe\nelse:\n    currentframe = lambda _=None: None\n\ndef stack(context=1):\n    \"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\n    return getouterframes(sys._getframe(1), context)\n\ndef trace(context=1):\n    \"\"\"Return a list of records for the stack below the current exception.\"\"\"\n    return getinnerframes(sys.exc_info()[2], context)\n"}
{"context": "<|file_sep|>garlicsim\\test_garlicsim\\__init__.py\n# Copyright 2009-2011 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''Testing package for `garlicsim`.'''\n\nfrom .shared import verify_sample_simpack_settings\n\ndef __bootstrap():\n    import os\n    import sys\n    from garlicsim.general_misc import import_tools    \n    if not import_tools.exists('garlicsim_lib'):\n        garlicsim_lib_candidate_path = os.path.realpath(\n            os.path.join(\n                os.path.split(__file__)[0],\n                '..',\n                '..',\n                'garlicsim_lib'\n            )\n        )\n        sys.path.append(garlicsim_lib_candidate_path)\n    if not import_tools.exists('garlicsim_wx'):\n        garlicsim_wx_candidate_path = os.path.realpath(\n            os.path.join(\n                os.path.split(__file__)[0],\n                '..',\n                '..',\n                'garlicsim_wx'\n            )\n        )\n        sys.path.append(garlicsim_wx_candidate_path)\n        \n    \n__bootstrap()"}
{"context": "<|file_sep|>garlicsim_wx\\garlicsim_wx\\application_window\\application_window.py\n# Copyright 2009-2010 Ram Rachum. No part of this program may be used, copied or\n# distributed without explicit written permission from Ram Rachum.\n\n'''\nThis module defines the ApplicationWindow class.\n\nSee its documentation for more information.\n'''\n\nfrom __future__ import with_statement\n\nimport os\nimport sys\nimport random\nimport cPickle\n\nimport wx\nimport wx.lib.agw.aui\nimport pkg_resources\n\nimport garlicsim_wx.general_misc.notebookctrl\nimport garlicsim_wx.general_misc.thread_timer as thread_timer\n\nimport garlicsim\nimport garlicsim_wx.gui_project\nimport garlicsim_wx.widgets\n\nfrom . import images as __images_package\nimages_package = __images_package.__name__\n\n\nclass ApplicationWindow(wx.Frame):\n    '''\n    The main window of garlicsim_wx.\n    \n    This window allows the user to create and manipulate gui projects.\n    '''\n    def __init__(self, *args, **keywords):\n        \n        wx.Frame.__init__(self, *args, **keywords)\n        self.SetDoubleBuffered(True)\n        \n        \n        self.aui_manager = wx.lib.agw.aui.AuiManager()\n        \n        self.aui_manager.SetManagedWindow(self)\n\n        # create several text controls\n        text1 = wx.TextCtrl(self, -1, \"Pane 1 - sample text\",\n                            wx.DefaultPosition, wx.Size(200,150),\n                            wx.NO_BORDER | wx.TE_MULTILINE)\n                                           \n        text2 = wx.TextCtrl(self, -1, \"Pane 2 - sample text\",\n                            wx.DefaultPosition, wx.Size(200,150),\n                            wx.NO_BORDER | wx.TE_MULTILINE)\n                                           \n        text3 = wx.TextCtrl(self, -1, \"Main content window\",\n                            wx.DefaultPosition, wx.Size(200,150),\n                            wx.NO_BORDER | wx.TE_MULTILINE)\n        \n        # add the panes to the manager\n        self.aui_manager.AddPane(text1, wx.lib.agw.aui.AuiPaneInfo().Left().Caption(\"Pane Number One\"))\n        self.aui_manager.AddPane(text2, wx.lib.agw.aui.AuiPaneInfo().Bottom().Caption(\"Pane Number Two\"))\n        self.aui_manager.AddPane(text3, wx.lib.agw.aui.AuiPaneInfo().CenterPane())\n                              \n        self.aui_manager.Update()\n\n                \n\n        self.gui_project = None\n\n        ######################################\n        \n        filemenu = wx.Menu()\n        new_menu_button = filemenu.Append(-1 ,\"&New\", \" New\")\n        open_menu_button = filemenu.Append(-1 ,\"&Open\", \" Open\")\n        save_menu_button = filemenu.Append(-1 ,\"&Save\", \" Save\")\n        exit_menu_button = filemenu.Append(-1 ,\"E&xit\", \" Close the program\")\n        self.Bind(wx.EVT_MENU, self.on_new, new_menu_button)\n        self.Bind(wx.EVT_MENU, self.on_open, open_menu_button)        \n        self.Bind(wx.EVT_MENU, self.on_save, save_menu_button)        \n        self.Bind(wx.EVT_MENU, self.exit, exit_menu_button)        \n        menubar = wx.MenuBar()\n        menubar.Append(filemenu, \"&File\")\n        #menubar.Append(stuffmenu,\"&Stuff\")\n        #menubar.Append(nodemenu,\"&Node\")\n        self.SetMenuBar(menubar)\n        self.CreateStatusBar()\n        \n        ######################################\n        \n        toolbar = self.CreateToolBar()\n        image_file_name = {\n            'new': 'new.png',\n            'done': 'check.png',\n        }\n        images = {}\n        for key in image_file_name:\n            file_name = pkg_resources.resource_filename(images_package,\n                                                        image_file_name[key])\n            images[key] = wx.Bitmap(file_name, wx.BITMAP_TYPE_ANY)\n            \n        new_tool = toolbar.AddSimpleTool(\n            -1,\n            images['new'],\n            \"New\",\n            \" Create a new file\"\n        )\n        toolbar.AddSeparator()\n        done_tool = toolbar.AddSimpleTool(\n            -1,\n            images['done'],\n            \"Done editing\",\n            \" Done editing\"\n        )\n        toolbar.Realize()\n\n        self.Bind(wx.EVT_TOOL, self.on_new, new_tool)\n        self.Bind(wx.EVT_TOOL, self.done_editing, done_tool)\n        \n        ######################################\n        \n        self.background_timer = thread_timer.ThreadTimer(self)\n        self.background_timer.start(150)\n        self.Bind(thread_timer.EVT_THREAD_TIMER, self.sync_crunchers)\n\n        ######################################\n        \n        self.Show()\n\n        \n    def on_open(self, event=None):\n        '''Raise a dialog for opening a gui project from file.'''\n        wcd = 'Text files (*.txt)|*.txt|All files (*)|*|'\n        cur_dir = os.getcwd()\n        tickled_gui_project = None\n        try:\n            open_dlg = wx.FileDialog(self, message='Choose a file',\n                                     defaultDir=cur_dir, defaultFile='',\n                                     wildcard=wcd, style=wx.OPEN | wx.CHANGE_DIR)\n            if open_dlg.ShowModal() == wx.ID_OK:\n                path = open_dlg.GetPath()\n                \n                try:\n                    with file(path, 'r') as my_file:\n                        tickled_gui_project = cPickle.load(my_file)\n                        \n                except IOError, error:\n                    dlg = wx.MessageDialog(self,\n                                           'Error opening file\\n' + str(error))\n                    dlg.ShowModal()\n                        \n                except UnicodeDecodeError, error:\n                    dlg = wx.MessageDialog(self,\n                                           'Error opening file\\n' + str(error))\n                    dlg.ShowModal()\n                    \n                \n                    open_dlg.Destroy()\n        finally:\n            fuck_the_path()\n            \n        if tickled_gui_project:\n            my_gui_project = garlicsim_wx.gui_project.load_tickled_gui_project\\\n                (tickled_gui_project, self.notebook)\n        self.add_gui_project(my_gui_project)\n    \n    def on_save(self, event=None):\n        '''Raise a dialog for saving a gui project to file.'''\n        \n        my_gui_project = self.gui_projects[0] # Change this to get the active\n        tickled = my_gui_project.tickle()\n        \n        \n        wcd='Text files (*.txt)|*.txt|All files (*)|*|'\n        cur_dir = os.getcwd()\n        try:\n            save_dlg = wx.FileDialog(self, message='Save file as...',\n                                     defaultDir=cur_dir, defaultFile='',\n                                     wildcard=wcd,\n                                     style=wx.SAVE | wx.OVERWRITE_PROMPT)\n            if save_dlg.ShowModal() == wx.ID_OK:\n                path = save_dlg.GetPath()\n    \n                try:\n                    with file(path, 'w') as my_file:\n                        cPickle.dump(tickled, my_file)\n    \n                except IOError, error:\n                    dlg = wx.MessageDialog(self,\n                                           'Error saving file\\n' + str(error))\n                    dlg.ShowModal()\n            \n        finally:\n            fuck_the_path()\n            \n        save_dlg.Destroy()\n    \n    '''\n    def delete_gui_project(self,gui_project):\n        I did this wrong.\n        self.gui_projects.remove(gui_project)\n        self.notebook.AddPage(gui_project.main_window,\"zort!\")\n        self.notebook.DeletePage(0)\n        del gui_project\n    '''\n\n    def exit(self, e=None):\n        '''Close the application window.'''\n        self.aui_manager.UnInit()\n        self.Destroy()        \n        event.Skip()        \n        self.background_timer.stop()\n        self.Close()\n\n    def done_editing(self, e=None):\n        '''Finalize editing of the active node in the active gui project.'''\n        self.gui_project.done_editing()\n\n    def on_new(self, e):\n        '''Create a new gui project.'''        \n        if self.gui_project is not None:\n            raise NotImplementedError\n        \n        dialog = garlicsim_wx.widgets.misc.SimpackSelectionDialog(self, -1)\n        if dialog.ShowModal() == wx.ID_OK:\n            simpack = dialog.get_simpack_selection()\n        else:\n            dialog.Destroy()\n            return\n        dialog.Destroy()\n\n        self.gui_project = garlicsim_wx.gui_project.GuiProject(simpack, self)\n\n    def sync_crunchers(self, e=None):\n        '''\n        Take work from the crunchers, and give them new instructions if needed.\n                \n        (This is a wrapper that calls the sync_crunchers method of all the\n        gui projects.)\n        \n        Talks with all the crunchers, takes work from them for implementing\n        into the tree, retiring crunchers or recruiting new crunchers as\n        necessary.\n        \n        Returns the total amount of nodes that were added to each gui project's\n        tree.\n        '''\n        \n        return self.gui_project.sync_crunchers() if self.gui_project else 0\n\n"}
{"context": "<|file_sep|>garlicsim\\garlicsim\\general_misc\\misc_tools.py\n# Copyright 2009-2010 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n'''This module defines miscellaneous tools.'''\n\nimport math\n\n\ndef frange(start, finish=None, step=1.):\n    '''\n    Make a list containing an arithmetic progression of numbers.\n\n    This is an extension of the builtin `range`; It allows using floating point\n    numbers.\n    '''\n    if finish is None:\n        finish, start = start, 0.\n    else:\n        start = float(start)\n\n    count = int(math.ceil(finish - start)/step)\n    return (start + n*step for n in range(count))\n\n\ndef shorten_class_address(module_name, class_name):\n    '''\n    Shorten the address of a class.\n    \n    This is mostly used in `__repr__` methods of various classes to shorten the\n    text and make the final output more conscise. For example, if you have a\n    class `garlicsim.asynchronous_crunching.project.Project`, but which is also\n    available as `garlicsim.Project`, this function will return\n    'garlicsim.Project'.    \n    '''\n    get_module = lambda module_name: __import__(module_name, fromlist=[''])\n    original_module = get_module(module_name)\n    original_class = getattr(original_module, class_name)\n    \n    current_module_name = module_name\n    \n    last_successful_module_name = current_module_name\n    \n    while True:\n        # Removing the last submodule from the module name:\n        current_module_name = '.'.join(current_module_name.split('.')[:-1]) \n        \n        if not current_module_name:\n            # We've reached the top module and it's successful, can break now.\n            break\n        \n        current_module = get_module(current_module_name)\n        \n        candidate_class = getattr(current_module, class_name, None)\n        \n        if candidate_class is original_class:\n            last_successful_module_name = current_module_name\n        else:\n            break\n        \n    return '.'.join((last_successful_module_name, class_name))\n\n\nclass LazilyEvaluatedConstantProperty(object):\n    '''\n    A property that is calculated (a) lazily and (b) only once for an object.\n    \n    Usage:\n    \n        class MyObject(object):\n        \n            # ... Regular definitions here\n        \n            def _get_personality(self):\n                print('Calculating personality...')\n                time.sleep(5) # Time consuming process that creates personality\n                return 'Nice person'\n        \n            personality = LazilyEvaluatedConstantProperty(_get_personality)\n    \n    '''\n    def __init__(self, getter, name=None):\n        '''\n        Construct the LEC-property.\n        \n        You may optionally pass in the name the this property has in the class;\n        This will save a bit of processing later.\n        '''\n        self.getter = getter\n        self.our_name = name\n        \n        \n    def __get__(self, obj, our_type=None):\n\n        value = self.getter(obj)\n        \n        if not self.our_name:\n            if not our_type:\n                our_type = type(obj)\n            (self.our_name,) = (key for (key, value) in \n                                vars(our_type).iteritems()\n                                if value is self)\n        \n        setattr(obj, self.our_name, value)\n        \n        return value\n\ndef getted_vars(thing):\n    # todo: can make \"fallback\" option, to use value from original `vars` if get\n    # is unsuccessful.\n    my_vars = vars(thing)\n    return dict((name, getattr(thing, name)) for name in my_vars.iterkeys())\n    \n\n        \nif __name__ == '__main__': # todo: move to test suite\n    import random\n    class A(object):\n        def _get_personality(self):\n            print(\n                \"Calculating personality for %s. (Should happen only once.)\" % self\n            )\n            return random.choice(['Angry', 'Happy', 'Sad', 'Excited'])\n        personality = LazilyEvaluatedConstantProperty(_get_personality)\n    a = A()\n    print(a.personality)\n    print(a.personality)\n    print(a.personality)\n    \n    a2 = A()\n    print(a2.personality)\n    print(a2.personality)\n    print(a2.personality)\n    "}
{"context": "<|file_sep|>src\\garlicsim\\asynchronous_crunching\\project\\project.py\n# Copyright 2009 Ram Rachum.\n# This program is distributed under the LGPL2.1 license.\n\n\"\"\"\nThis module defines the Project class. See its documentation for more\ninformation.\n\"\"\"\n\nimport garlicsim.data_structures\nimport garlicsim.simpack_grokker\nimport crunching_manager\n\nimport garlicsim.misc.read_write_lock as read_write_lock\nfrom garlicsim.misc.infinity import Infinity\nimport garlicsim.misc.module_wrapper\nimport garlicsim.misc.cool_dict\n\n__all__ = [\"Project\"]\n\nclass Project(object):\n    \"\"\"\n    You create a project when you want to do a simulation which will crunch\n    in the background with worker threads or worker processes.\n\n    A project contains within it a tree.\n        \n    The crunching is taken care of by the CrunchingManager which is a part of\n    every project. The CrunchingManager employs CruncherThreads and/or\n    CruncherProcesses to get the work done. To make the CrunchingManager take\n    work from the crunchers and coordinate them, call the sync_crunchers method\n    of the project.\n    \n    What the crunching manager's sync_crunchers method will do is check the\n    attribute .nodes_to_crunch of the project. This attribute is a dict-like\n    object which maps nodes that should be crunched to a number specifying how\n    many states should be crunched from this node. The crunching manager will\n    then coordinate the crunchers in order to do this work. It will update the\n    .nodes_to_crunch attribute when the crunchers have completed some of the\n    work.\n    \"\"\"\n\n    def __init__(self, simpack):\n        \n        wrapped_simpack = \\\n            garlicsim.misc.module_wrapper.module_wrapper_factory(simpack)\n        \n        self.simpack_grokker = \\\n            garlicsim.simpack_grokker.SimpackGrokker(wrapped_simpack)\n        \n        self.simpack = wrapped_simpack\n\n        self.tree = garlicsim.data_structures.Tree()\n        \n        self.crunching_manager = crunching_manager.CrunchingManager(self)\n        \n        self.tree_lock = read_write_lock.ReadWriteLock()\n        \"\"\"\n        The tree_lock is a read-write lock that guards access to the tree.\n        We need such a thing because some simulations are history-dependent\n        and require reading from the tree in the same time that sync_crunchers\n        could potentially be writing to it.\n        \"\"\"\n\n        self.nodes_to_crunch = garlicsim.misc.cool_dict.CoolDict()\n        \"\"\"\n        A dict that maps leaves that should be worked on to a number specifying\n        how many nodes should be created after them.\n        \"\"\"\n\n    def make_plain_root(self, *args, **kwargs):\n        \"\"\"\n        Creates a parentless node, whose state is a simple plain state.\n        The simulation package should define the function `make_plain_state`\n        for this to work.\n        Returns the node.\n        \"\"\"\n        state = self.simpack.make_plain_state(*args, **kwargs)\n        return self.root_this_state(state)\n\n    def make_random_root(self, *args, **kwargs):\n        \"\"\"\n        Creates a parentless node, whose state is a random and messy state.\n        The simulation package should define the function `make_random_state`\n        for this to work.\n        Returns the node.\n        \"\"\"\n        state = self.simpack.make_random_state(*args, **kwargs)\n        return self.root_this_state(state)\n\n    def root_this_state(self, state):\n        \"\"\"\n        Takes a state, wraps it in a node and adds to the tree without a\n        parent.\n        Returns the node.\n        \"\"\"\n        return self.tree.add_state(state)\n\n    def crunch_all_leaves(self, node, wanted_distance):\n        \"\"\"\n        Orders to start crunching from all the leaves of `node`, so that there\n        will be a buffer whose length is at least `wanted_distance`.\n        \"\"\"\n        leaves = node.get_all_leaves(wanted_distance)\n        for (leaf, distance) in leaves.items():\n            new_distance = wanted_distance - distance\n            self.nodes_to_crunch.raise_to(leaf, new_distance)\n\n    def sync_crunchers(self, temp_infinity_node=None):\n        \"\"\"\n        Talks with all the crunchers, takes work from them for\n        implementing into the tree, terminates crunchers or creates\n        new crunchers if necessary.\n        You can pass a node as `temp_infinity_node`. That will cause this\n        function to temporarily treat this node as if it should be crunched\n        indefinitely.\n\n        Returns the total amount of nodes that were added to the tree.\n        \"\"\"\n        \n        return self.crunching_manager.sync_crunchers \\\n               (temp_infinity_node=temp_infinity_node)\n    \n    def __getstate__(self):\n        my_dict = dict(self.__dict__)\n        \n        del my_dict[\"tree_lock\"]\n        del my_dict[\"crunching_manager\"]\n        \n        return my_dict\n    \n    def __setstate__(self, pickled_project):\n        self.__init__(pickled_project[\"simpack\"])\n        self.__dict__.update(pickled_project)"}
{"context": "<|file_sep|>src\\garlicsim_wx\\simulation_packages\\prisoner\\prisoner.py\n# Copyright 2009 Ram Rachum.\n# This program is not licensed for distribution and may not be distributed.\n\nimport garlicsim.data_structures\nimport copy\n\nimport random\nrandom.seed()\n\n\nROUNDS=7\nNUMBER_OF_PLAYERS=70\n\ndef make_plain_state(*args,**kwargs):\n    global player_types\n    state=garlicsim.data_structures.State()\n\n    state.round=-1\n    state.match=0\n\n    state.player_pool=[player_types[i%len(player_types)]() for i in range(NUMBER_OF_PLAYERS)]\n\n    return new_match_step(state)\n\n\ndef make_random_state(*args,**kwargs):\n    state=garlicsim.data_structures.State()\n\n    state.round=-1\n    state.match=0\n\n    state.player_pool=[random_strategy_player() for i in range(NUMBER_OF_PLAYERS)]\n\n    return new_match_step(state)\n\ndef step(source_state,*args,**kwargs):\n    state=copy.deepcopy(source_state)\n    state.clock+=1\n\n    state.round+=1\n    if state.round==ROUNDS:\n        state.round=-1\n        state.match+=1\n        return new_match_step(state)\n\n    for pair in state.pairs:\n        play_game(pair,state.round)\n\n    return state\n\ndef new_match_step(state):\n    \"\"\"\n    Note: this function is not strictly a \"step function\":\n    it manipulates the state that is given to it and then returns it.\n    \"\"\"\n    pool=state.player_pool\n    loser=player_with_least_points(pool)\n    pool.remove(loser)\n    pool.append(random_strategy_player())\n\n    #for player in pool:\n    #    player.points=0\n\n    state.pairs=pair_pool(state.player_pool)\n    return state\n\ndef pair_pool(player_pool):\n    \"\"\"\n    Takes a player pool and returns a list of random pairs of players.\n    Every player will be a member of exactly one pair.\n    \"\"\"\n    assert len(player_pool)%2==0\n    result=[]\n    pool=player_pool[:]\n    while pool!=[]:\n        pair=random.sample(pool,2)\n        result.append(pair)\n\n        pool.remove(pair[0])\n        pool.remove(pair[1])\n    return result\n\ndef play_game((x,y),round):\n    x_move=x.play(round)\n    y_move=y.play(round)\n\n    assert x_move in [\"Play nice\",\"Play mean\"]\n    assert y_move in [\"Play nice\",\"Play mean\"]\n\n    if x_move==\"Play nice\" and y_move==\"Play nice\":\n        x.points+= 1\n        y.points+= 1\n    elif x_move==\"Play nice\" and y_move==\"Play mean\":\n        x.points+= -4\n        y.points+= 2\n    elif x_move==\"Play mean\" and y_move==\"Play nice\":\n        x.points+= 2\n        y.points+= -4\n    elif x_move==\"Play mean\" and y_move==\"Play mean\":\n        x.points+= -1\n        y.points+= -1\n\n    x.other_guy_played(y_move)\n    y.other_guy_played(x_move)\n\ndef random_strategy_player():\n    player=random.choice(player_types)\n    return player()\n\nclass Player(object):\n    def __init__(self):\n        self.points=0\n\n    def play(self,*args,**kwargs):\n        raise NotImplementedError\n\n    def other_guy_played(self,move):\n        pass\n\nclass Angel(Player):\n    def play(self,round):\n        return \"Play nice\"\n\nclass Asshole(Player):\n    def play(self,round):\n        return \"Play mean\"\n\nclass Smarty(Player):\n    def play(self,round):\n        if round==0:\n            return \"Play nice\"\n        else:\n            return self.last_play\n\n    def other_guy_played(self,move):\n        self.last_play=move\n\n\nplayer_types=[Angel,Asshole,Smarty]\n\ndef how_many_players_of_certain_type(pool,type):\n    n=0\n    for player in pool:\n        if isinstance(player,type):\n            n+=1\n    return n\n\ndef player_with_least_points(pool):\n    assert len(pool)>0\n    loser=pool[0]\n    for player in pool:\n        if player.points<loser.points:\n            loser=player\n    return loser\n\n\n\n\n\n\n\n\n"}
{"context": "<|file_sep|>tests\\contrib\\test_securecookie.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    tests.securecookie\n    ~~~~~~~~~~~~~~~~~~\n\n    Tests the secure cookie.\n\n    :copyright: (c) 2014 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\n\nfrom werkzeug.utils import parse_cookie\nfrom werkzeug.wrappers import Request, Response\nfrom werkzeug.contrib.securecookie import SecureCookie\n\n\ndef test_basic_support():\n    c = SecureCookie(secret_key=b'foo')\n    assert c.new\n    assert not c.modified\n    assert not c.should_save\n    c['x'] = 42\n    assert c.modified\n    assert c.should_save\n    s = c.serialize()\n\n    c2 = SecureCookie.unserialize(s, b'foo')\n    assert c is not c2\n    assert not c2.new\n    assert not c2.modified\n    assert not c2.should_save\n    assert c2 == c\n\n    c3 = SecureCookie.unserialize(s, b'wrong foo')\n    assert not c3.modified\n    assert not c3.new\n    assert c3 == {}\n\n    c4 = SecureCookie({'x': 42}, 'foo')\n    c4_serialized = c4.serialize()\n    assert SecureCookie.unserialize(c4_serialized, 'foo') == c4\n\n\ndef test_wrapper_support():\n    req = Request.from_values()\n    resp = Response()\n    c = SecureCookie.load_cookie(req, secret_key=b'foo')\n    assert c.new\n    c['foo'] = 42\n    assert c.secret_key == b'foo'\n    c.save_cookie(resp)\n\n    req = Request.from_values(headers={\n        'Cookie':  'session=\"%s\"' % parse_cookie(resp.headers['set-cookie'])['session']\n    })\n    c2 = SecureCookie.load_cookie(req, secret_key=b'foo')\n    assert not c2.new\n    assert c2 == c\n"}
{"context": "<|file_sep|>tests\\test_parsing.py\n# -*- coding: utf-8 -*-\nfrom os.path import join, dirname, abspath\nfrom werkzeug import Client, Request, Response\n\n\n@Request.application\ndef form_data_consumer(request):\n    result_object = request.args['object']\n    if result_object == 'text':\n        return Response(repr(request.form['text']))\n    f = request.files[result_object]\n    return Response('\\n'.join((\n        repr(f.filename),\n        repr(f.name),\n        repr(f.content_type),\n        f.stream.read()\n    )))\n\n\ndef get_contents(filename):\n    f = file(filename, 'rb')\n    try:\n        return f.read()\n    finally:\n        f.close()\n\n\ndef test_multipart():\n    \"\"\"Tests multipart parsing against data collected from webbrowsers\"\"\"\n    resources = join(dirname(__file__), 'multipart')\n    client = Client(form_data_consumer, Response)\n\n    repository = [\n        ('firefox3-2png1txt', '---------------------------186454651713519341951581030105', [\n            (u'anchor.png', 'file1', 'image/png', 'file1.png'),\n            (u'application_edit.png', 'file2', 'image/png', 'file2.png')\n        ], u'example text'),\n        ('firefox3-2pnglongtext', '---------------------------14904044739787191031754711748', [\n            (u'accept.png', 'file1', 'image/png', 'file1.png'),\n            (u'add.png', 'file2', 'image/png', 'file2.png')\n        ], u'--long text\\r\\n--with boundary\\r\\n--lookalikes--'),\n        ('opera8-2png1txt', '----------zEO9jQKmLc2Cq88c23Dx19', [\n            (u'arrow_branch.png', 'file1', 'image/png', 'file1.png'),\n            (u'award_star_bronze_1.png', 'file2', 'image/png', 'file2.png')\n        ], u'blafasel öäü'),\n        ('webkit3-2png1txt', '----WebKitFormBoundaryjdSFhcARk8fyGNy6', [\n            (u'gtk-apply.png', 'file1', 'image/png', 'file1.png'),\n            (u'gtk-no.png', 'file2', 'image/png', 'file2.png')\n        ], u'this is another text with ümläüts'),\n        ('ie6-2png1txt', '---------------------------7d91b03a20128', [\n            (u'file1.png', 'file1', 'image/x-png', 'file1.png'),\n            (u'file2.png', 'file2', 'image/x-png', 'file2.png')\n        ], u'ie6 sucks :-/')\n    ]\n\n    for name, boundary, files, text in repository:\n        folder = join(resources, name)\n        data = get_contents(join(folder, 'request.txt'))\n        for filename, field, content_type, fsname in files:\n            response = client.post('/?object=' + field, data=data, content_type=\n                                   'multipart/form-data; boundary=\"%s\"' % boundary,\n                                   content_length=len(data))\n            lines = response.data.split('\\n', 3)\n            assert lines[0] == repr(filename)\n            assert lines[1] == repr(field)\n            assert lines[2] == repr(content_type)\n            assert lines[3] == get_contents(join(folder, fsname))\n        response = client.post('/?object=text', data=data, content_type=\n                               'multipart/form-data; boundary=\"%s\"' % boundary,\n                               content_length=len(data))\n        assert response.data == repr(text)\n"}
{"context": "<|file_sep|>werkzeug\\debug\\util.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.debug.util\n    ~~~~~~~~~~~~~~~~~~~\n\n    Debugging utilities.\n\n    :copyright: 2007 by Georg Brandl, Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport os\nimport sys\nimport inspect\nimport threading\nfrom random import random\nfrom cStringIO import StringIO\n\nfrom werkzeug.debug.highlighter import PythonParser\n\n\ndef get_current_thread():\n    return threading.currentThread()\n\n\nclass Namespace(object):\n    def __init__(self, **kwds):\n        self.__dict__.update(kwds)\n\n\nclass ThreadedStream(object):\n    _orig = None\n\n    def __init__(self):\n        self._buffer = {}\n\n    def install(cls, environ):\n        if cls._orig or not environ['wsgi.multithread']:\n            return\n        cls._orig = sys.stdout\n        sys.stdout = cls()\n    install = classmethod(install)\n\n    def can_interact(cls):\n        return not cls._orig is None\n    can_interact = classmethod(can_interact)\n\n    def push(self):\n        tid = get_current_thread()\n        self._buffer[tid] = StringIO()\n\n    def release(self):\n        tid = get_current_thread()\n        if tid in self._buffer:\n            result = self._buffer[tid].getvalue()\n            del self._buffer[tid]\n        else:\n            result = ''\n        return result\n\n    def write(self, d):\n        tid = get_current_thread()\n        if tid in self._buffer:\n            self._buffer[tid].write(d)\n        else:\n            self._orig.write(d)\n\n\ndef get_uid():\n    \"\"\"\n    Return a random unique ID.\n    \"\"\"\n    return str(random()).encode('base64')[3:11]\n\n\ndef get_frame_info(tb, context_lines=7):\n    \"\"\"\n    Return a dict of information about a given traceback.\n    \"\"\"\n    # line numbers / function / variables\n    lineno = tb.tb_lineno\n    function = tb.tb_frame.f_code.co_name\n    variables = tb.tb_frame.f_locals\n\n    # get filename\n    fn = tb.tb_frame.f_globals.get('__file__')\n    if not fn:\n        fn = os.path.realpath(inspect.getsourcefile(tb) or\n                              inspect.getfile(tb))\n    if fn[-4:] in ('.pyc', '.pyo'):\n        fn = fn[:-1]\n\n    # module name\n    modname = tb.tb_frame.f_globals.get('__name__')\n\n    # get loader\n    loader = tb.tb_frame.f_globals.get('__loader__')\n\n    # sourcecode\n    try:\n        if not loader is None:\n            source = loader.get_source(modname)\n        else:\n            source = file(fn).read()\n    except:\n        source = ''\n        pre_context, post_context = [], []\n        context_line, context_lineno = None, None\n    else:\n        parser = PythonParser(source)\n        parser.parse()\n        parsed_source = parser.get_html_output()\n        lbound = max(0, lineno - context_lines - 1)\n        ubound = lineno + context_lines\n        try:\n            context_line = parsed_source[lineno - 1]\n            pre_context = parsed_source[lbound:lineno - 1]\n            post_context = parsed_source[lineno:ubound]\n        except IndexError, e:\n            context_line = None\n            pre_context = post_context = [], []\n        context_lineno = lbound\n\n    return {\n        'tb':               tb,\n        'filename':         isinstance(fn, unicode) and fn.encode('utf-8') or fn,\n        'loader':           loader,\n        'function':         function,\n        'lineno':           lineno,\n        'vars':             variables,\n        'pre_context':      pre_context,\n        'context_line':     context_line,\n        'post_context':     post_context,\n        'context_lineno':   context_lineno,\n        'source':           source\n    }\n"}
{"context": "<|file_sep|>werkzeug\\contrib\\fixers.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.contrib.fixers\n    ~~~~~~~~~~~~~~~~~~~~~~~\n\n    .. versionadded:: 0.5\n\n    This module includes various helpers that fix bugs in web servers.  They may\n    be necessary for some versions of a buggy web server but not others.  We try\n    to stay updated with the status of the bugs as good as possible but you have\n    to make sure whether they fix the problem you encounter.\n\n    If you notice bugs in webservers not fixed in this module consider\n    contributing a patch.\n\n    :copyright: Copyright 2009 by the Werkzeug Team, see AUTHORS for more details.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nfrom urllib import unquote\n\n\nclass LighttpdCGIRootFix(object):\n    \"\"\"Wrap the application in this middleware if you are using lighttpd\n    with FastCGI or CGI and the application is mounted on the URL root.\n    \"\"\"\n\n    def __init__(self, app):\n        self.app = app\n\n    def __call__(self, environ, start_response):\n        environ['PATH_INFO'] = environ.get('SCRIPT_NAME', '') + \\\n                               environ.get('PATH_INFO', '')\n        environ['SCRIPT_NAME'] = ''\n        return self.app(environ, start_response)\n\n\nclass PathInfoFromRequestUriFix(object):\n    \"\"\"On windows environment variables are limited to the system charset\n    which makes it impossible to store the `PATH_INFO` variable in the\n    environment without loss of information on some systems.\n\n    This is for example a problem for CGI scripts on a Windows Apache.\n\n    This fixer works by recreating the `PATH_INFO` from `REQUEST_URI`,\n    `REQUEST_URL`, or `UNENCODED_URL` (whatever is available).  Thus the\n    fix can only be applied if the webserver supports either of these\n    variables.\n    \"\"\"\n\n    def __init__(self, app):\n        self.app = app\n\n    def __call__(self, environ, start_response):\n        for key in 'REQUEST_URL', 'REQUEST_URI', 'UNENCODED_URL':\n            if key not in environ:\n                continue\n            request_uri = unquote(environ[key])\n            script_name = unquote(environ.get('SCRIPT_NAME', ''))\n            if request_uri.startswith(script_name):\n                environ['PATH_INFO'] = request_uri[len(script_name):] \\\n                    .split('?', 1)[0]\n                break\n        return self.app(environ, start_response)\n\n\nclass ProxyFix(object):\n    \"\"\"This middleware can be applied to add HTTP proxy support to an\n    application that was not designed with HTTP proxies in mind.  It\n    sets `REMOTE_ADDR`, `HTTP_HOST` from `X-Forwarded` headers.\n\n    Werkzeug wrappers have builtin support for this by setting the\n    :attr:`~werkzeug.BaseRequest.is_behind_proxy` attribute to `True`.\n\n    Do not use this middleware in non-proxy setups for security reasons.\n\n    The original values of `REMOTE_ADDR` and `HTTP_HOST` are stored in\n    the WSGI environment as `werkzeug.proxy_fix.orig_remote_addr` and\n    `werkzeug.proxy_fix.orig_http_host`.\n    \"\"\"\n\n    def __init__(self, app):\n        self.app = app\n\n    def __call__(self, environ, start_response):\n        getter = environ.get\n        forwarded_for = getter('HTTP_X_FORWARDED_FOR', '').split(',')\n        forwarded_host = getter('HTTP_X_FORWARDED_HOST', '')\n        environ.update({\n            'werkzeug.proxy_fix.orig_remote_addr':  getter('REMOTE_ADDR'),\n            'werkzeug.proxy_fix.orig_http_host':    getter('HTTP_HOST')\n        })\n        if forwarded_for:\n            environ['REMOTE_ADDR'] = forwarded_for[0].strip()\n        if forwarded_host:\n            environ['HTTP_HOST'] = forwarded_host\n        return self.app(environ, start_response)\n"}
{"context": "<|file_sep|>werkzeug\\debug\\__init__.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.debug\n    ~~~~~~~~~~~~~~\n\n    WSGI application traceback debugger.\n\n    :copyright: 2007 by Georg Brandl.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport sys\nimport inspect\nimport traceback\nimport code\n\nfrom werkzeug.debug.render import debug_page, load_resource\nfrom werkzeug.debug.util import ThreadedStream, Namespace, get_uid, \\\n     get_frame_info\nfrom werkzeug.utils import url_decode\n\n\nclass DebuggedApplication(object):\n    \"\"\"\n    Enables debugging support for a given application::\n\n        from werkzeug.debug import DebuggedApplication\n        from myapp import app\n        app = DebuggedApplication(app, evalex=True)\n\n    The `evalex` keyword argument allows evaluating expressions in a\n    traceback's frame context.\n\n    THIS IS A GAPING SECURITY HOLE IF PUBLICLY ACCESSIBLE!\n    \"\"\"\n\n    def __init__(self, application, evalex=False):\n        self.evalex = bool(evalex)\n        self.application = application\n        self.tracebacks = {}\n\n    def __call__(self, environ, start_response):\n        # exec code in open tracebacks or provide shared data\n        if environ.get('PATH_INFO', '').strip('/').endswith('__traceback__'):\n            parameters = url_decode(environ.get('QUERY_STRING', ''))\n            # shared data\n            if 'resource' in parameters and 'mimetype' in parameters:\n                data = load_resource(parameters['resource'])\n                start_response('200 OK', [\n                    ('Content-Type', str(parameters['mimetype'])),\n                    ('Content-Length', str(len(data)))\n                ])\n                yield data\n                return\n            # execute commands in an existing debug context\n            elif self.evalex:\n                try:\n                    tb = self.tracebacks[parameters['tb']]\n                    frame = parameters['frame']\n                    context = tb[frame]\n                    code = parameters['code']\n                except (IndexError, KeyError):\n                    pass\n                else:\n                    result = context.exec_expr(code)\n                    start_response('200 OK', [('Content-Type', 'text/plain')])\n                    yield result\n                    return\n\n        # wrap the application and catch errors.\n        appiter = None\n        try:\n            appiter = self.application(environ, start_response)\n            for line in appiter:\n                yield line\n        except:\n            ThreadedStream.install(environ)\n            exc_info = sys.exc_info()\n            try:\n                headers = [('Content-Type', 'text/html; charset=utf-8')]\n                start_response('500 INTERNAL SERVER ERROR', headers)\n            except:\n                pass\n            debug_context = self.create_debug_context(environ, exc_info)\n            yield debug_page(debug_context).encode('utf-8')\n\n        if hasattr(appiter, 'close'):\n            appiter.close()\n\n    def create_debug_context(self, environ, exc_info):\n        exception_type, exception_value, tb = exc_info\n        # skip first internal frame\n        if not tb.tb_next is None:\n            tb = tb.tb_next\n        plaintb = ''.join(traceback.format_exception(exception_type,\n                                                     exception_value, tb))\n        environ['wsgi.errors'].write(plaintb)\n\n        # load frames\n        frames = []\n        frame_map = {}\n        tb_uid = None\n        if ThreadedStream.can_interact():\n            tb_uid = get_uid()\n            frame_map = self.tracebacks[tb_uid] = {}\n\n        # walk through frames and collect information\n        while tb is not None:\n            if not tb.tb_frame.f_locals.get('__traceback_hide__', False):\n                if tb_uid:\n                    frame_uid = get_uid()\n                    frame_map[frame_uid] = InteractiveDebugger(tb.tb_frame)\n                else:\n                    frame_uid = None\n                frame = get_frame_info(tb)\n                frame['frame_uid'] = frame_uid\n                frames.append(frame)\n            tb = tb.tb_next\n\n        # guard for string exceptions\n        if isinstance(exception_type, str):\n            extypestr = 'string exception'\n            exception_value = exception_type\n        elif exception_type.__module__ == 'exceptions':\n            extypestr = exception_type.__name__\n        else:\n            extypestr = '%s.%s' % (\n                exception_type.__module__,\n                exception_type.__name__\n            )\n\n        # support for the werkzeug request object or fall back to\n        # WSGI environment\n        request = environ.get('werkzeug.request')\n        if request is not None:\n            req_vars = []\n            for varname in dir(request):\n                if varname[0] == '_':\n                    continue\n                value = getattr(request, varname)\n                if hasattr(value, 'im_func'):\n                    continue\n                req_vars.append((varname, value))\n        else:\n            req_vars = [('WSGI Environ', environ)]\n\n        return Namespace(\n            evalex =          self.evalex,\n            exception_type =  extypestr,\n            exception_value = str(exception_value),\n            frames =          frames,\n            last_frame =      frames[-1],\n            plaintb =         plaintb,\n            tb_uid =          tb_uid,\n            frame_map =       frame_map,\n            req_vars =        req_vars,\n        )\n\n\nclass InteractiveDebugger(code.InteractiveInterpreter):\n    \"\"\"\n    Subclass of the python interactive interpreter that\n    automatically captures stdout and buffers older input.\n    \"\"\"\n\n    def __init__(self, frame):\n        self.globals = frame.f_globals\n        code.InteractiveInterpreter.__init__(self, frame.f_locals)\n        self.prompt = '>>> '\n        self.buffer = []\n\n    def runsource(self, source):\n        prompt = self.prompt\n        sys.stdout.push()\n        try:\n            source_to_eval = ''.join(self.buffer + [source])\n            if code.InteractiveInterpreter.runsource(self,\n               source_to_eval, '<debugger>', 'single'):\n                self.prompt = '... '\n                self.buffer.append(source)\n            else:\n                self.prompt = '>>> '\n                del self.buffer[:]\n        finally:\n            return prompt + source + sys.stdout.release()\n\n    def runcode(self, code):\n        try:\n            exec code in self.globals, self.locals\n        except:\n            self.showtraceback()\n\n    def write(self, data):\n        sys.stdout.write(data)\n\n    def exec_expr(self, code):\n        rv = self.runsource(code)\n        if isinstance(rv, unicode):\n            return rv.encode('utf-8')\n        return rv\n"}
{"context": "<|file_sep|>tests\\contrib\\test_cache.py\nimport os, tempfile, shutil\n\nfrom werkzeug.contrib.cache import SimpleCache, FileSystemCache\n\n\ndef test_simplecache_get_dict():\n    \"\"\"SimpleCache.get_dict bug\"\"\"\n    cache = SimpleCache()\n    cache.set('a', 'a')\n    cache.set('b', 'b')\n    d = cache.get_dict('a', 'b')\n    assert 'a' in d\n    assert 'a' == d['a']\n    assert 'b' in d\n    assert 'b' == d['b']\n\n\ndef test_filesystemcache_set_get():\n    \"\"\"\n    test if FileSystemCache.set/get works\n    \"\"\"\n    tmp_dir = tempfile.mkdtemp()\n    try:\n        cache = FileSystemCache(cache_dir=tmp_dir)\n        for i in range(3):\n            cache.set(str(i), i * i)\n        for i in range(3):\n            result = cache.get(str(i))\n            assert result == i * i\n    finally:\n        shutil.rmtree(tmp_dir)\n\n\ndef test_filesystemcache_prune():\n    \"\"\"\n    test if FileSystemCache._prune works and keeps the cache entry count\n    below the given threshold.\n    \"\"\"\n    THRESHOLD = 13\n    tmp_dir = tempfile.mkdtemp()\n    cache = FileSystemCache(cache_dir=tmp_dir, threshold=THRESHOLD)\n    for i in range(2 * THRESHOLD):\n        cache.set(str(i), i)\n    cache_files = os.listdir(tmp_dir)\n    shutil.rmtree(tmp_dir)\n    assert len(cache_files) <= THRESHOLD\n\n\ndef test_filesystemcache_clear():\n    \"\"\"\n    test if FileSystemCache.clear works\n    \"\"\"\n    tmp_dir = tempfile.mkdtemp()\n    cache = FileSystemCache(cache_dir=tmp_dir)\n    cache.set('foo', 'bar')\n    cache_files = os.listdir(tmp_dir)\n    assert len(cache_files) == 1\n    cache.clear()\n    cache_files = os.listdir(tmp_dir)\n    assert len(cache_files) == 0\n    shutil.rmtree(tmp_dir)\n\n"}
{"context": "<|file_sep|>tests\\sansio\\test_multipart.py\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.sansio.multipart import Data\nfrom werkzeug.sansio.multipart import Epilogue\nfrom werkzeug.sansio.multipart import Field\nfrom werkzeug.sansio.multipart import File\nfrom werkzeug.sansio.multipart import MultipartDecoder\nfrom werkzeug.sansio.multipart import MultipartEncoder\nfrom werkzeug.sansio.multipart import Preamble\n\n\ndef test_decoder_simple() -> None:\n    boundary = b\"---------------------------9704338192090380615194531385\"\n    decoder = MultipartDecoder(boundary)\n    data = \"\"\"\n-----------------------------9704338192090380615194531385\nContent-Disposition: form-data; name=\"fname\"\n\nß∑œß∂ƒå∂\n-----------------------------9704338192090380615194531385\nContent-Disposition: form-data; name=\"lname\"; filename=\"bob\"\n\nasdasd\n-----------------------------9704338192090380615194531385--\n    \"\"\".replace(\n        \"\\n\", \"\\r\\n\"\n    ).encode(\n        \"utf-8\"\n    )\n    decoder.receive_data(data)\n    decoder.receive_data(None)\n    events = [decoder.next_event()]\n    while not isinstance(events[-1], Epilogue) and len(events) < 6:\n        events.append(decoder.next_event())\n    assert events == [\n        Preamble(data=b\"\"),\n        Field(\n            name=\"fname\",\n            headers=Headers([(\"Content-Disposition\", 'form-data; name=\"fname\"')]),\n        ),\n        Data(data=\"ß∑œß∂ƒå∂\".encode(), more_data=False),\n        File(\n            name=\"lname\",\n            filename=\"bob\",\n            headers=Headers(\n                [(\"Content-Disposition\", 'form-data; name=\"lname\"; filename=\"bob\"')]\n            ),\n        ),\n        Data(data=b\"asdasd\", more_data=False),\n        Epilogue(data=b\"    \"),\n    ]\n    encoder = MultipartEncoder(boundary)\n    result = b\"\"\n    for event in events:\n        result += encoder.send_event(event)\n    assert data == result\n"}
{"context": "<|file_sep|>werkzeug\\testsuite\\contrib\\iterio.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.testsuite.iterio\n    ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Tests the iterio object.\n\n    :copyright: (c) 2011 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport unittest\nfrom functools import partial\n\nfrom werkzeug.testsuite import WerkzeugTestCase\nfrom werkzeug.contrib.iterio import IterIO, greenlet\n\n\nclass IterOTestSuite(WerkzeugTestCase):\n\n    def test_basic_native(self):\n        io = IterIO([\"Hello\", \"World\", \"1\", \"2\", \"3\"])\n        self.assert_equal(io.tell(), 0)\n        self.assert_equal(io.read(2), \"He\")\n        self.assert_equal(io.tell(), 2)\n        self.assert_equal(io.read(3), \"llo\")\n        self.assert_equal(io.tell(), 5)\n        io.seek(0)\n        self.assert_equal(io.read(5), \"Hello\")\n        self.assert_equal(io.tell(), 5)\n        self.assert_equal(io._buf, \"Hello\")\n        self.assert_equal(io.read(), \"World123\")\n        self.assert_equal(io.tell(), 13)\n        io.close()\n        assert io.closed\n\n        io = IterIO([\"Hello\\n\", \"World!\"])\n        self.assert_equal(io.readline(), 'Hello\\n')\n        self.assert_equal(io._buf, 'Hello\\n')\n        self.assert_equal(io.read(), 'World!')\n        self.assert_equal(io._buf, 'Hello\\nWorld!')\n        self.assert_equal(io.tell(), 12)\n        io.seek(0)\n        self.assert_equal(io.readlines(), ['Hello\\n', 'World!'])\n\n        io = IterIO([\"foo\\n\", \"bar\"])\n        io.seek(-4, 2)\n        self.assert_equal(io.read(4), '\\nbar')\n\n        self.assert_raises(IOError, io.seek, 2, 100)\n        io.close()\n        self.assert_raises(ValueError, io.read)\n\n    def test_basic_bytes(self):\n        io = IterIO([b\"Hello\", b\"World\", b\"1\", b\"2\", b\"3\"])\n        self.assert_equal(io.tell(), 0)\n        self.assert_equal(io.read(2), b\"He\")\n        self.assert_equal(io.tell(), 2)\n        self.assert_equal(io.read(3), b\"llo\")\n        self.assert_equal(io.tell(), 5)\n        io.seek(0)\n        self.assert_equal(io.read(5), b\"Hello\")\n        self.assert_equal(io.tell(), 5)\n        self.assert_equal(io._buf, b\"Hello\")\n        self.assert_equal(io.read(), b\"World123\")\n        self.assert_equal(io.tell(), 13)\n        io.close()\n        assert io.closed\n\n        io = IterIO([b\"Hello\\n\", b\"World!\"])\n        self.assert_equal(io.readline(), b'Hello\\n')\n        self.assert_equal(io._buf, b'Hello\\n')\n        self.assert_equal(io.read(), b'World!')\n        self.assert_equal(io._buf, b'Hello\\nWorld!')\n        self.assert_equal(io.tell(), 12)\n        io.seek(0)\n        self.assert_equal(io.readlines(), [b'Hello\\n', b'World!'])\n\n        io = IterIO([b\"foo\\n\", b\"bar\"])\n        io.seek(-4, 2)\n        self.assert_equal(io.read(4), b'\\nbar')\n\n        self.assert_raises(IOError, io.seek, 2, 100)\n        io.close()\n        self.assert_raises(ValueError, io.read)\n\n    def test_basic_unicode(self):\n        io = IterIO([u\"Hello\", u\"World\", u\"1\", u\"2\", u\"3\"])\n        self.assert_equal(io.tell(), 0)\n        self.assert_equal(io.read(2), u\"He\")\n        self.assert_equal(io.tell(), 2)\n        self.assert_equal(io.read(3), u\"llo\")\n        self.assert_equal(io.tell(), 5)\n        io.seek(0)\n        self.assert_equal(io.read(5), u\"Hello\")\n        self.assert_equal(io.tell(), 5)\n        self.assert_equal(io._buf, u\"Hello\")\n        self.assert_equal(io.read(), u\"World123\")\n        self.assert_equal(io.tell(), 13)\n        io.close()\n        assert io.closed\n\n        io = IterIO([u\"Hello\\n\", u\"World!\"])\n        self.assert_equal(io.readline(), u'Hello\\n')\n        self.assert_equal(io._buf, u'Hello\\n')\n        self.assert_equal(io.read(), u'World!')\n        self.assert_equal(io._buf, u'Hello\\nWorld!')\n        self.assert_equal(io.tell(), 12)\n        io.seek(0)\n        self.assert_equal(io.readlines(), [u'Hello\\n', u'World!'])\n\n        io = IterIO([u\"foo\\n\", u\"bar\"])\n        io.seek(-4, 2)\n        self.assert_equal(io.read(4), u'\\nbar')\n\n        self.assert_raises(IOError, io.seek, 2, 100)\n        io.close()\n        self.assert_raises(ValueError, io.read)\n\n\nclass IterITestSuite(WerkzeugTestCase):\n\n    def test_basic(self):\n        def producer(out):\n            out.write('1\\n')\n            out.write('2\\n')\n            out.flush()\n            out.write('3\\n')\n        iterable = IterIO(producer)\n        self.assert_equal(next(iterable), '1\\n2\\n')\n        self.assert_equal(next(iterable), '3\\n')\n        self.assert_raises(StopIteration, partial(next, iterable))\n\n\ndef suite():\n    suite = unittest.TestSuite()\n    suite.addTest(unittest.makeSuite(IterOTestSuite))\n    if greenlet is not None:\n        suite.addTest(unittest.makeSuite(IterITestSuite))\n    return suite\n"}
{"context": "<|file_sep|>werkzeug\\serving.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.serving\n    ~~~~~~~~~~~~~~~~\n\n    This module wraps the `wsgiref` module so that it reloads code\n    automatically. Works with any WSGI application but it won't help in\n    non `wsgiref` environments. Use it only for development.\n\n    Usage::\n\n        from werkzeug.serving import run_simple\n        from myproject import make_app\n        run_simple('localhost', 8080, make_app())\n\n    :copyright: 2007 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport os\nimport socket\nimport sys\nimport time\nimport thread\n\n\ndef reloader_loop(extra_files):\n    \"\"\"When this function is run from the main thread, it will force other\n    threads to exit when any modules currently loaded change.\n\n    :param extra_files: a list of additional files it should watch.\n    \"\"\"\n    mtimes = {}\n    while True:\n        for filename in filter(None, [getattr(module, '__file__', None)\n                                      for module in sys.modules.values()] +\n                                     extra_files):\n            while not os.path.isfile(filename):\n                filename = os.path.dirname(filename)\n                if not filename:\n                    break\n            if not filename:\n                continue\n\n            if filename[-4:] in ('.pyc', '.pyo'):\n                filename = filename[:-1]\n\n            mtime = os.stat(filename).st_mtime\n            if filename not in mtimes:\n                mtimes[filename] = mtime\n                continue\n            if mtime > mtimes[filename]:\n                sys.exit(3)\n        time.sleep(1)\n\n\ndef restart_with_reloader():\n    \"\"\"Spawn a new Python interpreter with the same arguments as this one,\n    but running the reloader thread.\"\"\"\n    while True:\n        print '* Restarting with reloader...'\n        args = [sys.executable] + sys.argv\n        if sys.platform == 'win32':\n            args = ['\"%s\"' % arg for arg in args]\n        new_environ = os.environ.copy()\n        new_environ['RUN_MAIN'] = 'true'\n        exit_code = os.spawnve(os.P_WAIT, sys.executable, args, new_environ)\n        if exit_code != 3:\n            return exit_code\n\n\ndef run_with_reloader(main_func, extra_watch):\n    \"\"\"\n    Run the given function in an independent python interpreter.\n    \"\"\"\n    if os.environ.get('RUN_MAIN') == 'true':\n        thread.start_new_thread(main_func, ())\n        try:\n            reloader_loop(extra_watch)\n        except KeyboardInterrupt:\n            return\n    try:\n        sys.exit(restart_with_reloader())\n    except KeyboardInterrupt:\n        pass\n\n\ndef run_simple(hostname, port, application, use_reloader=False,\n               extra_files=None):\n    \"\"\"\n    Start an application using wsgiref and with an optional reloader.\n    \"\"\"\n    from wsgiref.simple_server import make_server\n    def inner():\n        srv = make_server(hostname, port, application)\n        try:\n            srv.serve_forever()\n        except KeyboardInterrupt:\n            pass\n\n    if os.environ.get('RUN_MAIN') != 'true':\n        print '* Running on http://%s:%d/' % (hostname, port)\n    if use_reloader:\n        # Create and destroy a socket so that any exceptions are raised before we\n        # spawn a separate Python interpreter and loose this ability.\n        test_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        test_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        test_socket.bind((hostname, port))\n        test_socket.close()\n        run_with_reloader(inner, extra_files or [])\n    else:\n        inner()\n"}
{"context": "<|file_sep|>tests\\test_utils.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.utils test\n    ~~~~~~~~~~~~~~~~~~~\n\n    :copyright: (c) 2011 by the Werkzeug Team, see AUTHORS for more details.\n    :license: BSD license.\n\"\"\"\nimport sys\nfrom datetime import datetime\nfrom StringIO import StringIO\n\nfrom nose.tools import assert_raises\n\nfrom werkzeug.utils import *\nfrom werkzeug.wrappers import BaseResponse, Request\nfrom werkzeug.http import parse_date\nfrom werkzeug.test import Client, run_wsgi_app, create_environ\n\n\ndef test_import_patch():\n    \"\"\"Import patch\"\"\"\n    import werkzeug\n    from werkzeug import __all__ as public_methods\n    for name in public_methods:\n        getattr(werkzeug, name)\n\n\ndef test_cached_property():\n    \"\"\"Cached property decorator\"\"\"\n    foo = []\n    class A(object):\n        def prop(self):\n            foo.append(42)\n            return 42\n        prop = cached_property(prop)\n\n    a = A()\n    p = a.prop\n    q = a.prop\n    assert p == q == 42\n    assert foo == [42]\n\n    foo = []\n    class A(object):\n        def _prop(self):\n            foo.append(42)\n            return 42\n        prop = cached_property(_prop, name='prop')\n        del _prop\n\n    a = A()\n    p = a.prop\n    q = a.prop\n    assert p == q == 42\n    assert foo == [42]\n\n\ndef test_environ_property():\n    \"\"\"Environ property descriptor\"\"\"\n    from werkzeug.http import http_date\n    class A(object):\n        environ = {'string': 'abc', 'number': '42'}\n\n        string = environ_property('string')\n        missing = environ_property('missing', 'spam')\n        read_only = environ_property('number')\n        number = environ_property('number', load_func=int)\n        broken_number = environ_property('broken_number', load_func=int)\n        date = environ_property('date', None, parse_date, http_date,\n                                read_only=False)\n        foo = environ_property('foo')\n\n    a = A()\n    assert a.string == 'abc'\n    assert a.missing == 'spam'\n    def test_assign():\n        a.read_only = 'something'\n    assert_raises(AttributeError, test_assign)\n    assert a.number == 42\n    assert a.broken_number == None\n    assert a.date is None\n    a.date = datetime(2008, 1, 22, 10, 0, 0, 0)\n    assert a.environ['date'] == 'Tue, 22 Jan 2008 10:00:00 GMT'\n\n\ndef test_escape():\n    \"\"\"XML/HTML escaping\"\"\"\n    class Foo(str):\n        def __html__(self):\n            return unicode(self)\n    assert escape(None) == ''\n    assert escape(42) == '42'\n    assert escape('<>') == '&lt;&gt;'\n    assert escape('\"foo\"') == '\"foo\"'\n    assert escape('\"foo\"', True) == '&quot;foo&quot;'\n    assert escape(Foo('<foo>')) == '<foo>'\n\n\ndef test_unescape():\n    \"\"\"XML/HTML unescaping\"\"\"\n    assert unescape('&lt;&auml;&gt;') == u'<ä>'\n\n\ndef test_run_wsgi_app():\n    \"\"\"WSGI test-runner\"\"\"\n    def foo(environ, start_response):\n        start_response('200 OK', [('Content-Type', 'text/plain')])\n        yield '1'\n        yield '2'\n        yield '3'\n\n    app_iter, status, headers = run_wsgi_app(foo, {})\n    assert status == '200 OK'\n    assert headers == [('Content-Type', 'text/plain')]\n    assert app_iter.next() == '1'\n    assert app_iter.next() == '2'\n    assert app_iter.next() == '3'\n    assert_raises(StopIteration, app_iter.next)\n\n    got_close = []\n    class CloseIter(object):\n        def __init__(self):\n            self.iterated = False\n        def __iter__(self):\n            return self\n        def close(self):\n            got_close.append(None)\n        def next(self):\n            if self.iterated:\n                raise StopIteration()\n            self.iterated = True\n            return 'bar'\n\n    def bar(environ, start_response):\n        start_response('200 OK', [('Content-Type', 'text/plain')])\n        return CloseIter()\n\n    app_iter, status, headers = run_wsgi_app(bar, {})\n    assert status == '200 OK'\n    assert headers == [('Content-Type', 'text/plain')]\n    assert app_iter.next() == 'bar'\n    assert_raises(StopIteration, app_iter.next)\n    app_iter.close()\n\n    assert run_wsgi_app(bar, {}, True)[0] == ['bar']\n\n    assert len(got_close) == 2\n\n\ndef test_import_string():\n    \"\"\"String based importing\"\"\"\n    import cgi\n    from werkzeug.debug import DebuggedApplication\n    assert import_string('cgi.escape') is cgi.escape\n    assert import_string(u'cgi.escape') is cgi.escape\n    assert import_string('cgi:escape') is cgi.escape\n    assert import_string('XXXXXXXXXXXX', True) is None\n    assert import_string('cgi.XXXXXXXXXXXX', True) is None\n    assert import_string(u'cgi.escape') is cgi.escape\n    assert import_string(u'werkzeug.debug.DebuggedApplication') is DebuggedApplication\n    assert_raises(ImportError, import_string, 'XXXXXXXXXXXXXXXX')\n    assert_raises(ImportError, import_string, 'cgi.XXXXXXXXXX')\n\n\ndef test_find_modules():\n    \"\"\"Module and package lookup\"\"\"\n    assert list(find_modules('werkzeug.debug')) == \\\n        ['werkzeug.debug.console', 'werkzeug.debug.repr',\n         'werkzeug.debug.tbtools']\n\n\ndef test_html_builder():\n    \"\"\"HTML builder\"\"\"\n    assert html.p('Hello World') == '<p>Hello World</p>'\n    assert html.a('Test', href='#') == '<a href=\"#\">Test</a>'\n    assert html.br() == '<br>'\n    assert xhtml.br() == '<br />'\n    assert html.img(src='foo') == '<img src=\"foo\">'\n    assert xhtml.img(src='foo') == '<img src=\"foo\" />'\n    assert html.html(\n        html.head(\n            html.title('foo'),\n            html.script(type='text/javascript')\n        )\n    ) == '<html><head><title>foo</title><script type=\"text/javascript\">' \\\n         '</script></head></html>'\n    assert html('<foo>') == '&lt;foo&gt;'\n    assert html.input(disabled=True) == '<input disabled>'\n    assert xhtml.input(disabled=True) == '<input disabled=\"disabled\" />'\n    assert html.input(disabled='') == '<input>'\n    assert xhtml.input(disabled='') == '<input />'\n    assert html.input(disabled=None) == '<input>'\n    assert xhtml.input(disabled=None) == '<input />'\n    assert html.script('alert(\"Hello World\");') == '<script>' \\\n        'alert(\"Hello World\");</script>'\n    assert xhtml.script('alert(\"Hello World\");') == '<script>' \\\n        '/*<![CDATA[*/alert(\"Hello World\");/*]]>*/</script>'\n\ndef test_validate_arguments():\n    \"\"\"Function argument validator\"\"\"\n    take_none = lambda: None\n    take_two = lambda a, b: None\n    take_two_one_default = lambda a, b=0: None\n\n    assert validate_arguments(take_two, (1, 2,), {}) == ((1, 2), {})\n    assert validate_arguments(take_two, (1,), {'b': 2}) == ((1, 2), {})\n    assert validate_arguments(take_two_one_default, (1,), {}) == ((1, 0), {})\n    assert validate_arguments(take_two_one_default, (1, 2), {}) == ((1, 2), {})\n\n    assert_raises(ArgumentValidationError, validate_arguments, take_two, (), {})\n\n    assert validate_arguments(take_none, (1, 2,), {'c': 3}) == ((), {})\n    assert_raises(ArgumentValidationError,\n           validate_arguments, take_none, (1,), {}, drop_extra=False)\n    assert_raises(ArgumentValidationError,\n           validate_arguments, take_none, (), {'a': 1}, drop_extra=False)\n\n\ndef test_header_set_duplication_bug():\n    \"\"\"Header duplication bug on set\"\"\"\n    from werkzeug.datastructures import Headers\n    headers = Headers([\n        ('Content-Type', 'text/html'),\n        ('Foo', 'bar'),\n        ('Blub', 'blah')\n    ])\n    headers['blub'] = 'hehe'\n    headers['blafasel'] = 'humm'\n    assert headers == Headers([\n        ('Content-Type', 'text/html'),\n        ('Foo', 'bar'),\n        ('blub', 'hehe'),\n        ('blafasel', 'humm')\n    ])\n\n\ndef test_append_slash_redirect():\n    \"\"\"Append slash redirect\"\"\"\n    def app(env, sr):\n        return append_slash_redirect(env)(env, sr)\n    client = Client(app, BaseResponse)\n    response = client.get('foo', base_url='http://example.org/app')\n    assert response.status_code == 301\n    assert response.headers['Location'] == 'http://example.org/app/foo/'\n\n\ndef test_cached_property_doc():\n    \"\"\"Documentation of cached_property is kept\"\"\"\n    @cached_property\n    def foo():\n        \"\"\"testing\"\"\"\n        return 42\n    assert foo.__doc__ == 'testing'\n    assert foo.__name__ == 'foo'\n    assert foo.__module__ == __name__\n"}
{"context": "<|file_sep|>werkzeug\\testsuite\\local.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.testsuite.local\n    ~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Local and local proxy tests.\n\n    :copyright: (c) 2011 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport time\nimport unittest\nfrom threading import Thread\n\nfrom werkzeug.testsuite import WerkzeugTestCase\n\nfrom werkzeug import local\n\n\nclass LocalTestCase(WerkzeugTestCase):\n\n    def test_basic_local(self):\n        l = local.Local()\n        l.foo = 0\n        values = []\n        def value_setter(idx):\n            time.sleep(0.01 * idx)\n            l.foo = idx\n            time.sleep(0.02)\n            values.append(l.foo)\n        threads = [Thread(target=value_setter, args=(x,))\n                   for x in [1, 2, 3]]\n        for thread in threads:\n            thread.start()\n        time.sleep(0.2)\n        assert sorted(values) == [1, 2, 3]\n\n        def delfoo():\n            del l.foo\n        delfoo()\n        self.assert_raises(AttributeError, lambda: l.foo)\n        self.assert_raises(AttributeError, delfoo)\n\n        local.release_local(l)\n\n    def test_local_release(self):\n        loc = local.Local()\n        loc.foo = 42\n        local.release_local(loc)\n        assert not hasattr(loc, 'foo')\n\n        ls = local.LocalStack()\n        ls.push(42)\n        local.release_local(ls)\n        assert ls.top is None\n\n    def test_local_proxy(self):\n        foo = []\n        ls = local.LocalProxy(lambda: foo)\n        ls.append(42)\n        ls.append(23)\n        ls[1:] = [1, 2, 3]\n        assert foo == [42, 1, 2, 3]\n        assert repr(foo) == repr(ls)\n        assert foo[0] == 42\n        foo += [1]\n        assert list(foo) == [42, 1, 2, 3, 1]\n\n    def test_local_stack(self):\n        ident = local.get_ident()\n\n        ls = local.LocalStack()\n        assert ident not in ls._local.__storage__\n        assert ls.top is None\n        ls.push(42)\n        assert ident in ls._local.__storage__\n        assert ls.top == 42\n        ls.push(23)\n        assert ls.top == 23\n        ls.pop()\n        assert ls.top == 42\n        ls.pop()\n        assert ls.top is None\n        assert ls.pop() is None\n        assert ls.pop() is None\n\n        proxy = ls()\n        ls.push([1, 2])\n        assert proxy == [1, 2]\n        ls.push((1, 2))\n        assert proxy == (1, 2)\n        ls.pop()\n        ls.pop()\n        assert repr(proxy) == '<LocalProxy unbound>'\n\n        assert ident not in ls._local.__storage__\n\n    def test_local_proxies_with_callables(self):\n        foo = 42\n        ls = local.LocalProxy(lambda: foo)\n        assert ls == 42\n        foo = [23]\n        ls.append(42)\n        assert ls == [23, 42]\n        assert foo == [23, 42]\n\n    def test_custom_idents(self):\n        ident = 0\n        loc = local.Local()\n        stack = local.LocalStack()\n        mgr = local.LocalManager([loc, stack], ident_func=lambda: ident)\n\n        loc.foo = 42\n        stack.push({'foo': 42})\n        ident = 1\n        loc.foo = 23\n        stack.push({'foo': 23})\n        ident = 0\n        assert loc.foo == 42\n        assert stack.top['foo'] == 42\n        stack.pop()\n        assert stack.top is None\n        ident = 1\n        assert loc.foo == 23\n        assert stack.top['foo'] == 23\n        stack.pop()\n        assert stack.top is None\n\n\ndef suite():\n    suite = unittest.TestSuite()\n    suite.addTest(unittest.makeSuite(LocalTestCase))\n    return suite\n"}
{"context": "<|file_sep|>tests\\test_wsgi.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.wsgi test\n    ~~~~~~~~~~~~~~~~~~\n\n    Tests the WSGI utilities.\n\n    :copyright: (c) 2010 by the Werkzeug Team, see AUTHORS for more details.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nfrom os import path\nfrom cStringIO import StringIO\n\nfrom nose.tools import assert_raises\n\nfrom werkzeug import Client, create_environ, BaseResponse, run_wsgi_app\nfrom werkzeug.exceptions import BadRequest\n\nfrom werkzeug.wsgi import SharedDataMiddleware, get_host, responder, \\\n     LimitedStream, pop_path_info, peek_path_info, extract_path_info\n\n\ndef test_shareddatamiddleware_get_file_loader():\n    \"\"\"Shared middleware file loader lookup\"\"\"\n    app = SharedDataMiddleware(None, {})\n    assert callable(app.get_file_loader('foo'))\n\n\ndef test_shared_data_middleware():\n    \"\"\"Shared data middleware\"\"\"\n    def null_application(environ, start_response):\n        start_response('404 NOT FOUND', [('Content-Type', 'text/plain')])\n        yield 'NOT FOUND'\n    app = SharedDataMiddleware(null_application, {\n        '/':        path.join(path.dirname(__file__), 'res'),\n        '/sources': path.join(path.dirname(__file__), 'res'),\n        '/pkg':     ('werkzeug.debug', 'shared')\n    })\n\n    for p in '/test.txt', '/sources/test.txt':\n        app_iter, status, headers = run_wsgi_app(app, create_environ(p))\n        assert status == '200 OK'\n        assert ''.join(app_iter).strip() == 'FOUND'\n\n    app_iter, status, headers = run_wsgi_app(app, create_environ('/pkg/body.tmpl'))\n    contents = ''.join(app_iter)\n    assert 'Werkzeug Debugger' in contents\n\n    app_iter, status, headers = run_wsgi_app(app, create_environ('/missing'))\n    assert status == '404 NOT FOUND'\n    assert ''.join(app_iter).strip() == 'NOT FOUND'\n\n\ndef test_get_host():\n    \"\"\"Host lookup\"\"\"\n    env = {'HTTP_X_FORWARDED_HOST': 'example.org',\n           'SERVER_NAME': 'bullshit', 'HOST_NAME': 'ignore me dammit'}\n    assert get_host(env) == 'example.org'\n    assert get_host(create_environ('/', 'http://example.org')) \\\n        == 'example.org'\n\n\ndef test_responder():\n    \"\"\"Responder decorator\"\"\"\n    def foo(environ, start_response):\n        return BaseResponse('Test')\n    client = Client(responder(foo), BaseResponse)\n    response = client.get('/')\n    assert response.status_code == 200\n    assert response.data == 'Test'\n\n\ndef test_pop_path_info():\n    \"\"\"Test path info popping in the utils\"\"\"\n    original_env = {'SCRIPT_NAME': '/foo', 'PATH_INFO': '/a/b///c'}\n\n    # regular path info popping\n    def assert_tuple(script_name, path_info):\n        assert env.get('SCRIPT_NAME') == script_name\n        assert env.get('PATH_INFO') == path_info\n    env = original_env.copy()\n    pop = lambda: pop_path_info(env)\n\n    assert_tuple('/foo', '/a/b///c')\n    assert pop() == 'a'\n    assert_tuple('/foo/a', '/b///c')\n    assert pop() == 'b'\n    assert_tuple('/foo/a/b', '///c')\n    assert pop() == 'c'\n    assert_tuple('/foo/a/b///c', '')\n    assert pop() is None\n\n\ndef test_peek_path_info():\n    \"\"\"Test path info peeking in wrappers and utils\"\"\"\n    env = {'SCRIPT_NAME': '/foo', 'PATH_INFO': '/aaa/b///c'}\n\n    assert peek_path_info(env) == 'aaa'\n    assert peek_path_info(env) == 'aaa'\n\n\nclass RaisingLimitedStream(LimitedStream):\n\n    def on_exhausted(self):\n        raise BadRequest('input stream exhausted')\n\n\ndef test_limited_stream():\n    \"\"\"Test the LimitedStream\"\"\"\n    io = StringIO('123456')\n    stream = RaisingLimitedStream(io, 3)\n    assert stream.read() == '123'\n    assert_raises(BadRequest, stream.read)\n\n    io = StringIO('123456')\n    stream = RaisingLimitedStream(io, 3)\n    assert stream.read(1) == '1'\n    assert stream.read(1) == '2'\n    assert stream.read(1) == '3'\n    assert_raises(BadRequest, stream.read)\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readline() == '123456\\n'\n    assert stream.readline() == 'ab'\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readlines() == ['123456\\n', 'ab']\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readlines(2) == ['12']\n    assert stream.readlines(2) == ['34']\n    assert stream.readlines() == ['56\\n', 'ab']\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readline(100) == '123456\\n'\n\n    io = StringIO('123456\\nabcdefg')\n    stream = LimitedStream(io, 9)\n    assert stream.readlines(100) == ['123456\\n', 'ab']\n\n    io = StringIO('123456')\n    stream = LimitedStream(io, 3)\n    assert stream.read(1) == '1'\n    assert stream.read(1) == '2'\n    assert stream.read() == '3'\n    assert stream.read() == ''\n\n\ndef test_path_info_extraction():\n    \"\"\"PATH INFO extraction feature\"\"\"\n    x = extract_path_info('http://example.com/app', '/app/hello')\n    assert x == u'/hello'\n    x = extract_path_info('http://example.com/app',\n                          'https://example.com/app/hello')\n    assert x == u'/hello'\n    x = extract_path_info('http://example.com/app/',\n                          'https://example.com/app/hello')\n    assert x == u'/hello'\n    x = extract_path_info('http://example.com/app/',\n                          'https://example.com/app')\n    assert x == u'/'\n    x = extract_path_info(u'http://☃.net/', u'/fööbär')\n    assert x == u'/fööbär'\n    x = extract_path_info(u'http://☃.net/x', u'http://☃.net/x/fööbär')\n    assert x == u'/fööbär'\n\n    env = create_environ(u'/fööbär', u'http://☃.net/x/')\n    x = extract_path_info(env, u'http://☃.net/x/fööbär')\n    assert x == u'/fööbär'\n\n    x = extract_path_info('http://example.com/app/',\n                          'https://example.com/a/hello')\n    assert x is None\n    x = extract_path_info('http://example.com/app/',\n                          'https://example.com/app/hello',\n                          collapse_http_schemes=False)\n    assert x is None\n\n\ndef test_get_host_fallback():\n    \"\"\"Test non Host header server name guessing\"\"\"\n    assert get_host({\n        'SERVER_NAME':      'foobar.example.com',\n        'wsgi.url_scheme':  'http',\n        'SERVER_PORT':      '80'\n    }) == 'foobar.example.com'\n    assert get_host({\n        'SERVER_NAME':      'foobar.example.com',\n        'wsgi.url_scheme':  'http',\n        'SERVER_PORT':      '81'\n    }) == 'foobar.example.com:81'\n"}
{"context": "<|file_sep|>werkzeug\\testsuite\\security.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.testsuite.security\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Tests the security helpers.\n\n    :copyright: (c) 2013 by Armin Ronacher.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport os\nimport unittest\n\nfrom werkzeug.testsuite import WerkzeugTestCase\n\nfrom werkzeug.security import check_password_hash, generate_password_hash, \\\n     safe_join\n\n\nclass SecurityTestCase(WerkzeugTestCase):\n\n    def test_password_hashing(self):\n        hash1 = generate_password_hash('default')\n        hash2 = generate_password_hash(u'default', method='sha1')\n        assert hash1 != hash2\n        assert check_password_hash(hash1, 'default')\n        assert check_password_hash(hash2, 'default')\n        assert hash1.startswith('sha1$')\n        assert hash2.startswith('sha1$')\n\n        fakehash = generate_password_hash('default', method='plain')\n        assert fakehash == 'plain$$default'\n        assert check_password_hash(fakehash, 'default')\n\n        mhash = generate_password_hash(u'default', method='md5')\n        assert mhash.startswith('md5$')\n        assert check_password_hash(mhash, 'default')\n\n        legacy = 'md5$$c21f969b5f03d33d43e04f8f136e7682'\n        assert check_password_hash(legacy, 'default')\n\n        legacy = u'md5$$c21f969b5f03d33d43e04f8f136e7682'\n        assert check_password_hash(legacy, 'default')\n\n    def test_safe_join(self):\n        assert safe_join('foo', 'bar/baz') == os.path.join('foo', 'bar/baz')\n        assert safe_join('foo', '../bar/baz') is None\n        if os.name == 'nt':\n            assert safe_join('foo', 'foo\\\\bar') is None\n\n\ndef suite():\n    suite = unittest.TestSuite()\n    suite.addTest(unittest.makeSuite(SecurityTestCase))\n    return suite\n"}
{"context": "<|file_sep|>examples\\manage-simplewiki.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"\n    Manage SimpleWiki\n    ~~~~~~~~~~~~~~~~~\n\n    This script provides some basic commands to debug and test SimpleWiki.\n\n    :copyright: (c) 2009 by the Werkzeug Team, see AUTHORS for more details.\n    :license: BSD, see LICENSE for more details.\n\"\"\"\nimport os\nfrom werkzeug import script\n\n\ndef make_wiki():\n    \"\"\"Helper function that creates a new wiki instance.\"\"\"\n    from simplewiki import SimpleWiki\n    database_uri = os.environ.get('SIMPLEWIKI_DATABASE_URI')\n    return SimpleWiki(database_uri or 'sqlite:////tmp/simplewiki.db')\n\n\ndef shell_init_func():\n    \"\"\"\n    Called on shell initialization.  Adds useful stuff to the namespace.\n    \"\"\"\n    from simplewiki import database\n    wiki = make_wiki()\n    wiki.bind_to_context()\n    return {\n        'wiki':     wiki,\n        'db':       database\n    }\n\n\naction_runserver = script.make_runserver(make_wiki, use_reloader=True)\naction_shell = script.make_shell(shell_init_func)\n\n\ndef action_initdb():\n    \"\"\"Initialize the database\"\"\"\n    make_wiki().init_database()\n\n\nif __name__ == '__main__':\n    script.run()\n"}
{"context": "<|file_sep|>tests\\sansio\\test_utils.py\nimport typing as t\n\nimport pytest\n\nfrom werkzeug.sansio.utils import get_host\n\n\n@pytest.mark.parametrize(\n    (\"scheme\", \"host_header\", \"server\", \"expected\"),\n    [\n        (\"http\", \"spam\", None, \"spam\"),\n        (\"http\", \"spam:80\", None, \"spam\"),\n        (\"https\", \"spam\", None, \"spam\"),\n        (\"https\", \"spam:443\", None, \"spam\"),\n        (\"http\", \"spam:8080\", None, \"spam:8080\"),\n        (\"ws\", \"spam\", None, \"spam\"),\n        (\"ws\", \"spam:80\", None, \"spam\"),\n        (\"wss\", \"spam\", None, \"spam\"),\n        (\"wss\", \"spam:443\", None, \"spam\"),\n        (\"http\", None, (\"spam\", 80), \"spam\"),\n        (\"http\", None, (\"spam\", 8080), \"spam:8080\"),\n        (\"http\", None, (\"unix/socket\", None), \"unix/socket\"),\n        (\"http\", \"spam\", (\"eggs\", 80), \"spam\"),\n    ],\n)\ndef test_get_host(\n    scheme: str,\n    host_header: t.Optional[str],\n    server: t.Optional[t.Tuple[str, t.Optional[int]]],\n    expected: str,\n) -> None:\n    assert get_host(scheme, host_header, server) == expected\n"}
{"context": "<|file_sep|>werkzeug\\debug\\repr.py\n# -*- coding: utf-8 -*-\n\"\"\"\n    werkzeug.debug.repr\n    ~~~~~~~~~~~~~~~~~~~\n\n    This module implements object representations for debugging purposes.\n    Unlike the default repr these reprs expose a lot more information and\n    produce HTML instead of ASCII.\n\n    Together with the CSS and JavaScript files of the debugger this gives\n    a colorful and more compact output.\n\n    :copyright: Copyright 2008 by Armin Ronacher.\n    :license: BSD.\n\"\"\"\nimport sys\nimport re\nfrom traceback import format_exception_only\ntry:\n    from collections import deque\nexcept ImportError:\n    deque = None\nfrom cgi import escape\ntry:\n    set\nexcept NameError:\n    from sets import Set as set, ImmutableSet as frozenset\n\n\nRegexType = type(re.compile(''))\n\n\ndef debug_repr(obj):\n    \"\"\"Creates a debug repr of an object as HTML unicode string.\"\"\"\n    return DebugReprGenerator().repr(obj)\n\n\ndef _add_subclass_info(inner, obj, base):\n    if isinstance(base, tuple):\n        for base in base:\n            if type(obj) is base:\n                return inner\n    elif type(obj) is base:\n        return inner\n    module = ''\n    if obj.__class__.__module__ not in ('__builtin__', 'exceptions'):\n        module = '<span class=\"module\">%s.</span>' % obj.__class__.__module__\n    return '%s%s(%s)' % (module, obj.__class__.__name__, inner)\n\n\nclass DebugReprGenerator(object):\n\n    def __init__(self):\n        self._stack = []\n\n    def _sequence_repr_maker(left, right, base=object(), limit=8):\n        def proxy(self, obj, recursive):\n            if recursive:\n                return _add_subclass_info(left + '...' + right, obj, base)\n            buf = [left]\n            have_extended_section = False\n            for idx, item in enumerate(obj):\n                if idx:\n                    buf.append(', ')\n                if idx == limit:\n                    buf.append('<span class=\"extended\">')\n                    have_extended_section = True\n                buf.append(self.repr(item))\n            if have_extended_section:\n                buf.append('</span>')\n            buf.append(right)\n            return _add_subclass_info(u''.join(buf), obj, base)\n        return proxy\n\n    list_repr = _sequence_repr_maker('[', ']', list)\n    tuple_repr = _sequence_repr_maker('(', ')', tuple)\n    set_repr = _sequence_repr_maker('set([', '])', set)\n    frozenset_repr = _sequence_repr_maker('frozenset([', '])', frozenset)\n    if deque is not None:\n        deque_repr = _sequence_repr_maker('<span class=\"module\">collections.'\n                                          '</span>deque([', '])', deque)\n    del _sequence_repr_maker\n\n    def regex_repr(self, obj):\n        pattern = repr(obj.pattern).decode('string-escape', 'ignore')\n        if pattern[:1] == 'u':\n            pattern = 'ur' + pattern[1:]\n        else:\n            pattern = 'r' + pattern\n        return u're.compile(<span class=\"string regex\">%s</span>)' % pattern\n\n    def string_repr(self, obj, limit=70):\n        buf = ['<span class=\"string\">']\n        escaped = escape(obj)\n        a = repr(escaped[:limit])\n        b = repr(escaped[limit:])\n        if isinstance(obj, unicode):\n            buf.append('u')\n            a = a[1:]\n            b = b[1:]\n        if b != \"''\":\n            buf.extend((a[:-1], '<span class=\"extended\">', b[1:], '</span>'))\n        else:\n            buf.append(a)\n        buf.append('</span>')\n        return _add_subclass_info(u''.join(buf), obj, (str, unicode))\n\n    def dict_repr(self, d, recursive, limit=5):\n        if recursive:\n            return _add_subclass_info(u'{...}', d, dict)\n        buf = ['{']\n        have_extended_section = False\n        for idx, (key, value) in enumerate(d.iteritems()):\n            if idx:\n                buf.append(', ')\n            if idx == limit - 1:\n                buf.append('<span class=\"extended\">')\n                have_extended_section = True\n            buf.append('<span class=\"pair\"><span class=\"key\">%s</span>: '\n                       '<span class=\"value\">%s</span></span>' %\n                       (self.repr(key), self.repr(value)))\n        if have_extended_section:\n            buf.append('</span>')\n        buf.append('}')\n        return _add_subclass_info(u''.join(buf), d, dict)\n\n    def object_repr(self, obj):\n        return u'<span class=\"object\">%s</span>' % \\\n               escape(repr(obj).decode('utf-8', 'replace'))\n\n    def dispatch_repr(self, obj, recursive):\n        if isinstance(obj, (int, long, float, complex)):\n            return u'<span class=\"number\">%r</span>' % obj\n        if isinstance(obj, basestring):\n            return self.string_repr(obj)\n        if isinstance(obj, RegexType):\n            return self.regex_repr(obj)\n        if isinstance(obj, list):\n            return self.list_repr(obj, recursive)\n        if isinstance(obj, tuple):\n            return self.tuple_repr(obj, recursive)\n        if isinstance(obj, set):\n            return self.set_repr(obj, recursive)\n        if isinstance(obj, frozenset):\n            return self.frozenset_repr(obj, recursive)\n        if isinstance(obj, dict):\n            return self.dict_repr(obj, recursive)\n        if deque is not None and isinstance(obj, deque):\n            return self.deque_repr(obj, recursive)\n        return self.object_repr(obj)\n\n    def fallback_repr(self):\n        try:\n            info = ''.join(format_exception_only(*sys.exc_info()[:2]))\n        except:\n            info = '?'\n        return u'<span class=\"brokenrepr\">&lt;broken repr (%s)&gt;' \\\n               u'</span>' % escape(info.decode('utf-8', 'ignore').strip())\n\n    def repr(self, obj):\n        recursive = False\n        for item in self._stack:\n            if item is obj:\n                recursive = True\n                break\n        self._stack.append(obj)\n        try:\n            try:\n                return self.dispatch_repr(obj, recursive)\n            except:\n                return self.fallback_repr()\n        finally:\n            self._stack.pop()\n"}
